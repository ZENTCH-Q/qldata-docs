{"config":{"lang":["en"],"separator":"[\\s\\-,:!=\\[\\]()\"/]+|(?!\\b)(?=[A-Z][a-z])|\\.(?!\\d)|&[lg]t;","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Home","text":"qldata <p>Production-ready Python library for cryptocurrency market data</p> Get Started API Reference"},{"location":"#why-qldata","title":"Why qldata?","text":"<p>qldata is a modern, Pythonic library designed for quantitative traders and researchers who need reliable access to cryptocurrency market data. Built with production systems in mind, it combines a beautiful fluent API with enterprise-grade resilience features.</p> \ud83c\udfaf Beautiful API <p>Fluent, chainable interface that reads like English. Write expressive queries in a single line of code.</p> \ud83d\udce1 Real-Time Streaming <p>WebSocket connections with auto-reconnect, rate limiting, and sequence tracking built-in.</p> \ud83d\udd04 Data Transforms <p>Clean, resample, and validate data with a powerful transform pipeline. Handles missing data intelligently.</p> \ud83d\udee1\ufe0f Production Ready <p>Monitoring, alerts, and resilience features designed for 24/7 operation in production environments.</p> \ud83c\udfe6 Multi-Exchange <p>Unified API across Binance and Bybit. Easily extend to support additional exchanges.</p> \ud83d\udcca Type Safe <p>Full type hints throughout. Rich data models for bars, ticks, order books, and more.</p>"},{"location":"#quick-example","title":"Quick Example","text":"<pre><code>import qldata as qd\n\n# Historical data with cleaning\ndf = qd.data(\"BTCUSDT\", source=\"binance\", category=\"spot\") \\\n    .last(30, \"days\") \\\n    .resolution(\"1h\") \\\n    .clean(remove_outliers=True) \\\n    .fill_forward() \\\n    .get()\n\n# Live streaming with callbacks\nstream = qd.stream([\"BTCUSDT\", \"ETHUSDT\"], source=\"binance\") \\\n    .resolution(\"tick\") \\\n    .on_data(lambda df: print(f\"Price: {df['price'].iloc[-1]}\")) \\\n    .on_error(lambda e: print(f\"Error: {e}\")) \\\n    .get(start=True)\n</code></pre>"},{"location":"#installation","title":"Installation","text":"Full InstallMinimalBinance OnlyBybit Only <pre><code>pip install qldata\n</code></pre> <pre><code>pip install qldata[minimal]\n</code></pre> <pre><code>pip install qldata[binance]\n</code></pre> <pre><code>pip install qldata[bybit]\n</code></pre>"},{"location":"#supported-exchanges","title":"Supported Exchanges","text":"Exchange Spot Perpetuals Live Streaming Status Binance \u2705 \u2705 USDM \u2705 Stable Bybit \u2705 \u2705 Linear \u2705 Stable"},{"location":"#whats-next","title":"What's Next?","text":"\ud83d\udcd6 Installation Guide <p>Set up qldata in your environment with our step-by-step guide.</p> \ud83d\ude80 Quick Start <p>Get up and running with your first data query in minutes.</p> \ud83d\udcd3 Cookbook <p>Real-world examples and recipes for common use cases.</p>"},{"location":"changelog/","title":"Changelog","text":"<p>All notable changes to qldata are documented here.</p> <p>The format is based on Keep a Changelog, and this project adheres to Semantic Versioning.</p>"},{"location":"changelog/#030-2025-12-05","title":"[0.3.0] - 2025-12-05","text":""},{"location":"changelog/#added","title":"Added","text":"<ul> <li>Resilience by Default: <code>qd.stream()</code> now enables auto-reconnect, rate limiting, sequence tracking, and time sync by default</li> <li>ResilienceConfig: New configuration class for customizing resilience behavior</li> <li>RateLimitManager: Intelligent rate limit handling for API calls</li> <li>SequenceTracker: Detect and log missing messages in streams</li> <li>TimeSyncManager: Clock synchronization with exchange servers</li> <li>DataQualityMonitor: Real-time latency, throughput, and staleness tracking</li> <li>AlertManager: Callback-based alerting for production systems</li> <li>ConnectionStateManager: Track connection state transitions</li> </ul>"},{"location":"changelog/#changed","title":"Changed","text":"<ul> <li>Streaming sessions now include resilience features by default</li> <li>Improved WebSocket reconnection with exponential backoff</li> <li>Better error messages for connection failures</li> </ul>"},{"location":"changelog/#fixed","title":"Fixed","text":"<ul> <li>WebSocket connection drops no longer cause data loss</li> <li>Rate limit handling for high-frequency queries</li> <li>Timestamp handling for Bybit linear contracts</li> </ul>"},{"location":"changelog/#020-2025-11-15","title":"[0.2.0] - 2025-11-15","text":""},{"location":"changelog/#added_1","title":"Added","text":"<ul> <li>Fluent API: New chainable query builder for <code>qd.data()</code> and <code>qd.stream()</code></li> <li>Transform Pipeline: <code>clean()</code>, <code>fill_forward()</code>, <code>resample()</code> methods</li> <li>Bybit Support: Full support for Bybit spot and linear perpetuals</li> <li>Multi-Symbol Queries: Parallel downloads for multiple symbols</li> <li>Symbol Discovery: <code>list_symbols()</code> with filtering options</li> </ul>"},{"location":"changelog/#changed_1","title":"Changed","text":"<ul> <li>Unified API design across all data sources</li> <li>Improved DataFrame column naming consistency</li> <li>Better timezone handling (all UTC)</li> </ul>"},{"location":"changelog/#deprecated","title":"Deprecated","text":"<ul> <li>Old-style positional arguments (use keyword arguments)</li> </ul>"},{"location":"changelog/#010-2025-10-01","title":"[0.1.0] - 2025-10-01","text":""},{"location":"changelog/#added_2","title":"Added","text":"<ul> <li>Initial release</li> <li>Binance spot and USDM futures support</li> <li>Historical data fetching with <code>qd.data()</code></li> <li>Live streaming with <code>qd.stream()</code></li> <li>Basic data models (Bar, Tick, OrderBook)</li> <li>Symbol information API</li> <li>Parquet and DuckDB storage backends</li> </ul>"},{"location":"changelog/#upgrade-guide","title":"Upgrade Guide","text":""},{"location":"changelog/#02x-030","title":"0.2.x \u2192 0.3.0","text":"<p>Resilience is now enabled by default. To opt out:</p> <pre><code># Disable resilience\nstream = qd.stream([\"BTCUSDT\"], source=\"binance\") \\\n    .resolution(\"tick\") \\\n    .on_data(handler) \\\n    .get(start=True, resilience=False)\n</code></pre>"},{"location":"changelog/#01x-020","title":"0.1.x \u2192 0.2.0","text":"<p>Update to fluent API style:</p> <pre><code># Old style (deprecated)\ndf = qd.get_bars(\"BTCUSDT\", \"binance\", days=30, resolution=\"1h\")\n\n# New style (recommended)\ndf = qd.data(\"BTCUSDT\", source=\"binance\") \\\n    .last(30) \\\n    .resolution(\"1h\") \\\n    .get()\n</code></pre>"},{"location":"contributing/","title":"Contributing","text":"<p>Thank you for your interest in contributing to qldata!</p>"},{"location":"contributing/#documentation-repository","title":"Documentation Repository","text":"<p>This documentation is hosted at github.com/ZENTCH-Q/qldata-docs.</p>"},{"location":"contributing/#ways-to-contribute","title":"Ways to Contribute","text":""},{"location":"contributing/#documentation","title":"\ud83d\udcdd Documentation","text":"<ul> <li>Fix typos or unclear explanations</li> <li>Add examples and recipes</li> <li>Improve API documentation</li> <li>Translate documentation</li> </ul>"},{"location":"contributing/#bug-reports","title":"\ud83d\udc1b Bug Reports","text":"<p>Found an issue? Please report it:</p> <ol> <li>Check existing issues first</li> <li>Provide a minimal reproducible example</li> <li>Include Python version and qldata version</li> <li>Describe expected vs actual behavior</li> </ol>"},{"location":"contributing/#feature-requests","title":"\ud83d\udca1 Feature Requests","text":"<p>Have an idea? We'd love to hear it:</p> <ol> <li>Check if it's already requested</li> <li>Describe the use case</li> <li>Propose an API design (optional)</li> </ol>"},{"location":"contributing/#development-setup","title":"Development Setup","text":"<pre><code># Clone the repository\ngit clone https://github.com/ZENTCH-Q/qldata-docs.git\ncd qldata-docs\n\n# Create virtual environment\npython -m venv .venv\nsource .venv/bin/activate  # or .venv\\Scripts\\activate on Windows\n\n# Install dependencies\npip install -e \".[dev]\"\n\n# Run tests\npytest\n\n# Build docs locally\nmkdocs serve\n</code></pre>"},{"location":"contributing/#code-style","title":"Code Style","text":"<p>We use:</p> <ul> <li>Black for formatting</li> <li>Ruff for linting</li> <li>mypy for type checking</li> </ul> <pre><code># Format code\nblack src tests\n\n# Lint\nruff check src tests\n\n# Type check\nmypy src\n</code></pre>"},{"location":"contributing/#pull-request-process","title":"Pull Request Process","text":"<ol> <li>Fork the repository</li> <li>Create a feature branch (<code>git checkout -b feature/amazing-feature</code>)</li> <li>Make your changes</li> <li>Run tests (<code>pytest</code>)</li> <li>Run linting (<code>ruff check &amp;&amp; black --check</code>)</li> <li>Commit with a clear message</li> <li>Push and create a Pull Request</li> </ol>"},{"location":"contributing/#documentation-style","title":"Documentation Style","text":"<p>When writing documentation:</p> <ul> <li>Use clear, concise language</li> <li>Include code examples for every feature</li> <li>Add type hints to all function signatures</li> <li>Use admonitions for important notes</li> </ul> <pre><code>!!! note \"Title\"\n    Content here\n\n!!! warning\n    Important warning\n\n!!! tip\n    Helpful tip\n</code></pre>"},{"location":"contributing/#license","title":"License","text":"<p>By contributing, you agree that your contributions will be licensed under the MIT License.</p>"},{"location":"contributing/#questions","title":"Questions?","text":"<ul> <li>Open a GitHub issue</li> <li>Check existing documentation</li> </ul> <p>Thank you for contributing! \ud83c\udf89</p>"},{"location":"license/","title":"License","text":"<p>qldata is released under the MIT License.</p>"},{"location":"license/#mit-license","title":"MIT License","text":"<pre><code>MIT License\n\nCopyright (c) 2024 ZENTCH-Q\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n</code></pre>"},{"location":"license/#what-this-means","title":"What This Means","text":"<p>The MIT License is a permissive license that allows you to:</p> <ul> <li>\u2705 Use commercially</li> <li>\u2705 Modify</li> <li>\u2705 Distribute</li> <li>\u2705 Use privately</li> <li>\u2705 Sublicense</li> </ul> <p>With the following conditions:</p> <ul> <li>Include the original copyright notice</li> <li>Include the license text</li> </ul>"},{"location":"license/#third-party-licenses","title":"Third-Party Licenses","text":"<p>qldata depends on several open-source packages:</p> Package License pandas BSD-3-Clause numpy BSD-3-Clause pyarrow Apache-2.0 python-binance MIT pybit MIT duckdb MIT websockets BSD-3-Clause aiohttp Apache-2.0"},{"location":"api/historical-data/","title":"Historical Data API","text":"<p>The <code>qd.data()</code> function provides a fluent interface for fetching historical market data.</p>"},{"location":"api/historical-data/#basic-usage","title":"Basic Usage","text":"<pre><code>import qldata as qd\n\n# Minimal query\ndf = qd.data(\"BTCUSDT\", source=\"binance\").last(30).resolution(\"1h\").get()\n\n# Full query with all options\ndf = qd.data(\n    \"BTCUSDT\",              # Symbol(s)\n    source=\"binance\",       # Exchange\n    category=\"spot\"         # Market type\n) \\\n    .last(30, \"days\") \\     # Time range\n    .resolution(\"1h\") \\     # Bar resolution\n    .clean() \\              # Clean data\n    .fill_forward() \\       # Fill gaps\n    .get()                  # Execute\n</code></pre>"},{"location":"api/historical-data/#function-signature","title":"Function Signature","text":""},{"location":"api/historical-data/#qldata.data","title":"data  <code>module-attribute</code>","text":"<pre><code>data = UnifiedAPI()\n</code></pre>"},{"location":"api/historical-data/#query-builder-methods","title":"Query Builder Methods","text":""},{"location":"api/historical-data/#lastn-unitdays","title":"<code>.last(n, unit=\"days\")</code>","text":"<p>Set the time range to the last N time units from now.</p> <pre><code># Last 30 days (default unit)\n.last(30)\n\n# Last 7 days\n.last(7, \"days\")\n\n# Last 24 hours\n.last(24, \"hours\")\n\n# Last 60 minutes\n.last(60, \"minutes\")\n</code></pre> <p>Parameters:</p> Parameter Type Default Description <code>n</code> <code>int</code> - Number of time units <code>unit</code> <code>str</code> <code>\"days\"</code> Time unit: <code>\"days\"</code>, <code>\"hours\"</code>, <code>\"minutes\"</code>"},{"location":"api/historical-data/#rangestart-end","title":"<code>.range(start, end)</code>","text":"<p>Set an explicit date range.</p> <pre><code>from datetime import datetime\n\n# Specific date range\n.range(\n    datetime(2024, 1, 1),\n    datetime(2024, 1, 31)\n)\n\n# With timezone\nfrom datetime import timezone\n.range(\n    datetime(2024, 1, 1, tzinfo=timezone.utc),\n    datetime(2024, 1, 31, tzinfo=timezone.utc)\n)\n</code></pre> <p>Parameters:</p> Parameter Type Description <code>start</code> <code>datetime</code> Start of range (inclusive) <code>end</code> <code>datetime</code> End of range (inclusive) <p>Timezone Handling</p> <p>If no timezone is provided, UTC is assumed. All returned timestamps are in UTC.</p>"},{"location":"api/historical-data/#resolutiontimeframe","title":"<code>.resolution(timeframe)</code>","text":"<p>Set the bar/candle resolution.</p> <pre><code># Using string shortcuts\n.resolution(\"1m\")   # 1-minute\n.resolution(\"5m\")   # 5-minute\n.resolution(\"15m\")  # 15-minute\n.resolution(\"1h\")   # 1-hour\n.resolution(\"4h\")   # 4-hour\n.resolution(\"1d\")   # Daily\n.resolution(\"1w\")   # Weekly\n\n# Using Timeframe enum\nfrom qldata import Timeframe\n.resolution(Timeframe.HOUR_1)\n</code></pre> <p>Supported Resolutions:</p> String Timeframe Enum Description <code>\"1m\"</code> <code>Timeframe.MINUTE_1</code> 1 minute <code>\"3m\"</code> <code>Timeframe.MINUTE_3</code> 3 minutes <code>\"5m\"</code> <code>Timeframe.MINUTE_5</code> 5 minutes <code>\"15m\"</code> <code>Timeframe.MINUTE_15</code> 15 minutes <code>\"30m\"</code> <code>Timeframe.MINUTE_30</code> 30 minutes <code>\"1h\"</code> <code>Timeframe.HOUR_1</code> 1 hour <code>\"2h\"</code> <code>Timeframe.HOUR_2</code> 2 hours <code>\"4h\"</code> <code>Timeframe.HOUR_4</code> 4 hours <code>\"6h\"</code> <code>Timeframe.HOUR_6</code> 6 hours <code>\"8h\"</code> <code>Timeframe.HOUR_8</code> 8 hours <code>\"12h\"</code> <code>Timeframe.HOUR_12</code> 12 hours <code>\"1d\"</code> <code>Timeframe.DAY_1</code> 1 day <code>\"3d\"</code> <code>Timeframe.DAY_3</code> 3 days <code>\"1w\"</code> <code>Timeframe.WEEK_1</code> 1 week <code>\"1M\"</code> <code>Timeframe.MONTH_1</code> 1 month"},{"location":"api/historical-data/#cleankwargs","title":"<code>.clean(**kwargs)</code>","text":"<p>Apply adaptive data cleaning.</p> <pre><code># Basic cleaning (sorts, deduplicates)\n.clean()\n\n# Aggressive cleaning\n.clean(\n    remove_invalid_prices=True,  # Remove zero/negative prices\n    validate_ohlc=True,          # Validate OHLC relationships\n    remove_outliers=True,        # Remove statistical outliers\n    dropna_subset=None           # Columns to check for NaN\n)\n</code></pre> <p>Parameters:</p> Parameter Type Default Description <code>remove_invalid_prices</code> <code>bool</code> <code>False</code> Remove rows with zero or negative prices <code>validate_ohlc</code> <code>bool</code> <code>False</code> Ensure high \u2265 open,close \u2265 low <code>remove_outliers</code> <code>bool</code> <code>False</code> Remove statistical outliers (&gt;3\u03c3) <code>dropna_subset</code> <code>list[str]</code> <code>None</code> Columns to check for NaN (default: OHLCV)"},{"location":"api/historical-data/#fill_forward-fill_backward-interpolate","title":"<code>.fill_forward()</code> / <code>.fill_backward()</code> / <code>.interpolate()</code>","text":"<p>Fill missing values.</p> <pre><code># Forward fill (use last known value)\n.fill_forward()\n\n# Backward fill (use next known value)\n.fill_backward()\n\n# Linear interpolation\n.interpolate()\n.interpolate(method=\"linear\")   # Default\n.interpolate(method=\"time\")     # Time-weighted\n</code></pre>"},{"location":"api/historical-data/#resampletimeframe","title":"<code>.resample(timeframe)</code>","text":"<p>Resample bars to a different timeframe.</p> <pre><code># Fetch 1-minute data, resample to hourly\ndf = qd.data(\"BTCUSDT\", source=\"binance\") \\\n    .last(1, \"days\") \\\n    .resolution(\"1m\") \\\n    .resample(\"1h\") \\\n    .get()\n</code></pre> <p>Upsampling Not Supported</p> <p>You can only resample to larger timeframes (e.g., 1m \u2192 1h). Resampling to smaller timeframes is not supported.</p>"},{"location":"api/historical-data/#getkwargs","title":"<code>.get(**kwargs)</code>","text":"<p>Execute the query and return data.</p> <pre><code># Basic execution\ndf = query.get()\n\n# With options\ndf = query.get(\n    cache=True,         # Use disk cache\n    validate=True,      # Validate data\n    parallel=False,     # Parallel download (multi-symbol)\n    workers=4           # Worker count for parallel\n)\n</code></pre> <p>Parameters:</p> Parameter Type Default Description <code>cache</code> <code>bool</code> Config default Use disk caching <code>validate</code> <code>bool</code> Config default Validate returned data <code>parallel</code> <code>bool</code> <code>False</code> Parallel download for multi-symbol <code>workers</code> <code>int</code> <code>4</code> Number of parallel workers <p>Returns:</p> <ul> <li>Single symbol: <code>pandas.DataFrame</code> with OHLCV data</li> <li>Multiple symbols: <code>dict[str, pandas.DataFrame]</code></li> </ul>"},{"location":"api/historical-data/#multi-symbol-queries","title":"Multi-Symbol Queries","text":"<p>Fetch data for multiple symbols at once:</p> <pre><code># List of symbols\ndata = qd.data([\"BTCUSDT\", \"ETHUSDT\", \"SOLUSDT\"], source=\"binance\") \\\n    .last(7) \\\n    .resolution(\"1d\") \\\n    .get()\n\n# Returns: {\"BTCUSDT\": df1, \"ETHUSDT\": df2, \"SOLUSDT\": df3}\nfor symbol, df in data.items():\n    print(f\"{symbol}: {len(df)} bars\")\n</code></pre>"},{"location":"api/historical-data/#parallel-downloads","title":"Parallel Downloads","text":"<p>For many symbols, use parallel downloads:</p> <pre><code># Parallel with 4 workers\ndata = qd.data(symbols, source=\"binance\") \\\n    .last(30) \\\n    .resolution(\"1h\") \\\n    .get(parallel=True, workers=4)\n</code></pre> <p>Optimal Worker Count</p> <ul> <li>For most cases, 4-8 workers is optimal</li> <li>More workers may hit rate limits faster</li> <li>Rate limiting is handled automatically</li> </ul>"},{"location":"api/historical-data/#return-value-format","title":"Return Value Format","text":""},{"location":"api/historical-data/#single-symbol","title":"Single Symbol","text":"<p>Returns a <code>pandas.DataFrame</code>:</p> <pre><code>df = qd.data(\"BTCUSDT\", source=\"binance\").last(7).resolution(\"1d\").get()\n\nprint(df.columns)\n# Index(['open', 'high', 'low', 'close', 'volume'], dtype='object')\n\nprint(df.index)\n# DatetimeIndex(['2024-11-28 00:00:00+00:00', ...], dtype='datetime64[ns, UTC]', name='timestamp')\n</code></pre>"},{"location":"api/historical-data/#multiple-symbols","title":"Multiple Symbols","text":"<p>Returns a <code>dict[str, DataFrame]</code>:</p> <pre><code>data = qd.data([\"BTCUSDT\", \"ETHUSDT\"], source=\"binance\").last(7).resolution(\"1d\").get()\n\nprint(type(data))\n# &lt;class 'dict'&gt;\n\nprint(data.keys())\n# dict_keys(['BTCUSDT', 'ETHUSDT'])\n</code></pre>"},{"location":"api/historical-data/#examples","title":"Examples","text":""},{"location":"api/historical-data/#example-1-basic-data-fetch","title":"Example 1: Basic Data Fetch","text":"<pre><code>import qldata as qd\n\n# Fetch last 30 days of hourly BTC data\ndf = qd.data(\"BTCUSDT\", source=\"binance\", category=\"spot\") \\\n    .last(30) \\\n    .resolution(\"1h\") \\\n    .get()\n\nprint(f\"Fetched {len(df)} bars\")\nprint(f\"Date range: {df.index[0]} to {df.index[-1]}\")\nprint(df.head())\n</code></pre>"},{"location":"api/historical-data/#example-2-clean-data-pipeline","title":"Example 2: Clean Data Pipeline","text":"<pre><code>import qldata as qd\n\n# Fetch and clean data\ndf = qd.data(\"BTCUSDT\", source=\"binance\") \\\n    .last(30) \\\n    .resolution(\"1h\") \\\n    .clean(\n        remove_invalid_prices=True,\n        remove_outliers=True\n    ) \\\n    .fill_forward() \\\n    .get()\n\n# Verify no missing values\nassert df.isna().sum().sum() == 0\n</code></pre>"},{"location":"api/historical-data/#example-3-resample-minute-to-hourly","title":"Example 3: Resample Minute to Hourly","text":"<pre><code>import qldata as qd\n\n# Fetch 1-minute data and resample to hourly\ndf = qd.data(\"BTCUSDT\", source=\"binance\") \\\n    .last(1, \"days\") \\\n    .resolution(\"1m\") \\\n    .clean() \\\n    .resample(\"1h\") \\\n    .get()\n\nprint(f\"Resampled to {len(df)} hourly bars\")\n</code></pre>"},{"location":"api/historical-data/#example-4-multi-symbol-comparison","title":"Example 4: Multi-Symbol Comparison","text":"<pre><code>import qldata as qd\n\n# Fetch same timeframe for multiple symbols\nsymbols = [\"BTCUSDT\", \"ETHUSDT\", \"SOLUSDT\", \"BNBUSDT\"]\n\ndata = qd.data(symbols, source=\"binance\") \\\n    .last(7) \\\n    .resolution(\"1d\") \\\n    .clean() \\\n    .get(parallel=True, workers=4)\n\n# Compare daily returns\nfor symbol, df in data.items():\n    returns = (df['close'].iloc[-1] / df['close'].iloc[0] - 1) * 100\n    print(f\"{symbol}: {returns:+.2f}%\")\n</code></pre>"},{"location":"api/historical-data/#example-5-futures-vs-spot","title":"Example 5: Futures vs Spot","text":"<pre><code>import qldata as qd\n\n# Compare spot and futures prices\nspot = qd.data(\"BTCUSDT\", source=\"binance\", category=\"spot\") \\\n    .last(7) \\\n    .resolution(\"1h\") \\\n    .get()\n\nfutures = qd.data(\"BTCUSDT\", source=\"binance\", category=\"usdm\") \\\n    .last(7) \\\n    .resolution(\"1h\") \\\n    .get()\n\n# Calculate basis (futures - spot)\nbasis = futures['close'] - spot['close']\nprint(f\"Average basis: ${basis.mean():.2f}\")\n</code></pre>"},{"location":"api/historical-data/#see-also","title":"See Also","text":"<ul> <li>Streaming API - Real-time data</li> <li>Data Transforms - Transform functions</li> <li>Reference Data - Symbol information</li> </ul>"},{"location":"api/monitoring/","title":"Monitoring &amp; Alerts API","text":"<p>Production-grade monitoring for data quality, latency, and connection health.</p>"},{"location":"api/monitoring/#overview","title":"Overview","text":"<p>qldata provides two main monitoring components:</p> <ul> <li>DataQualityMonitor - Track latency, throughput, and staleness</li> <li>AlertManager - Callback-based alerting system</li> </ul> <pre><code>from qldata.monitoring import DataQualityMonitor, AlertManager\n\n# Setup monitoring\nmonitor = DataQualityMonitor(stale_threshold_seconds=10)\nalerts = AlertManager()\n\n# Configure alerts\nalerts.on_stale_data(lambda: print(\"Data is stale!\"))\nalerts.on_high_latency(lambda ms: print(f\"High latency: {ms}ms\"))\n</code></pre>"},{"location":"api/monitoring/#dataqualitymonitor","title":"DataQualityMonitor","text":"<p>Real-time monitoring of data quality metrics.</p>"},{"location":"api/monitoring/#basic-usage","title":"Basic Usage","text":"<pre><code>from qldata.monitoring import DataQualityMonitor\nfrom datetime import datetime, timezone\n\n# Create monitor\nmonitor = DataQualityMonitor(stale_threshold_seconds=10)\n\n# Record incoming messages\ndef on_data(df):\n    if not df.empty:\n        monitor.record_message(df.index[-1])\n        # Process data...\n\n# Get current metrics\nmetrics = monitor.get_metrics()\nprint(f\"Throughput: {metrics['throughput']:.1f}/s\")\nprint(f\"P95 Latency: {metrics['latency_p95']:.1f}ms\")\nprint(f\"Is Stale: {metrics['is_stale']}\")\n</code></pre>"},{"location":"api/monitoring/#qldata.DataQualityMonitor","title":"DataQualityMonitor","text":"<pre><code>DataQualityMonitor(stale_threshold_seconds: int = 30)\n</code></pre> <p>Monitor streaming data quality in real-time.</p> <p>Tracks latency, throughput, and staleness of streaming data.</p> <p>Parameters:</p> Name Type Description Default <code>stale_threshold_seconds</code> <code>int</code> <p>Seconds without data before considered stale</p> <code>30</code>"},{"location":"api/monitoring/#qldata.DataQualityMonitor.record_message","title":"record_message","text":"<pre><code>record_message(\n    message_timestamp: datetime | None = None,\n) -&gt; None\n</code></pre> <p>Record receipt of a message.</p> <p>Parameters:</p> Name Type Description Default <code>message_timestamp</code> <code>datetime | None</code> <p>Timestamp from the message (for latency calc)</p> <code>None</code>"},{"location":"api/monitoring/#qldata.DataQualityMonitor.get_metrics","title":"get_metrics","text":"<pre><code>get_metrics() -&gt; dict\n</code></pre> <p>Get current quality metrics.</p> <p>Returns:</p> Type Description <code>dict</code> <p>Dictionary with quality metrics</p>"},{"location":"api/monitoring/#qldata.DataQualityMonitor.is_stale","title":"is_stale","text":"<pre><code>is_stale() -&gt; bool\n</code></pre> <p>Check if data is stale (no recent updates).</p> <p>Returns:</p> Type Description <code>bool</code> <p>True if no messages received within threshold</p>"},{"location":"api/monitoring/#qldata.DataQualityMonitor.get_health_status","title":"get_health_status","text":"<pre><code>get_health_status() -&gt; str\n</code></pre> <p>Get overall health status.</p> <p>Returns:</p> Type Description <code>str</code> <p>\"healthy\", \"degraded\", or \"unhealthy\"</p>"},{"location":"api/monitoring/#qldata.DataQualityMonitor.reset","title":"reset","text":"<pre><code>reset() -&gt; None\n</code></pre> <p>Reset all metrics.</p>"},{"location":"api/monitoring/#metrics-reference","title":"Metrics Reference","text":"<p>The <code>get_metrics()</code> method returns:</p> Metric Type Description <code>total_messages</code> <code>int</code> Total messages recorded <code>throughput</code> <code>float</code> Messages per second <code>latency_p50</code> <code>float</code> 50<sup>th</sup> percentile latency (ms) <code>latency_p95</code> <code>float</code> 95<sup>th</sup> percentile latency (ms) <code>latency_p99</code> <code>float</code> 99<sup>th</sup> percentile latency (ms) <code>is_stale</code> <code>bool</code> True if no recent messages <code>seconds_since_last_message</code> <code>float</code> Time since last message <code>window_start</code> <code>datetime</code> Start of measurement window"},{"location":"api/monitoring/#health-status","title":"Health Status","text":"<pre><code>status = monitor.get_health_status()\n# Returns: \"healthy\", \"degraded\", or \"unhealthy\"\n</code></pre> Status Condition <code>\"healthy\"</code> Recent data, low latency <code>\"degraded\"</code> High latency or low throughput <code>\"unhealthy\"</code> Stale data or no connection"},{"location":"api/monitoring/#alertmanager","title":"AlertManager","text":"<p>Callback-based alert system for production monitoring.</p>"},{"location":"api/monitoring/#basic-usage_1","title":"Basic Usage","text":"<pre><code>from qldata.monitoring import AlertManager\n\nalerts = AlertManager()\n\n# Register callbacks\nalerts.on_high_latency(lambda ms: print(f\"High latency: {ms}ms\"))\nalerts.on_stale_data(lambda: print(\"Data is stale!\"))\nalerts.on_low_throughput(lambda tps: print(f\"Low throughput: {tps}/s\"))\nalerts.on_connection_lost(lambda: print(\"Connection lost\"))\nalerts.on_reconnected(lambda n: print(f\"Reconnected after {n} attempts\"))\n</code></pre>"},{"location":"api/monitoring/#qldata.AlertManager","title":"AlertManager","text":"<pre><code>AlertManager()\n</code></pre> <p>Manage alerts for data quality issues.</p> <p>Provides callbacks for various alert conditions.</p>"},{"location":"api/monitoring/#qldata.AlertManager.on_high_latency","title":"on_high_latency","text":"<pre><code>on_high_latency(callback: Callable[[float], None]) -&gt; None\n</code></pre> <p>Register callback for high latency alerts.</p> <p>Parameters:</p> Name Type Description Default <code>callback</code> <code>Callable[[float], None]</code> <p>Function(latency_ms) to call when latency is high</p> required"},{"location":"api/monitoring/#qldata.AlertManager.on_stale_data","title":"on_stale_data","text":"<pre><code>on_stale_data(callback: Callable[[], None]) -&gt; None\n</code></pre> <p>Register callback for stale data alerts.</p> <p>Parameters:</p> Name Type Description Default <code>callback</code> <code>Callable[[], None]</code> <p>Function to call when data becomes stale</p> required"},{"location":"api/monitoring/#qldata.AlertManager.on_low_throughput","title":"on_low_throughput","text":"<pre><code>on_low_throughput(\n    callback: Callable[[float], None]\n) -&gt; None\n</code></pre> <p>Register callback for low throughput alerts.</p> <p>Parameters:</p> Name Type Description Default <code>callback</code> <code>Callable[[float], None]</code> <p>Function(throughput) to call when throughput is low</p> required"},{"location":"api/monitoring/#qldata.AlertManager.on_connection_lost","title":"on_connection_lost","text":"<pre><code>on_connection_lost(callback: Callable[[], None]) -&gt; None\n</code></pre> <p>Register callback for connection loss.</p> <p>Parameters:</p> Name Type Description Default <code>callback</code> <code>Callable[[], None]</code> <p>Function to call when connection is lost</p> required"},{"location":"api/monitoring/#qldata.AlertManager.on_reconnected","title":"on_reconnected","text":"<pre><code>on_reconnected(callback: Callable[[int], None]) -&gt; None\n</code></pre> <p>Register callback for successful reconnection.</p> <p>Parameters:</p> Name Type Description Default <code>callback</code> <code>Callable[[int], None]</code> <p>Function(attempts) to call when reconnected</p> required"},{"location":"api/monitoring/#qldata.AlertManager.check_latency","title":"check_latency","text":"<pre><code>check_latency(\n    latency_ms: float,\n    warning_threshold: float = 500,\n    error_threshold: float = 1000,\n) -&gt; Alert | None\n</code></pre> <p>Check latency and trigger alerts if needed.</p> <p>Parameters:</p> Name Type Description Default <code>latency_ms</code> <code>float</code> <p>Current latency in milliseconds</p> required <code>warning_threshold</code> <code>float</code> <p>Warning threshold in ms</p> <code>500</code> <code>error_threshold</code> <code>float</code> <p>Error threshold in ms</p> <code>1000</code> <p>Returns:</p> Type Description <code>Alert | None</code> <p>Alert if threshold exceeded, None otherwise</p>"},{"location":"api/monitoring/#qldata.AlertManager.check_stale_data","title":"check_stale_data","text":"<pre><code>check_stale_data(is_stale: bool) -&gt; Alert | None\n</code></pre> <p>Check if data is stale and trigger alerts.</p> <p>Parameters:</p> Name Type Description Default <code>is_stale</code> <code>bool</code> <p>Whether data is currently stale</p> required <p>Returns:</p> Type Description <code>Alert | None</code> <p>Alert if stale, None otherwise</p>"},{"location":"api/monitoring/#qldata.AlertManager.notify_connection_lost","title":"notify_connection_lost","text":"<pre><code>notify_connection_lost() -&gt; None\n</code></pre> <p>Notify that connection was lost.</p>"},{"location":"api/monitoring/#qldata.AlertManager.notify_reconnected","title":"notify_reconnected","text":"<pre><code>notify_reconnected(attempts: int) -&gt; None\n</code></pre> <p>Notify successful reconnection.</p> <p>Parameters:</p> Name Type Description Default <code>attempts</code> <code>int</code> <p>Number of attempts it took to reconnect</p> required"},{"location":"api/monitoring/#qldata.AlertManager.get_recent_alerts","title":"get_recent_alerts","text":"<pre><code>get_recent_alerts(limit: int = 10) -&gt; list[Alert]\n</code></pre> <p>Get recent alerts.</p> <p>Parameters:</p> Name Type Description Default <code>limit</code> <code>int</code> <p>Maximum number of alerts to return</p> <code>10</code> <p>Returns:</p> Type Description <code>list[Alert]</code> <p>List of recent alerts</p>"},{"location":"api/monitoring/#alert-callbacks","title":"Alert Callbacks","text":"Method Callback Signature Description <code>on_high_latency</code> <code>(latency_ms: float) -&gt; None</code> Latency exceeds threshold <code>on_stale_data</code> <code>() -&gt; None</code> No data received recently <code>on_low_throughput</code> <code>(tps: float) -&gt; None</code> Throughput below threshold <code>on_connection_lost</code> <code>() -&gt; None</code> Connection dropped <code>on_reconnected</code> <code>(attempts: int) -&gt; None</code> Successfully reconnected"},{"location":"api/monitoring/#checking-thresholds","title":"Checking Thresholds","text":"<pre><code>from qldata.monitoring import AlertManager\n\nalerts = AlertManager()\n\n# Check latency with thresholds\nalert = alerts.check_latency(\n    latency_ms=1200,\n    warning_threshold=500,   # Warning above 500ms\n    error_threshold=1000     # Error above 1000ms\n)\n\nif alert:\n    print(f\"Alert: {alert.severity} - {alert.message}\")\n</code></pre>"},{"location":"api/monitoring/#alert-history","title":"Alert History","text":"<pre><code># Get recent alerts\nrecent = alerts.get_recent_alerts(limit=10)\n\nfor alert in recent:\n    print(f\"[{alert.severity}] {alert.timestamp}: {alert.message}\")\n</code></pre>"},{"location":"api/monitoring/#integration-examples","title":"Integration Examples","text":""},{"location":"api/monitoring/#example-1-monitor-with-streaming","title":"Example 1: Monitor with Streaming","text":"<pre><code>import qldata as qd\nfrom qldata.monitoring import DataQualityMonitor, AlertManager\nimport time\n\n# Setup\nmonitor = DataQualityMonitor(stale_threshold_seconds=5)\nalerts = AlertManager()\n\ndef on_high_latency(ms):\n    print(f\"\u26a0\ufe0f High latency: {ms:.1f}ms\")\n\ndef on_stale():\n    print(\"\ud83d\udea8 Data is STALE!\")\n\nalerts.on_high_latency(on_high_latency)\nalerts.on_stale_data(on_stale)\n\ndef handle_data(df):\n    if df.empty:\n        return\n\n    # Record message\n    monitor.record_message(df.index[-1])\n\n    # Check thresholds\n    metrics = monitor.get_metrics()\n    if metrics[\"latency_p95\"]:\n        alerts.check_latency(metrics[\"latency_p95\"], warning_threshold=200)\n    alerts.check_stale_data(monitor.is_stale())\n\n# Start stream\nstream = qd.stream([\"BTCUSDT\"], source=\"binance\") \\\n    .resolution(\"tick\") \\\n    .on_data(handle_data) \\\n    .get(start=True)\n\n# Monitor health\nwhile True:\n    metrics = monitor.get_metrics()\n    print(f\"Health: {monitor.get_health_status()} | TPS: {metrics['throughput']:.1f}\")\n    time.sleep(10)\n</code></pre>"},{"location":"api/monitoring/#example-2-pagerduty-integration","title":"Example 2: PagerDuty Integration","text":"<pre><code>from qldata.monitoring import AlertManager\nimport requests\n\nPAGERDUTY_KEY = \"your-integration-key\"\n\ndef send_pagerduty(severity: str, message: str):\n    \"\"\"Send alert to PagerDuty.\"\"\"\n    requests.post(\n        \"https://events.pagerduty.com/v2/enqueue\",\n        json={\n            \"routing_key\": PAGERDUTY_KEY,\n            \"event_action\": \"trigger\",\n            \"payload\": {\n                \"summary\": message,\n                \"severity\": severity,\n                \"source\": \"qldata-monitor\"\n            }\n        }\n    )\n\nalerts = AlertManager()\nalerts.on_stale_data(lambda: send_pagerduty(\"critical\", \"Market data is stale\"))\nalerts.on_high_latency(lambda ms: send_pagerduty(\"warning\", f\"Latency: {ms}ms\"))\n</code></pre>"},{"location":"api/monitoring/#example-3-slack-integration","title":"Example 3: Slack Integration","text":"<pre><code>from qldata.monitoring import AlertManager\nimport requests\n\nSLACK_WEBHOOK = \"https://hooks.slack.com/services/...\"\n\ndef send_slack(message: str, emoji: str = \"\u26a0\ufe0f\"):\n    \"\"\"Send message to Slack.\"\"\"\n    requests.post(\n        SLACK_WEBHOOK,\n        json={\"text\": f\"{emoji} {message}\"}\n    )\n\nalerts = AlertManager()\nalerts.on_stale_data(lambda: send_slack(\"Data feed is stale!\", \"\ud83d\udea8\"))\nalerts.on_connection_lost(lambda: send_slack(\"Connection lost\", \"\u274c\"))\nalerts.on_reconnected(lambda n: send_slack(f\"Reconnected after {n} attempts\", \"\u2705\"))\n</code></pre>"},{"location":"api/monitoring/#example-4-prometheus-metrics","title":"Example 4: Prometheus Metrics","text":"<pre><code>from qldata.monitoring import DataQualityMonitor\nfrom prometheus_client import Gauge, start_http_server\n\n# Prometheus metrics\nlatency_p95 = Gauge(\"qldata_latency_p95_ms\", \"P95 latency in milliseconds\")\nthroughput = Gauge(\"qldata_throughput_tps\", \"Throughput in messages/second\")\nis_stale = Gauge(\"qldata_is_stale\", \"1 if data is stale, 0 otherwise\")\n\nmonitor = DataQualityMonitor()\n\ndef update_prometheus():\n    \"\"\"Update Prometheus metrics.\"\"\"\n    metrics = monitor.get_metrics()\n    latency_p95.set(metrics[\"latency_p95\"] or 0)\n    throughput.set(metrics[\"throughput\"])\n    is_stale.set(1 if metrics[\"is_stale\"] else 0)\n\n# Start Prometheus server\nstart_http_server(8000)\n\n# Update in background\nimport threading\nimport time\n\ndef metrics_loop():\n    while True:\n        update_prometheus()\n        time.sleep(5)\n\nthreading.Thread(target=metrics_loop, daemon=True).start()\n</code></pre>"},{"location":"api/monitoring/#example-5-logging-integration","title":"Example 5: Logging Integration","text":"<pre><code>import logging\nfrom qldata.monitoring import DataQualityMonitor, AlertManager\n\n# Configure logging\nlogging.basicConfig(\n    level=logging.INFO,\n    format=\"%(asctime)s [%(levelname)s] %(message)s\"\n)\nlogger = logging.getLogger(\"qldata.monitor\")\n\nalerts = AlertManager()\n\nalerts.on_high_latency(lambda ms: logger.warning(f\"High latency: {ms:.1f}ms\"))\nalerts.on_stale_data(lambda: logger.error(\"Data is stale!\"))\nalerts.on_connection_lost(lambda: logger.error(\"Connection lost\"))\nalerts.on_reconnected(lambda n: logger.info(f\"Reconnected after {n} attempts\"))\n\n# Periodic health logging\nmonitor = DataQualityMonitor()\n\ndef log_health():\n    metrics = monitor.get_metrics()\n    logger.info(\n        f\"Health: {monitor.get_health_status()} | \"\n        f\"TPS: {metrics['throughput']:.1f} | \"\n        f\"P95: {metrics['latency_p95']:.1f}ms\"\n    )\n</code></pre>"},{"location":"api/monitoring/#best-practices","title":"Best Practices","text":""},{"location":"api/monitoring/#1-set-appropriate-thresholds","title":"1. Set Appropriate Thresholds","text":"<pre><code># Crypto markets: tighter thresholds\nmonitor = DataQualityMonitor(stale_threshold_seconds=5)\nalerts.check_latency(ms, warning_threshold=100, error_threshold=500)\n\n# Lower-frequency data: relaxed thresholds\nmonitor = DataQualityMonitor(stale_threshold_seconds=60)\nalerts.check_latency(ms, warning_threshold=1000, error_threshold=5000)\n</code></pre>"},{"location":"api/monitoring/#2-avoid-alert-fatigue","title":"2. Avoid Alert Fatigue","text":"<pre><code># Debounce alerts\nfrom datetime import datetime, timedelta\n\nlast_alert = {}\n\ndef debounced_alert(alert_type: str, callback):\n    now = datetime.now()\n    if alert_type not in last_alert or now - last_alert[alert_type] &gt; timedelta(minutes=5):\n        last_alert[alert_type] = now\n        callback()\n</code></pre>"},{"location":"api/monitoring/#3-include-context-in-alerts","title":"3. Include Context in Alerts","text":"<pre><code>def on_stale(symbol: str, last_time: datetime):\n    send_alert(f\"Symbol {symbol} stale since {last_time}\")\n</code></pre>"},{"location":"api/monitoring/#4-monitor-multiple-data-feeds","title":"4. Monitor Multiple Data Feeds","text":"<pre><code>monitors = {\n    \"BTCUSDT\": DataQualityMonitor(),\n    \"ETHUSDT\": DataQualityMonitor(),\n}\n\ndef handle_data(df):\n    symbol = df[\"symbol\"].iloc[0]\n    monitors[symbol].record_message(df.index[-1])\n</code></pre>"},{"location":"api/monitoring/#see-also","title":"See Also","text":"<ul> <li>Streaming API - Integrate with streams</li> <li>Resilience - Connection management</li> <li>Cookbook - Production examples</li> </ul>"},{"location":"api/reference-data/","title":"Reference Data API","text":"<p>Functions for accessing symbol metadata, exchange information, and market discovery.</p>"},{"location":"api/reference-data/#symbol-information","title":"Symbol Information","text":""},{"location":"api/reference-data/#get_symbol_info","title":"<code>get_symbol_info()</code>","text":"<p>Get detailed metadata about a trading symbol.</p> <pre><code>import qldata as qd\n\ninfo = qd.get_symbol_info(\"BTCUSDT\", source=\"binance\", category=\"spot\")\n\nprint(f\"Symbol: {info.symbol}\")\nprint(f\"Base/Quote: {info.base_asset}/{info.quote_asset}\")\nprint(f\"Status: {info.status}\")\nprint(f\"Is Active: {info.is_active}\")\n</code></pre> <p>Get complete symbol metadata and trading specifications.</p> <p>Parameters:</p> Name Type Description Default <code>symbol</code> <code>str</code> <p>Trading pair symbol (e.g., \"BTCUSDT\")</p> required <code>source</code> <code>str</code> <p>Exchange (\"binance\", \"bybit\")</p> required <code>category</code> <code>str | None</code> <p>Market category (spot, usdm, linear, etc.)</p> <code>None</code> <p>Returns:</p> Type Description <code>SymbolInfo</code> <p>SymbolInfo with complete trading specifications</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; info = get_symbol_info(\"BTCUSDT\", source=\"binance\", category=\"spot\")\n&gt;&gt;&gt; print(info.filters.tick_size, info.filters.min_notional)\n&gt;&gt;&gt; if info.validate_price(Decimal(\"50000.5\")):\n...     print(\"Price is valid\")\n</code></pre>"},{"location":"api/reference-data/#symbolinfo-model","title":"SymbolInfo Model","text":"<p>The returned <code>SymbolInfo</code> object contains:</p>"},{"location":"api/reference-data/#qldata.SymbolInfo","title":"SymbolInfo  <code>dataclass</code>","text":"<pre><code>SymbolInfo(\n    symbol: str,\n    base_asset: str,\n    quote_asset: str,\n    status: str = \"TRADING\",\n    filters: SymbolFilters = SymbolFilters(),\n    trading_hours: TradingHours = TradingHours(),\n    contract_type: str | None = None,\n    delivery_date: str | None = None,\n    margin_asset: str | None = None,\n    maker_fee: Decimal | None = None,\n    taker_fee: Decimal | None = None,\n    fee_tier: str | None = None,\n    source: str | None = None,\n    last_updated: str | None = None,\n)\n</code></pre> <p>Complete symbol metadata and trading specifications.</p> <p>Attributes:</p> Name Type Description <code>symbol</code> <code>str</code> <p>Trading pair symbol</p> <code>base_asset</code> <code>str</code> <p>Base currency (e.g., \"BTC\" in \"BTCUSDT\")</p> <code>quote_asset</code> <code>str</code> <p>Quote currency (e.g., \"USDT\" in \"BTCUSDT\")</p> <code>status</code> <code>str</code> <p>Trading status (\"TRADING\", \"HALT\", \"BREAK\", etc.)</p> <code>filters</code> <code>SymbolFilters</code> <p>Price/quantity filters</p> <code>trading_hours</code> <code>TradingHours</code> <p>Market hours</p> <code>contract_type</code> <code>str | None</code> <p>For futures (\"PERPETUAL\", \"CURRENT_QUARTER\", etc.)</p> <code>delivery_date</code> <code>str | None</code> <p>For futures contracts</p> <code>margin_asset</code> <code>str | None</code> <p>Asset used for margin</p> <code>fee_tier</code> <code>str | None</code> <p>Fee tier or maker/taker fees</p> <code>source</code> <code>str | None</code> <p>Data source</p>"},{"location":"api/reference-data/#qldata.SymbolInfo.symbol","title":"symbol  <code>instance-attribute</code>","text":"<pre><code>symbol: str\n</code></pre>"},{"location":"api/reference-data/#qldata.SymbolInfo.base_asset","title":"base_asset  <code>instance-attribute</code>","text":"<pre><code>base_asset: str\n</code></pre>"},{"location":"api/reference-data/#qldata.SymbolInfo.quote_asset","title":"quote_asset  <code>instance-attribute</code>","text":"<pre><code>quote_asset: str\n</code></pre>"},{"location":"api/reference-data/#qldata.SymbolInfo.status","title":"status  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>status: str = 'TRADING'\n</code></pre>"},{"location":"api/reference-data/#qldata.SymbolInfo.is_active","title":"is_active  <code>property</code>","text":"<pre><code>is_active: bool\n</code></pre> <p>Check if symbol is actively trading.</p>"},{"location":"api/reference-data/#qldata.SymbolInfo.is_spot","title":"is_spot  <code>property</code>","text":"<pre><code>is_spot: bool\n</code></pre> <p>Check if this is a spot market.</p>"},{"location":"api/reference-data/#qldata.SymbolInfo.is_perpetual","title":"is_perpetual  <code>property</code>","text":"<pre><code>is_perpetual: bool\n</code></pre> <p>Check if this is a perpetual contract.</p>"},{"location":"api/reference-data/#qldata.SymbolInfo.contract_type","title":"contract_type  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>contract_type: str | None = None\n</code></pre>"},{"location":"api/reference-data/#qldata.SymbolInfo.margin_asset","title":"margin_asset  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>margin_asset: str | None = None\n</code></pre>"},{"location":"api/reference-data/#qldata.SymbolInfo.filters","title":"filters  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>filters: SymbolFilters = field(\n    default_factory=SymbolFilters\n)\n</code></pre>"},{"location":"api/reference-data/#qldata.SymbolInfo.validate_price","title":"validate_price","text":"<pre><code>validate_price(price: Decimal) -&gt; bool\n</code></pre> <p>Check if price meets filter requirements.</p> <p>Parameters:</p> Name Type Description Default <code>price</code> <code>Decimal</code> <p>Price to validate</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if valid, False otherwise</p>"},{"location":"api/reference-data/#qldata.SymbolInfo.validate_quantity","title":"validate_quantity","text":"<pre><code>validate_quantity(quantity: Decimal) -&gt; bool\n</code></pre> <p>Check if quantity meets filter requirements.</p> <p>Parameters:</p> Name Type Description Default <code>quantity</code> <code>Decimal</code> <p>Quantity to validate</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if valid, False otherwise</p>"},{"location":"api/reference-data/#trading-filters","title":"Trading Filters","text":"<p>The <code>filters</code> attribute contains trading constraints:</p> <pre><code>info = qd.get_symbol_info(\"BTCUSDT\", source=\"binance\", category=\"spot\")\n\nprint(f\"Tick Size: {info.filters.tick_size}\")      # Price increment\nprint(f\"Step Size: {info.filters.step_size}\")      # Quantity increment\nprint(f\"Min Quantity: {info.filters.min_quantity}\") # Minimum order size\nprint(f\"Min Notional: {info.filters.min_notional}\") # Minimum order value\n</code></pre> Field Type Description <code>tick_size</code> <code>Decimal</code> Minimum price increment <code>step_size</code> <code>Decimal</code> Minimum quantity increment <code>min_quantity</code> <code>Decimal</code> Minimum order quantity <code>max_quantity</code> <code>Decimal</code> Maximum order quantity <code>min_notional</code> <code>Decimal</code> Minimum order value (price \u00d7 quantity)"},{"location":"api/reference-data/#pricequantity-validation","title":"Price/Quantity Validation","text":"<p>Validate prices and quantities against exchange rules:</p> <pre><code>from decimal import Decimal\n\ninfo = qd.get_symbol_info(\"BTCUSDT\", source=\"binance\", category=\"spot\")\n\n# Validate a price\nprice = Decimal(\"50000.123\")\nif info.validate_price(price):\n    print(f\"Price {price} is valid\")\nelse:\n    print(f\"Price {price} is invalid (tick size: {info.filters.tick_size})\")\n\n# Validate a quantity\nqty = Decimal(\"0.00123\")\nif info.validate_quantity(qty):\n    print(f\"Quantity {qty} is valid\")\nelse:\n    print(f\"Quantity {qty} is invalid (step size: {info.filters.step_size})\")\n</code></pre>"},{"location":"api/reference-data/#exchange-information","title":"Exchange Information","text":""},{"location":"api/reference-data/#get_exchange_info","title":"<code>get_exchange_info()</code>","text":"<p>Get exchange-level metadata.</p> <pre><code>import qldata as qd\n\nexchange = qd.get_exchange_info(source=\"binance\")\n\nprint(f\"Exchange: {exchange.exchange}\")\nprint(f\"Timezone: {exchange.timezone}\")\nprint(f\"Status: {exchange.status}\")\nprint(f\"Total Symbols: {exchange.symbol_count}\")\n</code></pre> <p>Get exchange-wide information and available symbols.</p> <p>Parameters:</p> Name Type Description Default <code>source</code> <code>str</code> <p>Exchange (\"binance\", \"bybit\")</p> required <code>category</code> <code>str | None</code> <p>Market category (optional)</p> <code>None</code> <p>Returns:</p> Type Description <code>ExchangeInfo</code> <p>ExchangeInfo with exchange metadata</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; info = get_exchange_info(source=\"binance\")\n&gt;&gt;&gt; print(f\"Exchange: {info.exchange}, Symbols: {info.symbol_count}\")\n</code></pre>"},{"location":"api/reference-data/#symbol-discovery","title":"Symbol Discovery","text":""},{"location":"api/reference-data/#list_symbols","title":"<code>list_symbols()</code>","text":"<p>List available trading symbols with optional filtering.</p> <pre><code>import qldata as qd\n\n# All active USDT pairs\nusdt_pairs = qd.list_symbols(\n    source=\"binance\",\n    category=\"spot\",\n    quote_asset=\"USDT\",\n    active_only=True\n)\nprint(f\"Found {len(usdt_pairs)} USDT pairs\")\nprint(f\"First 10: {usdt_pairs[:10]}\")\n\n# All BTC pairs\nbtc_base = qd.list_symbols(\n    source=\"binance\",\n    category=\"spot\",\n    base_asset=\"BTC\"\n)\nprint(f\"BTC pairs: {btc_base}\")\n\n# All perpetual contracts\nperpetuals = qd.list_symbols(\n    source=\"binance\",\n    category=\"usdm\",\n    active_only=True\n)\nprint(f\"Found {len(perpetuals)} perpetual contracts\")\n</code></pre> <p>List all available trading symbols on an exchange.</p> <p>Parameters:</p> Name Type Description Default <code>source</code> <code>str</code> <p>Exchange (\"binance\", \"bybit\")</p> required <code>category</code> <code>str | None</code> <p>Market category (optional)</p> <code>None</code> <code>active_only</code> <code>bool</code> <p>Only return actively trading symbols</p> <code>True</code> <code>base_asset</code> <code>str | None</code> <p>Filter by base asset (e.g., \"BTC\")</p> <code>None</code> <code>quote_asset</code> <code>str | None</code> <p>Filter by quote asset (e.g., \"USDT\")</p> <code>None</code> <p>Returns:</p> Type Description <code>list[str]</code> <p>List of symbol names</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # Get all USDT pairs\n&gt;&gt;&gt; symbols = list_symbols(source=\"binance\", category=\"spot\", quote_asset=\"USDT\")\n&gt;&gt;&gt; print(len(symbols), \"USDT pairs\")\n</code></pre> <pre><code>&gt;&gt;&gt; # Get all BTC pairs that are actively trading\n&gt;&gt;&gt; btc_pairs = list_symbols(source=\"binance\", category=\"spot\",  base_asset=\"BTC\", active_only=True)\n</code></pre>"},{"location":"api/reference-data/#funding-rates","title":"Funding Rates","text":""},{"location":"api/reference-data/#current_funding_rate","title":"<code>current_funding_rate()</code>","text":"<p>Get the current funding rate for perpetual contracts.</p> <pre><code>import qldata as qd\n\n# Binance USDM perpetual\nrate = qd.current_funding_rate(\"BTCUSDT\", source=\"binance\", category=\"usdm\")\nprint(f\"Current funding rate: {rate:.6f}\")\nprint(f\"Annualized: {rate * 3 * 365 * 100:.2f}%\")  # 8-hour funding = 3x daily\n\n# Bybit linear perpetual\nrate = qd.current_funding_rate(\"BTCUSDT\", source=\"bybit\", category=\"linear\")\nprint(f\"Bybit funding rate: {rate:.6f}\")\n</code></pre> <p>Get current funding rate for a perpetual contract.</p> <p>Convenience function for quick funding rate access.</p> <p>Parameters:</p> Name Type Description Default <code>symbol</code> <code>str</code> <p>Trading pair symbol (e.g., \"BTCUSDT\")</p> required <code>source</code> <code>str</code> <p>Exchange (\"binance\", \"bybit\")</p> <code>'binance'</code> <code>category</code> <code>str</code> <p>Futures category (\"usdm\", \"coinm\", \"linear\", \"inverse\")</p> <code>'usdm'</code> <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>Dictionary with funding rate information</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; rate = qd.current_funding_rate(\"BTCUSDT\", source=\"binance\", category=\"usdm\")\n&gt;&gt;&gt; print(f\"Rate: {rate['fundingRate']}\")\n</code></pre> <pre><code>&gt;&gt;&gt; # Compare funding across exchanges\n&gt;&gt;&gt; binance_rate = qd.current_funding_rate(\"BTCUSDT\", source=\"binance\", category=\"usdm\")\n&gt;&gt;&gt; bybit_rate = qd.current_funding_rate(\"BTCUSDT\", source=\"bybit\", category=\"linear\")\n</code></pre>"},{"location":"api/reference-data/#examples","title":"Examples","text":""},{"location":"api/reference-data/#example-1-symbol-metadata-report","title":"Example 1: Symbol Metadata Report","text":"<pre><code>import qldata as qd\n\ndef print_symbol_report(symbol: str, source: str, category: str):\n    \"\"\"Print detailed symbol information.\"\"\"\n    info = qd.get_symbol_info(symbol, source=source, category=category)\n\n    print(f\"\\n{'='*50}\")\n    print(f\"Symbol Report: {info.symbol}\")\n    print(f\"{'='*50}\")\n\n    print(f\"\\nBasic Info:\")\n    print(f\"  Base Asset: {info.base_asset}\")\n    print(f\"  Quote Asset: {info.quote_asset}\")\n    print(f\"  Status: {info.status}\")\n    print(f\"  Active: {info.is_active}\")\n\n    print(f\"\\nMarket Type:\")\n    print(f\"  Is Spot: {info.is_spot}\")\n    print(f\"  Is Perpetual: {info.is_perpetual}\")\n    if info.is_perpetual:\n        print(f\"  Contract Type: {info.contract_type}\")\n        print(f\"  Margin Asset: {info.margin_asset}\")\n\n    print(f\"\\nTrading Filters:\")\n    print(f\"  Tick Size: {info.filters.tick_size}\")\n    print(f\"  Step Size: {info.filters.step_size}\")\n    print(f\"  Min Quantity: {info.filters.min_quantity}\")\n    print(f\"  Min Notional: {info.filters.min_notional}\")\n\n# Generate reports\nprint_symbol_report(\"BTCUSDT\", \"binance\", \"spot\")\nprint_symbol_report(\"BTCUSDT\", \"binance\", \"usdm\")\nprint_symbol_report(\"BTCUSDT\", \"bybit\", \"linear\")\n</code></pre>"},{"location":"api/reference-data/#example-2-find-high-volume-pairs","title":"Example 2: Find High-Volume Pairs","text":"<pre><code>import qldata as qd\n\n# Get all USDT pairs\nsymbols = qd.list_symbols(\n    source=\"binance\",\n    category=\"spot\",\n    quote_asset=\"USDT\",\n    active_only=True\n)\n\n# Fetch 24h volume for each (simplified example)\nprint(f\"Analyzing {len(symbols)} symbols...\")\n\n# In practice, you'd batch this\nfor symbol in symbols[:10]:\n    try:\n        info = qd.get_symbol_info(symbol, source=\"binance\", category=\"spot\")\n        print(f\"{symbol}: {info.status}\")\n    except Exception as e:\n        print(f\"{symbol}: Error - {e}\")\n</code></pre>"},{"location":"api/reference-data/#example-3-compare-exchange-listings","title":"Example 3: Compare Exchange Listings","text":"<pre><code>import qldata as qd\n\n# Get symbols from both exchanges\nbinance_symbols = set(qd.list_symbols(\n    source=\"binance\",\n    category=\"spot\",\n    quote_asset=\"USDT\",\n    active_only=True\n))\n\nbybit_symbols = set(qd.list_symbols(\n    source=\"bybit\",\n    category=\"spot\",\n    active_only=True\n))\n\n# Find common and unique\ncommon = binance_symbols &amp; bybit_symbols\nonly_binance = binance_symbols - bybit_symbols\nonly_bybit = bybit_symbols - binance_symbols\n\nprint(f\"Common symbols: {len(common)}\")\nprint(f\"Binance only: {len(only_binance)}\")\nprint(f\"Bybit only: {len(only_bybit)}\")\n</code></pre>"},{"location":"api/reference-data/#example-4-funding-rate-arbitrage-check","title":"Example 4: Funding Rate Arbitrage Check","text":"<pre><code>import qldata as qd\n\nsymbols = [\"BTCUSDT\", \"ETHUSDT\", \"SOLUSDT\", \"BNBUSDT\"]\n\nprint(\"Funding Rate Comparison\")\nprint(\"-\" * 50)\nprint(f\"{'Symbol':&lt;12} {'Binance':&gt;12} {'Bybit':&gt;12} {'Diff':&gt;10}\")\nprint(\"-\" * 50)\n\nfor symbol in symbols:\n    try:\n        binance_rate = qd.current_funding_rate(symbol, source=\"binance\", category=\"usdm\")\n        bybit_rate = qd.current_funding_rate(symbol, source=\"bybit\", category=\"linear\")\n        diff = (binance_rate - bybit_rate) * 100\n\n        print(f\"{symbol:&lt;12} {binance_rate*100:&gt;11.4f}% {bybit_rate*100:&gt;11.4f}% {diff:&gt;9.4f}%\")\n    except Exception as e:\n        print(f\"{symbol:&lt;12} Error: {e}\")\n\nprint(\"-\" * 50)\n</code></pre>"},{"location":"api/reference-data/#see-also","title":"See Also","text":"<ul> <li>Historical Data - Fetch OHLCV data</li> <li>Models Reference - Data model details</li> <li>Binance Cookbook - Exchange-specific examples</li> </ul>"},{"location":"api/resilience/","title":"Resilience API","text":"<p>Production-grade resilience features for WebSocket connections and data streaming.</p>"},{"location":"api/resilience/#overview","title":"Overview","text":"<p>qldata provides several resilience components:</p> <ul> <li>ReconnectionManager - Auto-reconnect with exponential backoff</li> <li>HeartbeatMonitor - Connection health monitoring</li> <li>MessageDeduplicator - Duplicate message detection</li> <li>RateLimitManager - API rate limit handling</li> <li>SequenceTracker - Missing message detection</li> <li>TimeSyncManager - Clock synchronization</li> </ul> <pre><code>from qldata.resilience import (\n    ReconnectionManager,\n    HeartbeatMonitor,\n    MessageDeduplicator,\n)\n</code></pre>"},{"location":"api/resilience/#reconnectionmanager","title":"ReconnectionManager","text":"<p>Manages automatic reconnection with exponential backoff.</p>"},{"location":"api/resilience/#qldata.ReconnectionManager","title":"ReconnectionManager","text":"<pre><code>ReconnectionManager(\n    max_retries: int = 10,\n    base_delay: float = 1.0,\n    max_delay: float = 60.0,\n    backoff_factor: float = 2.0,\n)\n</code></pre> <p>Manages automatic reconnection with exponential backoff.</p> <p>Handles reconnection attempts with configurable backoff and max retries.</p> <p>Parameters:</p> Name Type Description Default <code>max_retries</code> <code>int</code> <p>Maximum reconnection attempts (0 = infinite)</p> <code>10</code> <code>base_delay</code> <code>float</code> <p>Initial delay in seconds</p> <code>1.0</code> <code>max_delay</code> <code>float</code> <p>Maximum delay between retries</p> <code>60.0</code> <code>backoff_factor</code> <code>float</code> <p>Exponential backoff multiplier</p> <code>2.0</code>"},{"location":"api/resilience/#qldata.ReconnectionManager.reset","title":"reset","text":"<pre><code>reset() -&gt; None\n</code></pre> <p>Reset attempt counter.</p>"},{"location":"api/resilience/#configuration","title":"Configuration","text":"Parameter Type Default Description <code>max_attempts</code> <code>int</code> <code>10</code> Maximum reconnection attempts <code>initial_delay</code> <code>float</code> <code>1.0</code> Initial delay in seconds <code>max_delay</code> <code>float</code> <code>60.0</code> Maximum delay in seconds <code>backoff_factor</code> <code>float</code> <code>2.0</code> Exponential backoff multiplier"},{"location":"api/resilience/#usage","title":"Usage","text":"<pre><code>from qldata.resilience import ReconnectionManager\n\nmanager = ReconnectionManager(\n    max_attempts=10,\n    initial_delay=1.0,\n    max_delay=60.0,\n    backoff_factor=2.0\n)\n\nwhile manager.should_reconnect():\n    try:\n        connect()\n        manager.record_success()\n        break\n    except ConnectionError:\n        manager.record_failure()\n        delay = manager.get_delay()\n        print(f\"Reconnecting in {delay:.1f}s...\")\n        time.sleep(delay)\n</code></pre>"},{"location":"api/resilience/#heartbeatmonitor","title":"HeartbeatMonitor","text":"<p>Monitors connection health via periodic heartbeat checks.</p>"},{"location":"api/resilience/#qldata.HeartbeatMonitor","title":"HeartbeatMonitor","text":"<pre><code>HeartbeatMonitor(\n    timeout_seconds: float = 30.0,\n    ping_interval: float = 10.0,\n)\n</code></pre> <p>Monitors connection health via heartbeats.</p> <p>Detects stale connections and triggers reconnection if needed.</p> <p>Parameters:</p> Name Type Description Default <code>timeout_seconds</code> <code>float</code> <p>Seconds without heartbeat before timeout</p> <code>30.0</code> <code>ping_interval</code> <code>float</code> <p>Seconds between ping messages</p> <code>10.0</code>"},{"location":"api/resilience/#qldata.HeartbeatMonitor.record_heartbeat","title":"record_heartbeat","text":"<pre><code>record_heartbeat() -&gt; None\n</code></pre> <p>Record a heartbeat (pong received).</p>"},{"location":"api/resilience/#qldata.HeartbeatMonitor.is_alive","title":"is_alive","text":"<pre><code>is_alive() -&gt; bool\n</code></pre> <p>Check if connection is alive.</p> <p>Returns:</p> Type Description <code>bool</code> <p>True if heartbeat within timeout, False otherwise</p>"},{"location":"api/resilience/#configuration_1","title":"Configuration","text":"Parameter Type Default Description <code>interval</code> <code>float</code> <code>30.0</code> Heartbeat check interval (seconds) <code>timeout</code> <code>float</code> <code>10.0</code> Heartbeat timeout (seconds)"},{"location":"api/resilience/#usage_1","title":"Usage","text":"<pre><code>from qldata.resilience import HeartbeatMonitor\n\nmonitor = HeartbeatMonitor(interval=30.0, timeout=10.0)\n\ndef on_pong():\n    monitor.record_heartbeat()\n\n# Check health\nif not monitor.is_alive():\n    print(f\"Connection dead. Last heartbeat: {monitor.get_last_heartbeat()}\")\n    reconnect()\n</code></pre>"},{"location":"api/resilience/#messagededuplicator","title":"MessageDeduplicator","text":"<p>Detects and filters duplicate messages.</p>"},{"location":"api/resilience/#qldata.MessageDeduplicator","title":"MessageDeduplicator","text":"<pre><code>MessageDeduplicator(buffer_size: int = 1000)\n</code></pre> <p>Deduplicates messages using sequence numbers.</p> <p>Prevents processing duplicate messages during reconnections.</p> <p>Parameters:</p> Name Type Description Default <code>buffer_size</code> <code>int</code> <p>Number of recent sequence numbers to track</p> <code>1000</code>"},{"location":"api/resilience/#qldata.MessageDeduplicator.is_duplicate","title":"is_duplicate","text":"<pre><code>is_duplicate(sequence: int) -&gt; bool\n</code></pre> <p>Check if sequence number has been seen.</p> <p>Parameters:</p> Name Type Description Default <code>sequence</code> <code>int</code> <p>Sequence number</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if duplicate, False otherwise</p>"},{"location":"api/resilience/#qldata.MessageDeduplicator.record","title":"record","text":"<pre><code>record(sequence: int) -&gt; bool\n</code></pre> <p>Record a sequence number.</p> <p>Parameters:</p> Name Type Description Default <code>sequence</code> <code>int</code> <p>Sequence number</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if new (not duplicate), False if duplicate</p>"},{"location":"api/resilience/#configuration_2","title":"Configuration","text":"Parameter Type Default Description <code>window_size</code> <code>int</code> <code>1000</code> Number of recent IDs to track <code>ttl_seconds</code> <code>float</code> <code>60.0</code> Time-to-live for tracked IDs"},{"location":"api/resilience/#usage_2","title":"Usage","text":"<pre><code>from qldata.resilience import MessageDeduplicator\n\ndedup = MessageDeduplicator(window_size=1000, ttl_seconds=60)\n\ndef handle_message(msg):\n    msg_id = msg[\"id\"]\n\n    if dedup.is_duplicate(msg_id):\n        return  # Skip duplicate\n\n    dedup.record(msg_id)\n    process_message(msg)\n</code></pre>"},{"location":"api/resilience/#ratelimitmanager","title":"RateLimitManager","text":"<p>Manages API rate limits to prevent throttling.</p>"},{"location":"api/resilience/#usage_3","title":"Usage","text":"<pre><code>from qldata.resilience import RateLimitManager\n\n# Configure limits (e.g., Binance: 1200 requests/minute)\nlimiter = RateLimitManager(\n    requests_per_minute=1200,\n    burst_limit=100\n)\n\nasync def make_request():\n    await limiter.acquire()  # Wait if rate limited\n    response = await api.call()\n    return response\n</code></pre>"},{"location":"api/resilience/#exchange-defaults","title":"Exchange Defaults","text":"Exchange Requests/Minute WebSocket Connections Binance 1200 5 per IP Bybit 120 20 per IP"},{"location":"api/resilience/#sequencetracker","title":"SequenceTracker","text":"<p>Tracks message sequence numbers to detect gaps.</p>"},{"location":"api/resilience/#usage_4","title":"Usage","text":"<pre><code>from qldata.resilience import SequenceTracker\n\ntracker = SequenceTracker()\n\ndef handle_message(msg):\n    seq = msg[\"sequence\"]\n\n    if tracker.check(seq):\n        process_message(msg)\n    else:\n        gaps = tracker.get_gaps()\n        logger.warning(f\"Sequence gaps detected: {gaps}\")\n        request_replay(gaps)  # Request missing messages\n</code></pre>"},{"location":"api/resilience/#timesyncmanager","title":"TimeSyncManager","text":"<p>Synchronizes local clock with exchange server time.</p>"},{"location":"api/resilience/#usage_5","title":"Usage","text":"<pre><code>from qldata.resilience import TimeSyncManager\n\nsync = TimeSyncManager()\n\n# Sync with exchange\nawait sync.sync_with_exchange(\"binance\")\n\n# Get offset\noffset_ms = sync.get_offset()\nprint(f\"Clock offset: {offset_ms}ms\")\n\n# Convert server time to local\nlocal_time = sync.to_local_time(server_timestamp)\n</code></pre>"},{"location":"api/resilience/#integrated-resilience","title":"Integrated Resilience","text":""},{"location":"api/resilience/#default-configuration","title":"Default Configuration","text":"<p>Streaming uses resilience by default:</p> <pre><code>import qldata as qd\n\n# Resilience enabled by default\nstream = qd.stream([\"BTCUSDT\"], source=\"binance\") \\\n    .resolution(\"tick\") \\\n    .on_data(handler) \\\n    .get(start=True)\n\n# Includes:\n# - Auto-reconnect with exponential backoff\n# - Rate limit management\n# - Sequence tracking\n# - Heartbeat monitoring\n</code></pre>"},{"location":"api/resilience/#custom-configuration","title":"Custom Configuration","text":"<pre><code>from qldata.resilience import ResilienceConfig\n\nconfig = ResilienceConfig(\n    auto_reconnect=True,\n    max_reconnect_attempts=10,\n    reconnect_delay=1.0,\n    reconnect_delay_max=60.0,\n    heartbeat_interval=30.0,\n    rate_limit_enabled=True,\n    sequence_tracking=True,\n    time_sync_enabled=True\n)\n\nstream = qd.stream([\"BTCUSDT\"], source=\"binance\") \\\n    .resolution(\"tick\") \\\n    .on_data(handler) \\\n    .resilience(config) \\\n    .get(start=True)\n</code></pre>"},{"location":"api/resilience/#disable-resilience","title":"Disable Resilience","text":"<p>For testing or specific use cases:</p> <pre><code>stream = qd.stream([\"BTCUSDT\"], source=\"binance\") \\\n    .resolution(\"tick\") \\\n    .on_data(handler) \\\n    .get(start=True, resilience=False)\n</code></pre>"},{"location":"api/resilience/#connection-state-management","title":"Connection State Management","text":"<p>Track connection state transitions:</p> <pre><code>from qldata.resilience import ConnectionState, ConnectionStateManager\n\nstate_mgr = ConnectionStateManager()\n\n# Register callbacks\nstate_mgr.on_connected(lambda: print(\"Connected!\"))\nstate_mgr.on_reconnecting(lambda: print(\"Reconnecting...\"))\nstate_mgr.on_disconnected(lambda: print(\"Disconnected\"))\nstate_mgr.on_failed(lambda: print(\"Connection failed\"))\n\n# Manual state transitions\nstate_mgr.transition(ConnectionState.CONNECTING)\nstate_mgr.transition(ConnectionState.CONNECTED)\n\n# Check current state\nprint(f\"State: {state_mgr.state.value}\")\nprint(f\"Time in state: {state_mgr.time_in_state:.1f}s\")\n</code></pre>"},{"location":"api/resilience/#connection-states","title":"Connection States","text":"<pre><code>stateDiagram-v2\n    [*] --&gt; DISCONNECTED\n    DISCONNECTED --&gt; CONNECTING\n    CONNECTING --&gt; CONNECTED\n    CONNECTING --&gt; FAILED\n    CONNECTED --&gt; RECONNECTING\n    RECONNECTING --&gt; CONNECTED\n    RECONNECTING --&gt; FAILED\n    FAILED --&gt; CONNECTING\n    CONNECTED --&gt; DISCONNECTED</code></pre> State Description <code>DISCONNECTED</code> Not connected <code>CONNECTING</code> Establishing connection <code>CONNECTED</code> Successfully connected <code>RECONNECTING</code> Attempting to reconnect <code>FAILED</code> Connection permanently failed"},{"location":"api/resilience/#examples","title":"Examples","text":""},{"location":"api/resilience/#example-1-custom-reconnection-logic","title":"Example 1: Custom Reconnection Logic","text":"<pre><code>from qldata.resilience import ReconnectionManager\nimport asyncio\n\nasync def connect_with_retry():\n    manager = ReconnectionManager(max_attempts=5)\n\n    while manager.should_reconnect():\n        try:\n            ws = await websockets.connect(\"wss://...\")\n            manager.record_success()\n            return ws\n        except Exception as e:\n            manager.record_failure()\n            delay = manager.get_delay()\n            print(f\"Connection failed: {e}. Retry in {delay:.1f}s\")\n            await asyncio.sleep(delay)\n\n    raise ConnectionError(\"Max reconnection attempts exceeded\")\n</code></pre>"},{"location":"api/resilience/#example-2-duplicate-detection","title":"Example 2: Duplicate Detection","text":"<pre><code>from qldata.resilience import MessageDeduplicator\nimport qldata as qd\n\ndedup = MessageDeduplicator(window_size=5000)\nprocessed = 0\nduplicates = 0\n\ndef handle_data(df):\n    global processed, duplicates\n\n    for _, row in df.iterrows():\n        trade_id = row[\"trade_id\"]\n\n        if dedup.is_duplicate(trade_id):\n            duplicates += 1\n            continue\n\n        dedup.record(trade_id)\n        processed += 1\n        # Process unique trade...\n\nstream = qd.stream([\"BTCUSDT\"], source=\"binance\") \\\n    .resolution(\"tick\") \\\n    .on_data(handle_data) \\\n    .get(start=True)\n\n# Later: check stats\nprint(f\"Processed: {processed}, Duplicates: {duplicates}\")\n</code></pre>"},{"location":"api/resilience/#example-3-sequence-gap-detection","title":"Example 3: Sequence Gap Detection","text":"<pre><code>from qldata.resilience import SequenceTracker\nimport logging\n\nlogger = logging.getLogger(__name__)\ntracker = SequenceTracker()\n\ndef handle_message(msg):\n    seq = msg.get(\"u\")  # Update ID\n\n    if not tracker.check(seq):\n        gaps = tracker.get_gaps()\n        logger.error(f\"Sequence gap! Missing: {gaps}\")\n\n        # Request snapshot to recover\n        request_order_book_snapshot()\n        tracker.reset()\n        return\n\n    process_update(msg)\n</code></pre>"},{"location":"api/resilience/#example-4-production-resilience-setup","title":"Example 4: Production Resilience Setup","text":"<pre><code>import qldata as qd\nfrom qldata.resilience import ConnectionStateManager, ResilienceConfig\nfrom qldata.monitoring import DataQualityMonitor, AlertManager\nimport logging\n\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\n# State management\nstate = ConnectionStateManager()\nstate.on_connected(lambda: logger.info(\"Connected\"))\nstate.on_reconnecting(lambda: logger.warning(\"Reconnecting...\"))\nstate.on_failed(lambda: logger.error(\"Connection failed!\"))\n\n# Monitoring\nmonitor = DataQualityMonitor(stale_threshold_seconds=10)\nalerts = AlertManager()\nalerts.on_stale_data(lambda: logger.error(\"Data stale!\"))\n\n# Resilience config\nconfig = ResilienceConfig(\n    auto_reconnect=True,\n    max_reconnect_attempts=20,\n    reconnect_delay=1.0,\n    reconnect_delay_max=120.0,\n)\n\ndef handle_data(df):\n    if df.empty:\n        return\n    monitor.record_message(df.index[-1])\n    alerts.check_stale_data(monitor.is_stale())\n    # Process data...\n\nstream = qd.stream([\"BTCUSDT\"], source=\"binance\") \\\n    .resolution(\"tick\") \\\n    .on_data(handle_data) \\\n    .resilience(config) \\\n    .get(start=True)\n</code></pre>"},{"location":"api/resilience/#best-practices","title":"Best Practices","text":""},{"location":"api/resilience/#1-always-use-resilience-in-production","title":"1. Always Use Resilience in Production","text":"<pre><code># \u2713 Production - resilience enabled (default)\nstream = qd.stream(...).get(start=True)\n\n# \u2717 Testing only - resilience disabled\nstream = qd.stream(...).get(start=True, resilience=False)\n</code></pre>"},{"location":"api/resilience/#2-monitor-connection-health","title":"2. Monitor Connection Health","text":"<pre><code># Periodically log health\nwhile True:\n    if state.state == ConnectionState.CONNECTED:\n        logger.info(f\"Connected for {state.time_in_state:.0f}s\")\n    time.sleep(60)\n</code></pre>"},{"location":"api/resilience/#3-handle-sequence-gaps","title":"3. Handle Sequence Gaps","text":"<pre><code># Don't just log - take action\nif not tracker.check(seq):\n    # Option 1: Request snapshot\n    request_snapshot()\n\n    # Option 2: Skip to latest\n    tracker.reset()\n</code></pre>"},{"location":"api/resilience/#4-configure-appropriate-timeouts","title":"4. Configure Appropriate Timeouts","text":"<pre><code># High-frequency data\nconfig = ResilienceConfig(\n    heartbeat_interval=10.0,  # Check every 10s\n    reconnect_delay=0.5,      # Fast reconnect\n)\n\n# Lower-frequency data\nconfig = ResilienceConfig(\n    heartbeat_interval=60.0,  # Check every 60s\n    reconnect_delay=5.0,      # Slower reconnect\n)\n</code></pre>"},{"location":"api/resilience/#see-also","title":"See Also","text":"<ul> <li>Streaming API - Live data streaming</li> <li>Monitoring - Data quality monitoring</li> <li>Configuration - Global settings</li> </ul>"},{"location":"api/streaming/","title":"Streaming API","text":"<p>The <code>qd.stream()</code> function provides real-time market data streaming with built-in resilience features.</p>"},{"location":"api/streaming/#basic-usage","title":"Basic Usage","text":"<pre><code>import qldata as qd\nimport time\n\ndef handle_data(df):\n    \"\"\"Process incoming tick data.\"\"\"\n    if not df.empty:\n        latest = df.iloc[-1]\n        print(f\"[{latest['symbol']}] Price: {latest['price']}\")\n\n# Create and start the stream\nstream = qd.stream([\"BTCUSDT\", \"ETHUSDT\"], source=\"binance\", category=\"spot\") \\\n    .resolution(\"tick\") \\\n    .on_data(handle_data) \\\n    .get(start=True)\n\n# Keep running (Ctrl+C to stop)\ntry:\n    while True:\n        time.sleep(1)\nexcept KeyboardInterrupt:\n    stream.stop()\n</code></pre>"},{"location":"api/streaming/#function-signature","title":"Function Signature","text":""},{"location":"api/streaming/#qldata.stream","title":"stream  <code>module-attribute</code>","text":"<pre><code>stream = StreamingAPI()\n</code></pre>"},{"location":"api/streaming/#query-builder-methods","title":"Query Builder Methods","text":""},{"location":"api/streaming/#resolutiontimeframe","title":"<code>.resolution(timeframe)</code>","text":"<p>Set the stream data type.</p> <pre><code># Raw tick/trade data\n.resolution(\"tick\")\n\n# Aggregated bars (where supported)\n.resolution(\"1m\")\n</code></pre> <p>Supported Resolutions:</p> Resolution Description Data Type <code>\"tick\"</code> Individual trades Trade/tick data <code>\"1m\"</code> 1-minute bars OHLCV bars"},{"location":"api/streaming/#on_datacallback","title":"<code>.on_data(callback)</code>","text":"<p>Register a callback for incoming data.</p> <pre><code>def handle_data(df):\n    \"\"\"\n    Args:\n        df: pandas DataFrame with new data\n    \"\"\"\n    print(f\"Received {len(df)} rows\")\n\n.on_data(handle_data)\n</code></pre> <p>Callback Signature:</p> <pre><code>def callback(df: pandas.DataFrame) -&gt; None:\n    ...\n</code></pre> <p>The DataFrame contains:</p> Tick DataBar Data (1m) Column Type Description <code>price</code> float Trade price <code>quantity</code> float Trade quantity <code>symbol</code> str Trading pair <code>side</code> str <code>\"buy\"</code> or <code>\"sell\"</code> <code>trade_id</code> int Unique trade ID Column Type Description <code>open</code> float Opening price <code>high</code> float Highest price <code>low</code> float Lowest price <code>close</code> float Closing price <code>volume</code> float Trading volume <code>symbol</code> str Trading pair"},{"location":"api/streaming/#on_errorcallback","title":"<code>.on_error(callback)</code>","text":"<p>Register a callback for errors.</p> <pre><code>def handle_error(error):\n    \"\"\"\n    Args:\n        error: Exception that occurred\n    \"\"\"\n    print(f\"Stream error: {error}\")\n\n.on_error(handle_error)\n</code></pre>"},{"location":"api/streaming/#on_closecallback","title":"<code>.on_close(callback)</code>","text":"<p>Register a callback for stream close.</p> <pre><code>def handle_close():\n    \"\"\"Called when stream closes.\"\"\"\n    print(\"Stream closed\")\n\n.on_close(handle_close)\n</code></pre>"},{"location":"api/streaming/#on_reconnectcallback","title":"<code>.on_reconnect(callback)</code>","text":"<p>Register a callback for reconnection events.</p> <pre><code>def handle_reconnect(attempt):\n    \"\"\"\n    Args:\n        attempt: Reconnection attempt number\n    \"\"\"\n    print(f\"Reconnecting... (attempt {attempt})\")\n\n.on_reconnect(handle_reconnect)\n</code></pre>"},{"location":"api/streaming/#getstarttrue","title":"<code>.get(start=True)</code>","text":"<p>Create the stream session.</p> <pre><code># Auto-start the stream\nstream = query.get(start=True)\n\n# Create without starting (manual control)\nstream = query.get(start=False)\nstream.start()  # Start manually later\n</code></pre> <p>Parameters:</p> Parameter Type Default Description <code>start</code> <code>bool</code> <code>True</code> Auto-start the stream <p>Returns: <code>StreamSession</code> object</p>"},{"location":"api/streaming/#streamsession-class","title":"StreamSession Class","text":""},{"location":"api/streaming/#qldata.StreamSession","title":"StreamSession","text":"<pre><code>StreamSession(\n    adapter: Any,\n    symbols: list[str],\n    stream_type: str,\n    interval: str | None,\n    on_data: Callable[[DataFrame], None] | None = None,\n    on_error: Callable[[Exception], None] | None = None,\n    on_close: Callable[[], None] | None = None,\n    *,\n    window_seconds: float | None = None,\n    max_rows: int | None = None,\n    resample_to: str | None = None,\n    clean_fn: (\n        Callable[[DataFrame], DataFrame] | None\n    ) = None,\n    resilience: ResilienceConfig | bool = True,\n    source: str = \"binance\",\n    rate_limiter: RateLimitManager | None = None,\n    sequence_tracker: (\n        dict[str, SequenceTracker] | None\n    ) = None,\n    journal: Any | None = None\n)\n</code></pre> <p>               Bases: <code>AbstractContextManager['StreamSession']</code></p> <p>Manage a live streaming session using adapter WebSocket methods.</p>"},{"location":"api/streaming/#qldata.StreamSession.start","title":"start","text":"<pre><code>start() -&gt; StreamSession\n</code></pre> <p>Start streaming.</p>"},{"location":"api/streaming/#qldata.StreamSession.stop","title":"stop","text":"<pre><code>stop() -&gt; None\n</code></pre> <p>Stop streaming.</p>"},{"location":"api/streaming/#resilience-features","title":"Resilience Features","text":""},{"location":"api/streaming/#auto-reconnect","title":"Auto-Reconnect","text":"<p>Streams automatically reconnect on connection loss:</p> <pre><code>stream = qd.stream([\"BTCUSDT\"], source=\"binance\") \\\n    .resolution(\"tick\") \\\n    .on_data(handler) \\\n    .on_reconnect(lambda n: print(f\"Reconnect attempt {n}\")) \\\n    .get(start=True)\n\n# Stream will auto-reconnect with exponential backoff\n</code></pre>"},{"location":"api/streaming/#rate-limit-management","title":"Rate Limit Management","text":"<p>Built-in rate limiting prevents API throttling:</p> <pre><code># Even with many symbols, rate limits are respected\nstream = qd.stream(\n    [\"BTCUSDT\", \"ETHUSDT\", \"SOLUSDT\", \"BNBUSDT\", \"XRPUSDT\"],\n    source=\"binance\"\n) \\\n    .resolution(\"tick\") \\\n    .on_data(handler) \\\n    .get(start=True)\n</code></pre>"},{"location":"api/streaming/#sequence-tracking","title":"Sequence Tracking","text":"<p>Detects and logs missed messages:</p> <pre><code># Sequence gaps are automatically logged\n# Enable verbose logging to see them:\nimport logging\nlogging.basicConfig(level=logging.DEBUG)\n</code></pre>"},{"location":"api/streaming/#heartbeat-monitoring","title":"Heartbeat Monitoring","text":"<p>Connection health is monitored:</p> <pre><code>stream = qd.stream([\"BTCUSDT\"], source=\"binance\") \\\n    .resolution(\"tick\") \\\n    .on_data(handler) \\\n    .get(start=True)\n\n# Check if stream is healthy\nif stream.is_running():\n    print(\"Stream is healthy\")\n</code></pre>"},{"location":"api/streaming/#advanced-configuration","title":"Advanced Configuration","text":""},{"location":"api/streaming/#resilience-options","title":"Resilience Options","text":"<pre><code>from qldata.resilience import ResilienceConfig\n\nconfig = ResilienceConfig(\n    auto_reconnect=True,           # Enable auto-reconnect\n    max_reconnect_attempts=10,     # Max attempts before giving up\n    reconnect_delay=1.0,           # Initial delay (seconds)\n    reconnect_delay_max=60.0,      # Max delay (seconds)\n    heartbeat_interval=30.0,       # Heartbeat check interval\n    rate_limit_enabled=True        # Enable rate limiting\n)\n\nstream = qd.stream([\"BTCUSDT\"], source=\"binance\") \\\n    .resolution(\"tick\") \\\n    .on_data(handler) \\\n    .resilience(config) \\\n    .get(start=True)\n</code></pre>"},{"location":"api/streaming/#disable-resilience","title":"Disable Resilience","text":"<p>For testing or specific use cases:</p> <pre><code>stream = qd.stream([\"BTCUSDT\"], source=\"binance\") \\\n    .resolution(\"tick\") \\\n    .on_data(handler) \\\n    .get(start=True, resilience=False)\n</code></pre>"},{"location":"api/streaming/#monitoring-integration","title":"Monitoring Integration","text":""},{"location":"api/streaming/#dataqualitymonitor","title":"DataQualityMonitor","text":"<p>Monitor stream health and latency:</p> <pre><code>from qldata.monitoring import DataQualityMonitor\n\nmonitor = DataQualityMonitor(stale_threshold_seconds=10)\n\ndef handle_data(df):\n    if not df.empty:\n        # Record message for monitoring\n        monitor.record_message(df.index[-1])\n\n        # Process data\n        process_tick(df)\n\nstream = qd.stream([\"BTCUSDT\"], source=\"binance\") \\\n    .resolution(\"tick\") \\\n    .on_data(handle_data) \\\n    .get(start=True)\n\n# Periodically check metrics\nmetrics = monitor.get_metrics()\nprint(f\"Throughput: {metrics['throughput']:.1f}/s\")\nprint(f\"Latency P95: {metrics['latency_p95']:.1f}ms\")\nprint(f\"Is Stale: {metrics['is_stale']}\")\n</code></pre>"},{"location":"api/streaming/#alertmanager","title":"AlertManager","text":"<p>Set up production alerts:</p> <pre><code>from qldata.monitoring import AlertManager\n\nalerts = AlertManager()\n\n# Configure callbacks\nalerts.on_high_latency(lambda ms: send_pagerduty(f\"High latency: {ms}ms\"))\nalerts.on_stale_data(lambda: send_slack(\"Data is stale!\"))\nalerts.on_connection_lost(lambda: send_alert(\"Connection lost\"))\nalerts.on_reconnected(lambda n: log_info(f\"Reconnected after {n} attempts\"))\n</code></pre>"},{"location":"api/streaming/#examples","title":"Examples","text":""},{"location":"api/streaming/#example-1-simple-price-tracker","title":"Example 1: Simple Price Tracker","text":"<pre><code>import qldata as qd\nimport time\n\ndef print_price(df):\n    if not df.empty:\n        for _, row in df.iterrows():\n            print(f\"{row['symbol']}: ${row['price']:,.2f}\")\n\nstream = qd.stream([\"BTCUSDT\", \"ETHUSDT\"], source=\"binance\") \\\n    .resolution(\"tick\") \\\n    .on_data(print_price) \\\n    .get(start=True)\n\ntry:\n    while True:\n        time.sleep(1)\nexcept KeyboardInterrupt:\n    stream.stop()\n</code></pre>"},{"location":"api/streaming/#example-2-volume-weighted-average-price-vwap","title":"Example 2: Volume-Weighted Average Price (VWAP)","text":"<pre><code>import qldata as qd\nimport time\n\n# Track VWAP\nvwap_data = {\"total_value\": 0, \"total_volume\": 0}\n\ndef update_vwap(df):\n    if df.empty:\n        return\n\n    for _, row in df.iterrows():\n        vwap_data[\"total_value\"] += row[\"price\"] * row[\"quantity\"]\n        vwap_data[\"total_volume\"] += row[\"quantity\"]\n\n    if vwap_data[\"total_volume\"] &gt; 0:\n        vwap = vwap_data[\"total_value\"] / vwap_data[\"total_volume\"]\n        print(f\"VWAP: ${vwap:,.2f}\")\n\nstream = qd.stream([\"BTCUSDT\"], source=\"binance\") \\\n    .resolution(\"tick\") \\\n    .on_data(update_vwap) \\\n    .get(start=True)\n\ntime.sleep(60)  # Run for 60 seconds\nstream.stop()\n</code></pre>"},{"location":"api/streaming/#example-3-multi-symbol-price-comparison","title":"Example 3: Multi-Symbol Price Comparison","text":"<pre><code>import qldata as qd\nimport time\nfrom collections import defaultdict\n\n# Track latest prices\nprices = defaultdict(float)\n\ndef update_prices(df):\n    if df.empty:\n        return\n\n    for _, row in df.iterrows():\n        prices[row[\"symbol\"]] = row[\"price\"]\n\n    # Print comparison\n    if \"BTCUSDT\" in prices and \"ETHUSDT\" in prices:\n        ratio = prices[\"BTCUSDT\"] / prices[\"ETHUSDT\"]\n        print(f\"BTC/ETH ratio: {ratio:.2f}\")\n\nstream = qd.stream([\"BTCUSDT\", \"ETHUSDT\"], source=\"binance\") \\\n    .resolution(\"tick\") \\\n    .on_data(update_prices) \\\n    .get(start=True)\n\ntry:\n    while True:\n        time.sleep(1)\nexcept KeyboardInterrupt:\n    stream.stop()\n</code></pre>"},{"location":"api/streaming/#example-4-production-stream-with-monitoring","title":"Example 4: Production Stream with Monitoring","text":"<pre><code>import qldata as qd\nfrom qldata.monitoring import DataQualityMonitor, AlertManager\nimport time\nimport logging\n\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\n# Setup monitoring\nmonitor = DataQualityMonitor(stale_threshold_seconds=5)\nalerts = AlertManager()\n\nalerts.on_stale_data(lambda: logger.warning(\"Data is stale!\"))\nalerts.on_high_latency(lambda ms: logger.warning(f\"High latency: {ms}ms\"))\n\ndef handle_data(df):\n    if df.empty:\n        return\n\n    # Record for monitoring\n    monitor.record_message(df.index[-1])\n\n    # Check for issues\n    metrics = monitor.get_metrics()\n    if metrics[\"latency_p95\"]:\n        alerts.check_latency(metrics[\"latency_p95\"])\n    alerts.check_stale_data(monitor.is_stale())\n\n    # Process data\n    logger.info(f\"Received {len(df)} ticks\")\n\ndef handle_error(e):\n    logger.error(f\"Stream error: {e}\")\n\ndef handle_reconnect(attempt):\n    logger.info(f\"Reconnecting (attempt {attempt})\")\n\nstream = qd.stream([\"BTCUSDT\"], source=\"binance\") \\\n    .resolution(\"tick\") \\\n    .on_data(handle_data) \\\n    .on_error(handle_error) \\\n    .on_reconnect(handle_reconnect) \\\n    .get(start=True)\n\ntry:\n    while True:\n        # Log metrics every 30 seconds\n        time.sleep(30)\n        metrics = monitor.get_metrics()\n        logger.info(\n            f\"Health: {monitor.get_health_status()} | \"\n            f\"Throughput: {metrics['throughput']:.1f}/s | \"\n            f\"P95: {metrics['latency_p95']:.1f}ms\"\n        )\nexcept KeyboardInterrupt:\n    logger.info(\"Shutting down...\")\n    stream.stop()\n</code></pre>"},{"location":"api/streaming/#see-also","title":"See Also","text":"<ul> <li>Resilience Features - Detailed resilience options</li> <li>Monitoring &amp; Alerts - Production monitoring</li> <li>Historical Data - Batch data fetching</li> </ul>"},{"location":"api/transforms/","title":"Data Transforms API","text":"<p>Functions for cleaning, filling, and resampling market data.</p>"},{"location":"api/transforms/#overview","title":"Overview","text":"<p>qldata provides two ways to use transforms:</p> <ol> <li>Fluent API - Chain transforms in queries</li> <li>Standalone functions - Apply to any DataFrame</li> </ol> <pre><code>import qldata as qd\n\n# Fluent API (recommended)\ndf = qd.data(\"BTCUSDT\", source=\"binance\") \\\n    .last(30) \\\n    .resolution(\"1h\") \\\n    .clean() \\\n    .fill_forward() \\\n    .resample(\"4h\") \\\n    .get()\n\n# Standalone functions\nfrom qldata import remove_duplicates, fill_forward, resample\ndf = remove_duplicates(raw_df)\ndf = fill_forward(df)\ndf = resample(df, \"4h\")\n</code></pre>"},{"location":"api/transforms/#cleaning-functions","title":"Cleaning Functions","text":""},{"location":"api/transforms/#clean","title":"<code>clean()</code>","text":"<p>Apply adaptive data cleaning based on data type.</p> <pre><code># Basic cleaning\n.clean()\n\n# With options\n.clean(\n    remove_invalid_prices=True,\n    validate_ohlc=True,\n    remove_outliers=True\n)\n</code></pre> <p>Cleaning Steps:</p> <ol> <li>Sort by timestamp index</li> <li>Remove duplicate timestamps</li> <li>Drop rows with NaN in core columns (adaptive)</li> <li>Optional: Remove invalid prices</li> <li>Optional: Validate OHLC relationships</li> <li>Optional: Remove statistical outliers</li> </ol>"},{"location":"api/transforms/#remove_duplicatesdf","title":"<code>remove_duplicates(df)</code>","text":"<p>Remove rows with duplicate timestamps.</p> <pre><code>from qldata import remove_duplicates\n\n# Keep first occurrence\ndf = remove_duplicates(raw_df)\n\n# Keep last occurrence\ndf = remove_duplicates(raw_df, keep=\"last\")\n</code></pre> <p>Remove duplicate timestamps.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>DataFrame</code> <p>DataFrame with timestamp index</p> required <code>keep</code> <code>str</code> <p>Which duplicate to keep ('first', 'last', or 'mean')</p> <code>'last'</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>DataFrame with duplicates removed</p> Example <p>data = pd.DataFrame({ ...     'timestamp': ['2024-01-01', '2024-01-01', '2024-01-02'], ...     'close': [100, 101, 102] ... }).set_index('timestamp') clean = remove_duplicates(data, keep='last') len(clean) 2</p>"},{"location":"api/transforms/#remove_invalid_pricesdf","title":"<code>remove_invalid_prices(df)</code>","text":"<p>Remove rows with zero or negative prices.</p> <pre><code>from qldata import remove_invalid_prices\n\ndf = remove_invalid_prices(raw_df)\n\n# Specify price columns\ndf = remove_invalid_prices(raw_df, columns=[\"open\", \"high\", \"low\", \"close\"])\n</code></pre> <p>Remove rows with zero or negative prices.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>DataFrame</code> <p>DataFrame with price data</p> required <code>price_columns</code> <code>list[str] | None</code> <p>Columns to check (auto-detects OHLC if None)</p> <code>None</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>DataFrame with invalid prices removed</p> Example <p>df = pd.DataFrame({ ...     'open': [100, 0, -5, 102], ...     'high': [101, 101, 104, 103], ...     'close': [100.5, 100, 103, 102.5] ... }) clean = remove_invalid_prices(df) len(clean) 2</p>"},{"location":"api/transforms/#remove_outliersdf","title":"<code>remove_outliers(df)</code>","text":"<p>Remove statistical outliers using z-score.</p> <pre><code>from qldata import remove_outliers\n\n# Default: Remove &gt; 3 standard deviations\ndf = remove_outliers(raw_df)\n\n# Custom threshold\ndf = remove_outliers(raw_df, sigma=2.5)\n\n# Specific columns only\ndf = remove_outliers(raw_df, columns=[\"close\", \"volume\"])\n</code></pre> <p>Remove outliers from data.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>DataFrame</code> <p>DataFrame with data</p> required <code>columns</code> <code>list[str] | str | None</code> <p>Columns to check (default: auto-detect all numeric columns)</p> <code>None</code> <code>method</code> <code>str</code> <p>Detection method ('zscore' or 'iqr')</p> <code>'iqr'</code> <code>**kwargs</code> <code>Any</code> <p>Additional arguments for detection method</p> <code>{}</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>DataFrame with outliers removed</p> Example <p>data = pd.DataFrame({ ...     'close': [100, 101, 102, 200, 103, 104], ...     'volume': [1000, 1100, 1050, 1200, 1150, 1080] ... }) clean = remove_outliers(data, columns='close', method='iqr') len(clean) 5</p>"},{"location":"api/transforms/#fill-functions","title":"Fill Functions","text":""},{"location":"api/transforms/#fill_forwarddf","title":"<code>fill_forward(df)</code>","text":"<p>Forward fill missing values (use last known value).</p> <pre><code>from qldata import fill_forward\n\ndf = fill_forward(raw_df)\n\n# Or in fluent API\ndf = qd.data(...).clean().fill_forward().get()\n</code></pre> <p>Forward fill missing values.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>DataFrame</code> <p>DataFrame with data</p> required <code>columns</code> <code>list[str] | None</code> <p>Columns to fill (default: all columns)</p> <code>None</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>DataFrame with gaps filled</p>"},{"location":"api/transforms/#fill_backwarddf","title":"<code>fill_backward(df)</code>","text":"<p>Backward fill missing values (use next known value).</p> <pre><code>from qldata import fill_backward\n\ndf = fill_backward(raw_df)\n</code></pre> <p>Backward fill missing values.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>DataFrame</code> <p>DataFrame with data</p> required <code>columns</code> <code>list[str] | None</code> <p>Columns to fill (default: all columns)</p> <code>None</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>DataFrame with gaps filled</p>"},{"location":"api/transforms/#fill_interpolatedf","title":"<code>fill_interpolate(df)</code>","text":"<p>Fill missing values using interpolation.</p> <pre><code>from qldata import fill_interpolate\n\n# Linear interpolation (default)\ndf = fill_interpolate(raw_df)\n\n# Time-weighted interpolation\ndf = fill_interpolate(raw_df, method=\"time\")\n\n# Polynomial interpolation\ndf = fill_interpolate(raw_df, method=\"polynomial\", order=2)\n</code></pre> <p>Interpolate missing values.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>DataFrame</code> <p>DataFrame with data</p> required <code>columns</code> <code>list[str] | None</code> <p>Columns to fill (default: numeric columns)</p> <code>None</code> <code>method</code> <code>str</code> <p>Interpolation method (default: 'linear')</p> <code>'linear'</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>DataFrame with gaps filled</p> <p>Interpolation Methods:</p> Method Description <code>\"linear\"</code> Linear interpolation between points <code>\"time\"</code> Time-weighted linear interpolation <code>\"index\"</code> Index-based interpolation <code>\"polynomial\"</code> Polynomial interpolation (requires <code>order</code>) <code>\"spline\"</code> Spline interpolation (requires <code>order</code>)"},{"location":"api/transforms/#resample-functions","title":"Resample Functions","text":""},{"location":"api/transforms/#resampledf-timeframe","title":"<code>resample(df, timeframe)</code>","text":"<p>Resample bars to a different timeframe.</p> <pre><code>from qldata import resample\n\n# Resample 1m to 1h\nhourly = resample(minute_df, \"1h\")\n\n# Resample 1h to 4h\nfour_hour = resample(hourly_df, \"4h\")\n</code></pre> <p>Resampling transforms.</p> <p>Upsampling Not Supported</p> <p>You can only resample to larger timeframes (1m \u2192 1h). Resampling to smaller timeframes is not supported.</p>"},{"location":"api/transforms/#qldata.resample.aggregate_bars","title":"aggregate_bars","text":"<pre><code>aggregate_bars(bars: DataFrame) -&gt; dict[str, Any]\n</code></pre> <p>Aggregate multiple bars into a single bar.</p> <p>Used for resampling bars to higher timeframes.</p> <p>Parameters:</p> Name Type Description Default <code>bars</code> <code>DataFrame</code> <p>DataFrame with OHLCV bar data</p> required <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>Dictionary with aggregated OHLCV values</p>"},{"location":"api/transforms/#qldata.resample.aggregate_ohlcv","title":"aggregate_ohlcv","text":"<pre><code>aggregate_ohlcv(ticks: DataFrame) -&gt; dict[str, Any]\n</code></pre> <p>Aggregate ticks into OHLCV values.</p> <p>Parameters:</p> Name Type Description Default <code>ticks</code> <code>DataFrame</code> <p>DataFrame with tick data (must have 'price' and 'volume' columns)</p> required <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>Dictionary with OHLCV values</p> Example <p>ticks = pd.DataFrame({'price': [100, 101, 99, 102], 'volume': [1000, 2000, 1500, 1000]}) ohlcv = aggregate_ohlcv(ticks) ohlcv['open'], ohlcv['high'], ohlcv['low'], ohlcv['close'] (100, 102, 99, 102)</p>"},{"location":"api/transforms/#qldata.resample.aggregate_vwap","title":"aggregate_vwap","text":"<pre><code>aggregate_vwap(ticks: DataFrame) -&gt; float\n</code></pre> <p>Calculate volume-weighted average price.</p> <p>Parameters:</p> Name Type Description Default <code>ticks</code> <code>DataFrame</code> <p>DataFrame with tick data (must have 'price' and 'volume' columns)</p> required <p>Returns:</p> Type Description <code>float</code> <p>VWAP value</p> Example <p>ticks = pd.DataFrame({'price': [100, 101, 99], 'volume': [1000, 2000, 1500]}) vwap = aggregate_vwap(ticks) round(vwap, 2) 100.11</p>"},{"location":"api/transforms/#qldata.resample.resample_bars","title":"resample_bars","text":"<pre><code>resample_bars(\n    bars: DataFrame,\n    from_timeframe: Timeframe,\n    to_timeframe: Timeframe,\n) -&gt; DataFrame\n</code></pre> <p>Resample bars to different timeframe.</p> <p>Parameters:</p> Name Type Description Default <code>bars</code> <code>DataFrame</code> <p>DataFrame with OHLCV bar data (indexed by timestamp)</p> required <code>from_timeframe</code> <code>Timeframe</code> <p>Current timeframe</p> required <code>to_timeframe</code> <code>Timeframe</code> <p>Target timeframe</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>DataFrame with resampled OHLCV data</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If trying to resample to lower timeframe</p> Example <p>bars_1m = pd.DataFrame({ ...     'timestamp': pd.date_range('2024-01-01', periods=60, freq='1min'), ...     'open': [100 + i*0.1 for i in range(60)], ...     'high': [100 + i*0.1 + 0.5 for i in range(60)], ...     'low': [100 + i*0.1 - 0.3 for i in range(60)], ...     'close': [100 + i*0.1 + 0.2 for i in range(60)], ...     'volume': [1000] * 60 ... }).set_index('timestamp') bars_1h = resample_bars(bars_1m, Timeframe.MIN_1, Timeframe.HOUR_1) len(bars_1h) 1</p>"},{"location":"api/transforms/#qldata.resample.ticks_to_bars","title":"ticks_to_bars","text":"<pre><code>ticks_to_bars(\n    ticks: DataFrame,\n    timeframe: Timeframe,\n    symbol: str | None = None,\n) -&gt; DataFrame\n</code></pre> <p>Convert tick data to bars.</p> <p>Parameters:</p> Name Type Description Default <code>ticks</code> <code>DataFrame</code> <p>DataFrame with tick data (indexed by timestamp, with 'price' and 'volume')</p> required <code>timeframe</code> <code>Timeframe</code> <p>Target bar timeframe</p> required <code>symbol</code> <code>str | None</code> <p>Optional symbol (if not in DataFrame)</p> <code>None</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>DataFrame with OHLCV bar data</p> Example <p>ticks = pd.DataFrame({ ...     'timestamp': pd.date_range('2024-01-01', periods=1000, freq='1s'), ...     'price': [100 + i*0.01 for i in range(1000)], ...     'volume': [1000] * 1000 ... }).set_index('timestamp') bars = ticks_to_bars(ticks, Timeframe.MIN_1) len(bars) 17</p>"},{"location":"api/transforms/#resample_barsdf-timeframe","title":"<code>resample_bars(df, timeframe)</code>","text":"<p>OHLCV-aware resampling with proper aggregation.</p> <pre><code>from qldata import resample_bars\n\n# Properly aggregates OHLCV:\n# - open: first value\n# - high: max value\n# - low: min value\n# - close: last value\n# - volume: sum\nhourly = resample_bars(minute_df, \"1h\")\n</code></pre> <p>Resample bars to different timeframe.</p> <p>Parameters:</p> Name Type Description Default <code>bars</code> <code>DataFrame</code> <p>DataFrame with OHLCV bar data (indexed by timestamp)</p> required <code>from_timeframe</code> <code>Timeframe</code> <p>Current timeframe</p> required <code>to_timeframe</code> <code>Timeframe</code> <p>Target timeframe</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>DataFrame with resampled OHLCV data</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If trying to resample to lower timeframe</p> Example <p>bars_1m = pd.DataFrame({ ...     'timestamp': pd.date_range('2024-01-01', periods=60, freq='1min'), ...     'open': [100 + i*0.1 for i in range(60)], ...     'high': [100 + i*0.1 + 0.5 for i in range(60)], ...     'low': [100 + i*0.1 - 0.3 for i in range(60)], ...     'close': [100 + i*0.1 + 0.2 for i in range(60)], ...     'volume': [1000] * 60 ... }).set_index('timestamp') bars_1h = resample_bars(bars_1m, Timeframe.MIN_1, Timeframe.HOUR_1) len(bars_1h) 1</p>"},{"location":"api/transforms/#ticks_to_barsdf-timeframe","title":"<code>ticks_to_bars(df, timeframe)</code>","text":"<p>Convert tick/trade data to OHLCV bars.</p> <pre><code>from qldata import ticks_to_bars\n\n# Convert ticks to 1-minute bars\nbars = ticks_to_bars(tick_df, \"1m\")\n\n# Convert to hourly\nbars = ticks_to_bars(tick_df, \"1h\")\n</code></pre> <p>Convert tick data to bars.</p> <p>Parameters:</p> Name Type Description Default <code>ticks</code> <code>DataFrame</code> <p>DataFrame with tick data (indexed by timestamp, with 'price' and 'volume')</p> required <code>timeframe</code> <code>Timeframe</code> <p>Target bar timeframe</p> required <code>symbol</code> <code>str | None</code> <p>Optional symbol (if not in DataFrame)</p> <code>None</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>DataFrame with OHLCV bar data</p> Example <p>ticks = pd.DataFrame({ ...     'timestamp': pd.date_range('2024-01-01', periods=1000, freq='1s'), ...     'price': [100 + i*0.01 for i in range(1000)], ...     'volume': [1000] * 1000 ... }).set_index('timestamp') bars = ticks_to_bars(ticks, Timeframe.MIN_1) len(bars) 17</p>"},{"location":"api/transforms/#transform-pipeline","title":"Transform Pipeline","text":"<p>For complex transform workflows, use <code>TransformPipeline</code>:</p> <pre><code>from qldata import TransformPipeline, remove_duplicates, remove_outliers, fill_forward\n\n# Create a reusable pipeline\npipeline = TransformPipeline() \\\n    .add(remove_duplicates) \\\n    .add(remove_outliers, sigma=3) \\\n    .add(fill_forward)\n\n# Apply to any DataFrame\nclean_df = pipeline.apply(raw_df)\n\n# Apply to multiple DataFrames\nfor symbol, df in data.items():\n    data[symbol] = pipeline.apply(df)\n</code></pre>"},{"location":"api/transforms/#qldata.TransformPipeline","title":"TransformPipeline","text":"<pre><code>TransformPipeline(name: str = 'pipeline')\n</code></pre> <p>Pipeline for composing multiple data transforms.</p> <p>Allows chaining transforms and applying them in sequence.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Pipeline name for logging</p> <code>'pipeline'</code>"},{"location":"api/transforms/#qldata.TransformPipeline.add","title":"add","text":"<pre><code>add(\n    transform: Callable[[DataFrame], DataFrame],\n    name: str | None = None,\n) -&gt; TransformPipeline\n</code></pre> <p>Add a transform to the pipeline.</p> <p>Parameters:</p> Name Type Description Default <code>transform</code> <code>Callable[[DataFrame], DataFrame]</code> <p>Function that takes DataFrame and returns DataFrame</p> required <code>name</code> <code>str | None</code> <p>Optional name for logging</p> <code>None</code> <p>Returns:</p> Type Description <code>TransformPipeline</code> <p>Self for method chaining</p>"},{"location":"api/transforms/#examples","title":"Examples","text":""},{"location":"api/transforms/#example-1-basic-cleaning-pipeline","title":"Example 1: Basic Cleaning Pipeline","text":"<pre><code>import qldata as qd\n\n# Fetch and clean data\ndf = qd.data(\"BTCUSDT\", source=\"binance\") \\\n    .last(30) \\\n    .resolution(\"1h\") \\\n    .clean() \\\n    .get()\n\nprint(f\"Cleaned data: {len(df)} bars\")\nprint(f\"Missing values: {df.isna().sum().sum()}\")\n</code></pre>"},{"location":"api/transforms/#example-2-aggressive-cleaning","title":"Example 2: Aggressive Cleaning","text":"<pre><code>import qldata as qd\n\n# Production-grade cleaning\ndf = qd.data(\"BTCUSDT\", source=\"binance\") \\\n    .last(30) \\\n    .resolution(\"1h\") \\\n    .clean(\n        remove_invalid_prices=True,  # Remove zero/negative\n        validate_ohlc=True,          # Check high &gt;= low, etc.\n        remove_outliers=True         # Remove &gt; 3\u03c3 outliers\n    ) \\\n    .fill_forward() \\\n    .get()\n\n# Verify data quality\nassert (df[[\"open\", \"high\", \"low\", \"close\"]] &gt; 0).all().all()\nassert (df[\"high\"] &gt;= df[\"low\"]).all()\nassert df.isna().sum().sum() == 0\n</code></pre>"},{"location":"api/transforms/#example-3-minute-to-hourly-resampling","title":"Example 3: Minute to Hourly Resampling","text":"<pre><code>import qldata as qd\n\n# Fetch 1-minute data\nminute_df = qd.data(\"BTCUSDT\", source=\"binance\") \\\n    .last(1, \"days\") \\\n    .resolution(\"1m\") \\\n    .clean() \\\n    .get()\n\nprint(f\"1-minute bars: {len(minute_df)}\")\n\n# Resample to hourly\nhourly_df = qd.data(\"BTCUSDT\", source=\"binance\") \\\n    .last(1, \"days\") \\\n    .resolution(\"1m\") \\\n    .clean() \\\n    .resample(\"1h\") \\\n    .get()\n\nprint(f\"Hourly bars: {len(hourly_df)}\")\n</code></pre>"},{"location":"api/transforms/#example-4-custom-transform-pipeline","title":"Example 4: Custom Transform Pipeline","text":"<pre><code>from qldata import TransformPipeline, remove_duplicates, fill_forward\nimport pandas as pd\n\ndef custom_smooth(df: pd.DataFrame, window: int = 5) -&gt; pd.DataFrame:\n    \"\"\"Custom smoothing transform.\"\"\"\n    df = df.copy()\n    df[\"close_smooth\"] = df[\"close\"].rolling(window).mean()\n    return df\n\n# Build pipeline with custom transform\npipeline = TransformPipeline() \\\n    .add(remove_duplicates) \\\n    .add(fill_forward) \\\n    .add(custom_smooth, window=10)\n\n# Apply to data\nimport qldata as qd\nraw_df = qd.data(\"BTCUSDT\", source=\"binance\").last(30).resolution(\"1h\").get()\nsmooth_df = pipeline.apply(raw_df)\n\nprint(f\"Added column: close_smooth\")\nprint(smooth_df[[\"close\", \"close_smooth\"]].head())\n</code></pre>"},{"location":"api/transforms/#example-5-multi-symbol-cleaning","title":"Example 5: Multi-Symbol Cleaning","text":"<pre><code>import qldata as qd\nfrom qldata import TransformPipeline, remove_duplicates, remove_outliers, fill_forward\n\n# Create reusable pipeline\npipeline = TransformPipeline() \\\n    .add(remove_duplicates) \\\n    .add(remove_outliers, sigma=3) \\\n    .add(fill_forward)\n\n# Fetch multiple symbols\nsymbols = [\"BTCUSDT\", \"ETHUSDT\", \"SOLUSDT\"]\ndata = qd.data(symbols, source=\"binance\") \\\n    .last(30) \\\n    .resolution(\"1h\") \\\n    .get(parallel=True)\n\n# Clean each symbol\nfor symbol in data:\n    data[symbol] = pipeline.apply(data[symbol])\n    print(f\"{symbol}: {len(data[symbol])} bars, no NaN: {data[symbol].isna().sum().sum() == 0}\")\n</code></pre>"},{"location":"api/transforms/#best-practices","title":"Best Practices","text":""},{"location":"api/transforms/#1-order-matters","title":"1. Order Matters","text":"<p>Apply transforms in the right order:</p> <pre><code># \u2713 Good: Clean \u2192 Fill \u2192 Resample\n.clean().fill_forward().resample(\"1h\")\n\n# \u2717 Bad: Resample before cleaning may spread bad data\n.resample(\"1h\").clean().fill_forward()\n</code></pre>"},{"location":"api/transforms/#2-always-clean-production-data","title":"2. Always Clean Production Data","text":"<pre><code># \u2713 Production-ready\ndf = qd.data(...).clean().get()\n\n# \u2717 Risky in production\ndf = qd.data(...).get()\n</code></pre>"},{"location":"api/transforms/#3-validate-after-transforms","title":"3. Validate After Transforms","text":"<pre><code># Sanity check after cleaning\nassert df.isna().sum().sum() == 0, \"Unexpected NaN values\"\nassert (df[\"close\"] &gt; 0).all(), \"Invalid prices found\"\n</code></pre>"},{"location":"api/transforms/#4-use-pipelines-for-consistency","title":"4. Use Pipelines for Consistency","text":"<pre><code># Define once, use everywhere\nPRODUCTION_PIPELINE = TransformPipeline() \\\n    .add(remove_duplicates) \\\n    .add(remove_outliers) \\\n    .add(fill_forward)\n\n# Consistent cleaning across all data\ndf1 = PRODUCTION_PIPELINE.apply(raw_df1)\ndf2 = PRODUCTION_PIPELINE.apply(raw_df2)\n</code></pre>"},{"location":"api/transforms/#see-also","title":"See Also","text":"<ul> <li>Historical Data - Using transforms with queries</li> <li>Data Validation - Validation rules</li> <li>Cookbook - Real-world examples</li> </ul>"},{"location":"cookbook/","title":"Cookbook","text":"<p>Real-world examples and recipes for common use cases.</p>"},{"location":"cookbook/#quick-recipes","title":"Quick Recipes","text":""},{"location":"cookbook/#fetch-and-save-historical-data","title":"Fetch and Save Historical Data","text":"<pre><code>import qldata as qd\n\n# Fetch last 30 days of hourly data\ndf = qd.data(\"BTCUSDT\", source=\"binance\", category=\"spot\") \\\n    .last(30) \\\n    .resolution(\"1h\") \\\n    .clean() \\\n    .get()\n\n# Save to CSV\ndf.to_csv(\"btc_hourly_30d.csv\")\n\n# Save to Parquet (smaller, faster)\ndf.to_parquet(\"btc_hourly_30d.parquet\")\n</code></pre>"},{"location":"cookbook/#multi-symbol-download","title":"Multi-Symbol Download","text":"<pre><code>import qldata as qd\nfrom pathlib import Path\n\nsymbols = [\"BTCUSDT\", \"ETHUSDT\", \"SOLUSDT\", \"BNBUSDT\", \"XRPUSDT\"]\n\n# Parallel download\ndata = qd.data(symbols, source=\"binance\") \\\n    .last(90) \\\n    .resolution(\"1h\") \\\n    .clean() \\\n    .get(parallel=True, workers=4)\n\n# Save each symbol\noutput_dir = Path(\"./data\")\noutput_dir.mkdir(exist_ok=True)\n\nfor symbol, df in data.items():\n    df.to_parquet(output_dir / f\"{symbol}_1h.parquet\")\n    print(f\"Saved {symbol}: {len(df)} bars\")\n</code></pre>"},{"location":"cookbook/#real-time-price-tracker","title":"Real-Time Price Tracker","text":"<pre><code>import qldata as qd\nimport time\nfrom collections import defaultdict\n\nprices = defaultdict(float)\n\ndef update_prices(df):\n    for _, row in df.iterrows():\n        symbol = row[\"symbol\"]\n        prices[symbol] = row[\"price\"]\n        print(f\"{symbol}: ${prices[symbol]:,.2f}\")\n\nstream = qd.stream([\"BTCUSDT\", \"ETHUSDT\"], source=\"binance\") \\\n    .resolution(\"tick\") \\\n    .on_data(update_prices) \\\n    .get(start=True)\n\ntry:\n    while True:\n        time.sleep(1)\nexcept KeyboardInterrupt:\n    stream.stop()\n</code></pre>"},{"location":"cookbook/#prepare-backtesting-data","title":"Prepare Backtesting Data","text":"<pre><code>import qldata as qd\nimport pandas as pd\n\ndef prepare_backtest_data(\n    symbol: str,\n    days: int = 365,\n    resolution: str = \"1h\"\n) -&gt; pd.DataFrame:\n    \"\"\"Prepare clean data for backtesting.\"\"\"\n\n    # Fetch and clean\n    df = qd.data(symbol, source=\"binance\") \\\n        .last(days) \\\n        .resolution(resolution) \\\n        .clean(\n            remove_invalid_prices=True,\n            remove_outliers=True\n        ) \\\n        .fill_forward() \\\n        .get()\n\n    # Add common indicators\n    df[\"returns\"] = df[\"close\"].pct_change()\n    df[\"log_returns\"] = np.log(df[\"close\"] / df[\"close\"].shift(1))\n    df[\"volatility\"] = df[\"returns\"].rolling(24).std()\n\n    # Drop NaN from indicator calculation\n    df = df.dropna()\n\n    return df\n\n# Prepare data\nimport numpy as np\nbtc = prepare_backtest_data(\"BTCUSDT\", days=365, resolution=\"1h\")\nprint(f\"Ready for backtesting: {len(btc)} bars\")\n</code></pre>"},{"location":"cookbook/#funding-rate-monitor","title":"Funding Rate Monitor","text":"<pre><code>import qldata as qd\nimport time\n\nsymbols = [\"BTCUSDT\", \"ETHUSDT\", \"SOLUSDT\"]\n\ndef check_funding():\n    print(\"\\n\" + \"=\"*50)\n    print(\"Funding Rate Check\")\n    print(\"=\"*50)\n\n    for symbol in symbols:\n        try:\n            rate = qd.current_funding_rate(\n                symbol, \n                source=\"binance\", \n                category=\"usdm\"\n            )\n            annual = rate * 3 * 365 * 100  # 8h funding\n\n            if abs(rate) &gt; 0.001:  # High funding\n                print(f\"\u26a0\ufe0f {symbol}: {rate*100:.4f}% ({annual:.1f}% APR)\")\n            else:\n                print(f\"   {symbol}: {rate*100:.4f}% ({annual:.1f}% APR)\")\n\n        except Exception as e:\n            print(f\"   {symbol}: Error - {e}\")\n\n# Check every hour\nwhile True:\n    check_funding()\n    time.sleep(3600)\n</code></pre>"},{"location":"cookbook/#symbol-screener","title":"Symbol Screener","text":"<pre><code>import qldata as qd\n\n# Get all USDT pairs\nall_symbols = qd.list_symbols(\n    source=\"binance\",\n    category=\"spot\",\n    quote_asset=\"USDT\",\n    active_only=True\n)\n\nprint(f\"Screening {len(all_symbols)} symbols...\")\n\n# Screen for top movers (simplified)\nresults = []\n\nfor symbol in all_symbols[:50]:  # Limit for demo\n    try:\n        df = qd.data(symbol, source=\"binance\") \\\n            .last(7) \\\n            .resolution(\"1d\") \\\n            .clean() \\\n            .get()\n\n        if len(df) &gt;= 2:\n            change = (df[\"close\"].iloc[-1] / df[\"close\"].iloc[0] - 1) * 100\n            volume = df[\"volume\"].mean()\n            results.append({\n                \"symbol\": symbol,\n                \"change_7d\": change,\n                \"avg_volume\": volume\n            })\n    except:\n        pass\n\n# Sort by change\nresults.sort(key=lambda x: x[\"change_7d\"], reverse=True)\n\nprint(\"\\nTop 10 Gainers (7d):\")\nfor r in results[:10]:\n    print(f\"  {r['symbol']}: +{r['change_7d']:.2f}%\")\n\nprint(\"\\nTop 10 Losers (7d):\")\nfor r in results[-10:]:\n    print(f\"  {r['symbol']}: {r['change_7d']:.2f}%\")\n</code></pre>"},{"location":"cookbook/#production-data-pipeline","title":"Production Data Pipeline","text":"<pre><code>import qldata as qd\nfrom qldata.monitoring import DataQualityMonitor, AlertManager\nimport logging\nimport time\n\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(\"pipeline\")\n\n# Setup\nmonitor = DataQualityMonitor(stale_threshold_seconds=10)\nalerts = AlertManager()\n\ndef send_alert(msg):\n    logger.warning(f\"ALERT: {msg}\")\n    # Add PagerDuty/Slack integration here\n\nalerts.on_stale_data(lambda: send_alert(\"Data is stale!\"))\nalerts.on_high_latency(lambda ms: send_alert(f\"Latency: {ms}ms\"))\n\ndef process_trade(df):\n    \"\"\"Process incoming trades.\"\"\"\n    if df.empty:\n        return\n\n    # Record for monitoring\n    monitor.record_message(df.index[-1])\n\n    # Check health\n    metrics = monitor.get_metrics()\n    if metrics[\"latency_p95\"]:\n        alerts.check_latency(metrics[\"latency_p95\"])\n    alerts.check_stale_data(monitor.is_stale())\n\n    # Process data (your logic here)\n    for _, row in df.iterrows():\n        logger.debug(f\"Trade: {row['symbol']} @ ${row['price']}\")\n\n# Start stream\nstream = qd.stream([\"BTCUSDT\", \"ETHUSDT\"], source=\"binance\") \\\n    .resolution(\"tick\") \\\n    .on_data(process_trade) \\\n    .on_error(lambda e: logger.error(f\"Error: {e}\")) \\\n    .on_reconnect(lambda n: logger.info(f\"Reconnect #{n}\")) \\\n    .get(start=True)\n\n# Health loop\ntry:\n    while True:\n        metrics = monitor.get_metrics()\n        logger.info(\n            f\"Health: {monitor.get_health_status()} | \"\n            f\"TPS: {metrics['throughput']:.1f} | \"\n            f\"P95: {metrics['latency_p95']:.1f}ms\"\n        )\n        time.sleep(30)\nexcept KeyboardInterrupt:\n    logger.info(\"Shutting down...\")\n    stream.stop()\n</code></pre>"},{"location":"cookbook/#common-patterns","title":"Common Patterns","text":""},{"location":"cookbook/#error-handling","title":"Error Handling","text":"<pre><code>from qldata.errors import QldataError, ConnectionError, RateLimitError\n\ntry:\n    df = qd.data(\"BTCUSDT\", source=\"binance\").last(30).get()\nexcept RateLimitError:\n    print(\"Rate limited - waiting...\")\n    time.sleep(60)\n    df = qd.data(\"BTCUSDT\", source=\"binance\").last(30).get()\nexcept ConnectionError as e:\n    print(f\"Network error: {e}\")\n    df = load_cached_data()\nexcept QldataError as e:\n    print(f\"qldata error: {e}\")\n</code></pre>"},{"location":"cookbook/#caching-layer","title":"Caching Layer","text":"<pre><code>import qldata as qd\nfrom pathlib import Path\nimport pandas as pd\n\nCACHE_DIR = Path(\"./cache\")\nCACHE_DIR.mkdir(exist_ok=True)\n\ndef get_data_cached(symbol, days, resolution):\n    \"\"\"Fetch data with local cache.\"\"\"\n\n    cache_file = CACHE_DIR / f\"{symbol}_{resolution}_{days}d.parquet\"\n\n    # Check cache age\n    if cache_file.exists():\n        mtime = cache_file.stat().st_mtime\n        age_hours = (time.time() - mtime) / 3600\n\n        if age_hours &lt; 1:  # Cache valid for 1 hour\n            return pd.read_parquet(cache_file)\n\n    # Fetch fresh data\n    df = qd.data(symbol, source=\"binance\") \\\n        .last(days) \\\n        .resolution(resolution) \\\n        .clean() \\\n        .get()\n\n    # Save to cache\n    df.to_parquet(cache_file)\n\n    return df\n</code></pre>"},{"location":"cookbook/#retry-logic","title":"Retry Logic","text":"<pre><code>from tenacity import retry, stop_after_attempt, wait_exponential\nimport qldata as qd\n\n@retry(\n    stop=stop_after_attempt(3),\n    wait=wait_exponential(multiplier=1, min=1, max=10)\n)\ndef fetch_with_retry(symbol, days, resolution):\n    return qd.data(symbol, source=\"binance\") \\\n        .last(days) \\\n        .resolution(resolution) \\\n        .get()\n\n# Will retry up to 3 times with exponential backoff\ndf = fetch_with_retry(\"BTCUSDT\", 30, \"1h\")\n</code></pre>"},{"location":"cookbook/#next-steps","title":"Next Steps","text":"<ul> <li>Binance Examples - Binance-specific patterns</li> <li>Bybit Examples - Bybit-specific patterns</li> <li>API Reference - Full API documentation</li> </ul>"},{"location":"cookbook/binance/","title":"Binance Examples","text":"<p>Binance-specific patterns and examples.</p>"},{"location":"cookbook/binance/#market-types","title":"Market Types","text":"<p>Binance offers multiple market categories:</p> Category API Type Description <code>\"spot\"</code> Spot Spot market trading <code>\"usdm\"</code> USD-M Futures USDT-margined perpetual futures <pre><code>import qldata as qd\n\n# Spot market\nspot_df = qd.data(\"BTCUSDT\", source=\"binance\", category=\"spot\") \\\n    .last(7).resolution(\"1h\").get()\n\n# USD-M Futures\nfutures_df = qd.data(\"BTCUSDT\", source=\"binance\", category=\"usdm\") \\\n    .last(7).resolution(\"1h\").get()\n</code></pre>"},{"location":"cookbook/binance/#spot-market","title":"Spot Market","text":""},{"location":"cookbook/binance/#fetch-spot-data","title":"Fetch Spot Data","text":"<pre><code>import qldata as qd\n\n# Daily OHLCV\ndf = qd.data(\"BTCUSDT\", source=\"binance\", category=\"spot\") \\\n    .last(365) \\\n    .resolution(\"1d\") \\\n    .clean() \\\n    .get()\n\nprint(f\"BTC spot: {len(df)} daily bars\")\nprint(f\"Date range: {df.index[0].date()} to {df.index[-1].date()}\")\n</code></pre>"},{"location":"cookbook/binance/#list-spot-pairs","title":"List Spot Pairs","text":"<pre><code>import qldata as qd\n\n# All active USDT pairs\nusdt_pairs = qd.list_symbols(\n    source=\"binance\",\n    category=\"spot\",\n    quote_asset=\"USDT\",\n    active_only=True\n)\nprint(f\"USDT pairs: {len(usdt_pairs)}\")\n\n# All BTC pairs\nbtc_pairs = qd.list_symbols(\n    source=\"binance\",\n    category=\"spot\",\n    quote_asset=\"BTC\",\n    active_only=True\n)\nprint(f\"BTC pairs: {len(btc_pairs)}\")\n</code></pre>"},{"location":"cookbook/binance/#spot-symbol-info","title":"Spot Symbol Info","text":"<pre><code>import qldata as qd\nfrom decimal import Decimal\n\ninfo = qd.get_symbol_info(\"BTCUSDT\", source=\"binance\", category=\"spot\")\n\nprint(f\"Symbol: {info.symbol}\")\nprint(f\"Base/Quote: {info.base_asset}/{info.quote_asset}\")\nprint(f\"Tick Size: {info.filters.tick_size}\")\nprint(f\"Min Quantity: {info.filters.min_quantity}\")\n\n# Validate order parameters\nprice = Decimal(\"50000.50\")\nquantity = Decimal(\"0.001\")\n\nprint(f\"Price valid: {info.validate_price(price)}\")\nprint(f\"Qty valid: {info.validate_quantity(quantity)}\")\n</code></pre>"},{"location":"cookbook/binance/#usd-m-futures","title":"USD-M Futures","text":""},{"location":"cookbook/binance/#fetch-futures-data","title":"Fetch Futures Data","text":"<pre><code>import qldata as qd\n\n# BTCUSDT perpetual\ndf = qd.data(\"BTCUSDT\", source=\"binance\", category=\"usdm\") \\\n    .last(30) \\\n    .resolution(\"1h\") \\\n    .clean() \\\n    .get()\n\nprint(f\"Futures bars: {len(df)}\")\n</code></pre>"},{"location":"cookbook/binance/#funding-rates","title":"Funding Rates","text":"<pre><code>import qldata as qd\n\n# Current funding rate\nrate = qd.current_funding_rate(\"BTCUSDT\", source=\"binance\", category=\"usdm\")\n\nprint(f\"Current rate: {rate:.6f}\")\nprint(f\"8h rate: {rate * 100:.4f}%\")\nprint(f\"Annualized: {rate * 3 * 365 * 100:.2f}%\")\n</code></pre>"},{"location":"cookbook/binance/#basis-calculation","title":"Basis Calculation","text":"<pre><code>import qldata as qd\n\n# Fetch spot and futures\nspot = qd.data(\"BTCUSDT\", source=\"binance\", category=\"spot\") \\\n    .last(7).resolution(\"1h\").clean().get()\n\nfutures = qd.data(\"BTCUSDT\", source=\"binance\", category=\"usdm\") \\\n    .last(7).resolution(\"1h\").clean().get()\n\n# Align indices\naligned = spot.join(futures, lsuffix=\"_spot\", rsuffix=\"_futures\", how=\"inner\")\n\n# Calculate basis\naligned[\"basis\"] = aligned[\"close_futures\"] - aligned[\"close_spot\"]\naligned[\"basis_pct\"] = aligned[\"basis\"] / aligned[\"close_spot\"] * 100\n\nprint(f\"Current basis: ${aligned['basis'].iloc[-1]:.2f}\")\nprint(f\"Basis %: {aligned['basis_pct'].iloc[-1]:.4f}%\")\nprint(f\"Avg basis %: {aligned['basis_pct'].mean():.4f}%\")\n</code></pre>"},{"location":"cookbook/binance/#live-streaming","title":"Live Streaming","text":""},{"location":"cookbook/binance/#spot-trades","title":"Spot Trades","text":"<pre><code>import qldata as qd\nimport time\n\ndef on_trade(df):\n    for _, row in df.iterrows():\n        side = \"\ud83d\udfe2\" if row.get(\"side\") == \"buy\" else \"\ud83d\udd34\"\n        print(f\"{side} {row['symbol']}: ${row['price']:.2f} x {row['quantity']}\")\n\nstream = qd.stream([\"BTCUSDT\", \"ETHUSDT\"], source=\"binance\", category=\"spot\") \\\n    .resolution(\"tick\") \\\n    .on_data(on_trade) \\\n    .get(start=True)\n\ntime.sleep(60)\nstream.stop()\n</code></pre>"},{"location":"cookbook/binance/#futures-trades","title":"Futures Trades","text":"<pre><code>import qldata as qd\n\nstream = qd.stream([\"BTCUSDT\"], source=\"binance\", category=\"usdm\") \\\n    .resolution(\"tick\") \\\n    .on_data(lambda df: print(df[\"price\"].iloc[-1] if not df.empty else \"\")) \\\n    .get(start=True)\n</code></pre>"},{"location":"cookbook/binance/#rate-limits","title":"Rate Limits","text":"<p>Binance has the following rate limits:</p> Type Limit Notes REST API 1200 req/min Per IP WebSocket 5 connections/IP Per IP Order Rate 10 orders/sec Per account <p>qldata handles rate limits automatically:</p> <pre><code># This works even with many symbols\nsymbols = qd.list_symbols(source=\"binance\", category=\"spot\", quote_asset=\"USDT\")[:100]\n\n# Rate limiting handled automatically\ndata = qd.data(symbols, source=\"binance\") \\\n    .last(7) \\\n    .resolution(\"1d\") \\\n    .get(parallel=True, workers=4)\n</code></pre>"},{"location":"cookbook/binance/#multi-symbol-comparison","title":"Multi-Symbol Comparison","text":"<pre><code>import qldata as qd\nimport pandas as pd\n\nsymbols = [\"BTCUSDT\", \"ETHUSDT\", \"BNBUSDT\", \"SOLUSDT\", \"XRPUSDT\"]\n\n# Fetch all\ndata = qd.data(symbols, source=\"binance\", category=\"spot\") \\\n    .last(30) \\\n    .resolution(\"1d\") \\\n    .clean() \\\n    .get(parallel=True)\n\n# Compare returns\nprint(\"\\n30-Day Returns Analysis\")\nprint(\"-\" * 40)\n\nfor symbol, df in data.items():\n    returns = (df[\"close\"].iloc[-1] / df[\"close\"].iloc[0] - 1) * 100\n    volatility = df[\"close\"].pct_change().std() * (365 ** 0.5) * 100\n    print(f\"{symbol}: {returns:+.2f}% return, {volatility:.1f}% vol\")\n</code></pre>"},{"location":"cookbook/binance/#production-example","title":"Production Example","text":"<pre><code>import qldata as qd\nfrom qldata.monitoring import DataQualityMonitor\nimport logging\nimport time\n\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(\"binance\")\n\nmonitor = DataQualityMonitor(stale_threshold_seconds=5)\n\ndef process(df):\n    if df.empty:\n        return\n\n    monitor.record_message(df.index[-1])\n\n    for _, row in df.iterrows():\n        # Your trading logic here\n        logger.debug(f\"{row['symbol']}: ${row['price']:.2f}\")\n\nstream = qd.stream([\"BTCUSDT\", \"ETHUSDT\"], source=\"binance\", category=\"spot\") \\\n    .resolution(\"tick\") \\\n    .on_data(process) \\\n    .on_error(lambda e: logger.error(f\"Error: {e}\")) \\\n    .on_reconnect(lambda n: logger.warning(f\"Reconnect: {n}\")) \\\n    .get(start=True)\n\ntry:\n    while True:\n        m = monitor.get_metrics()\n        logger.info(f\"TPS: {m['throughput']:.1f} | P95: {m['latency_p95']:.1f}ms\")\n        time.sleep(30)\nexcept KeyboardInterrupt:\n    stream.stop()\n</code></pre>"},{"location":"cookbook/binance/#see-also","title":"See Also","text":"<ul> <li>Bybit Examples - Bybit patterns</li> <li>Streaming API - Full streaming docs</li> <li>Historical Data - Full historical docs</li> </ul>"},{"location":"cookbook/bybit/","title":"Bybit Examples","text":"<p>Bybit-specific patterns and examples.</p>"},{"location":"cookbook/bybit/#market-types","title":"Market Types","text":"<p>Bybit offers multiple market categories:</p> Category API Type Description <code>\"spot\"</code> Spot Spot market trading <code>\"linear\"</code> Linear USDT-margined perpetual contracts <pre><code>import qldata as qd\n\n# Spot market\nspot_df = qd.data(\"BTCUSDT\", source=\"bybit\", category=\"spot\") \\\n    .last(7).resolution(\"1h\").get()\n\n# Linear perpetuals\nlinear_df = qd.data(\"BTCUSDT\", source=\"bybit\", category=\"linear\") \\\n    .last(7).resolution(\"1h\").get()\n</code></pre>"},{"location":"cookbook/bybit/#linear-perpetuals","title":"Linear Perpetuals","text":""},{"location":"cookbook/bybit/#fetch-perpetual-data","title":"Fetch Perpetual Data","text":"<pre><code>import qldata as qd\n\n# BTCUSDT perpetual\ndf = qd.data(\"BTCUSDT\", source=\"bybit\", category=\"linear\") \\\n    .last(30) \\\n    .resolution(\"1h\") \\\n    .clean() \\\n    .get()\n\nprint(f\"BTCUSDT linear: {len(df)} bars\")\n</code></pre>"},{"location":"cookbook/bybit/#funding-rates","title":"Funding Rates","text":"<pre><code>import qldata as qd\n\n# Current funding\nrate = qd.current_funding_rate(\"BTCUSDT\", source=\"bybit\", category=\"linear\")\n\nprint(f\"Current rate: {rate:.6f}\")\nprint(f\"8h rate: {rate * 100:.4f}%\")\nprint(f\"Annualized: {rate * 3 * 365 * 100:.2f}%\")\n</code></pre>"},{"location":"cookbook/bybit/#symbol-info","title":"Symbol Info","text":"<pre><code>import qldata as qd\n\ninfo = qd.get_symbol_info(\"BTCUSDT\", source=\"bybit\", category=\"linear\")\n\nprint(f\"Symbol: {info.symbol}\")\nprint(f\"Contract Type: {info.contract_type}\")\nprint(f\"Is Perpetual: {info.is_perpetual}\")\nprint(f\"Tick Size: {info.filters.tick_size}\")\n</code></pre>"},{"location":"cookbook/bybit/#advanced-pybit-usage","title":"Advanced pybit Usage","text":"<p>For features not yet exposed via qldata, use pybit directly:</p>"},{"location":"cookbook/bybit/#order-book-snapshot","title":"Order Book Snapshot","text":"<pre><code>try:\n    from pybit.unified_trading import HTTP\nexcept ImportError:\n    print(\"Install pybit: pip install pybit\")\n    exit(1)\n\nclient = HTTP(testnet=False)\n\n# Get 50-level order book\nresponse = client.get_orderbook(\n    category=\"linear\",\n    symbol=\"BTCUSDT\",\n    limit=50\n)\n\nif response[\"retCode\"] == 0:\n    ob = response[\"result\"]\n    bids = ob.get(\"b\", [])\n    asks = ob.get(\"a\", [])\n\n    print(f\"Bids: {len(bids)} levels\")\n    print(f\"Asks: {len(asks)} levels\")\n\n    if bids and asks:\n        spread = float(asks[0][0]) - float(bids[0][0])\n        print(f\"Spread: ${spread:.2f}\")\n</code></pre>"},{"location":"cookbook/bybit/#funding-rate-history","title":"Funding Rate History","text":"<pre><code>from pybit.unified_trading import HTTP\n\nclient = HTTP(testnet=False)\n\nresponse = client.get_funding_rate_history(\n    category=\"linear\",\n    symbol=\"BTCUSDT\",\n    limit=10\n)\n\nif response[\"retCode\"] == 0:\n    history = response[\"result\"][\"list\"]\n\n    print(\"Recent Funding Rates:\")\n    for r in history[:5]:\n        rate = float(r.get(\"fundingRate\", 0))\n        print(f\"  {r['fundingRateTimestamp']}: {rate*100:.4f}%\")\n</code></pre>"},{"location":"cookbook/bybit/#open-interest","title":"Open Interest","text":"<pre><code>from pybit.unified_trading import HTTP\n\nclient = HTTP(testnet=False)\n\nresponse = client.get_open_interest(\n    category=\"linear\",\n    symbol=\"BTCUSDT\",\n    intervalTime=\"5min\"\n)\n\nif response[\"retCode\"] == 0:\n    oi_list = response[\"result\"][\"list\"]\n    if oi_list:\n        oi = oi_list[0]\n        print(f\"Open Interest: {oi.get('openInterest')}\")\n</code></pre>"},{"location":"cookbook/bybit/#live-streaming","title":"Live Streaming","text":"<pre><code>import qldata as qd\nimport time\n\ndef on_trade(df):\n    if df.empty:\n        return\n    for _, row in df.iterrows():\n        print(f\"[{row['symbol']}] ${row['price']:.2f} x {row['quantity']}\")\n\nstream = qd.stream([\"BTCUSDT\"], source=\"bybit\", category=\"linear\") \\\n    .resolution(\"tick\") \\\n    .on_data(on_trade) \\\n    .get(start=True)\n\ntime.sleep(60)\nstream.stop()\n</code></pre>"},{"location":"cookbook/bybit/#cross-exchange-comparison","title":"Cross-Exchange Comparison","text":"<pre><code>import qldata as qd\n\nsymbols = [\"BTCUSDT\", \"ETHUSDT\"]\n\nfor symbol in symbols:\n    # Bybit data\n    bybit_df = qd.data(symbol, source=\"bybit\", category=\"linear\") \\\n        .last(7).resolution(\"1h\").clean().get()\n\n    # Binance data\n    binance_df = qd.data(symbol, source=\"binance\", category=\"usdm\") \\\n        .last(7).resolution(\"1h\").clean().get()\n\n    # Compare last prices\n    bybit_price = bybit_df[\"close\"].iloc[-1]\n    binance_price = binance_df[\"close\"].iloc[-1]\n    diff = bybit_price - binance_price\n\n    print(f\"{symbol}:\")\n    print(f\"  Bybit:   ${bybit_price:,.2f}\")\n    print(f\"  Binance: ${binance_price:,.2f}\")\n    print(f\"  Diff:    ${diff:,.2f}\")\n</code></pre>"},{"location":"cookbook/bybit/#rate-limits","title":"Rate Limits","text":"<p>Bybit rate limits:</p> Type Limit Notes REST API 120 req/min Per endpoint WebSocket 20 connections/IP Per IP <p>Rate limits are handled automatically:</p> <pre><code># This works with many symbols\ndata = qd.data([\"BTCUSDT\", \"ETHUSDT\", \"SOLUSDT\"], source=\"bybit\") \\\n    .last(30).resolution(\"1h\") \\\n    .get(parallel=True, workers=2)  # Lower worker count for Bybit\n</code></pre>"},{"location":"cookbook/bybit/#see-also","title":"See Also","text":"<ul> <li>Binance Examples - Binance patterns</li> <li>Streaming API - Full streaming docs</li> <li>Historical Data - Full historical docs</li> </ul>"},{"location":"reference/configuration/","title":"Configuration Reference","text":"<p>Global configuration options for qldata.</p>"},{"location":"reference/configuration/#configuration-methods","title":"Configuration Methods","text":""},{"location":"reference/configuration/#qdconfig","title":"<code>qd.config()</code>","text":"<p>Set global configuration options.</p> <pre><code>import qldata as qd\n\nqd.config(\n    data_dir=\"./market_data\",\n    cache_enabled=True,\n    validation_enabled=True\n)\n</code></pre> <p>Parameters:</p> Parameter Type Default Description <code>data_dir</code> <code>str</code> <code>~/.qldata</code> Directory for cached data <code>cache_enabled</code> <code>bool</code> <code>True</code> Enable disk caching <code>validation_enabled</code> <code>bool</code> <code>True</code> Validate data on fetch"},{"location":"reference/configuration/#qdget_config","title":"<code>qd.get_config()</code>","text":"<p>Get the current configuration.</p> <pre><code>import qldata as qd\n\nconfig = qd.get_config()\nprint(config)\n# {'data_dir': '~/.qldata', 'cache_enabled': True, ...}\n</code></pre>"},{"location":"reference/configuration/#utility-functions","title":"Utility Functions","text":"<pre><code>import qldata as qd\n\n# Get current data directory\ndata_dir = qd.get_data_dir()\nprint(f\"Data directory: {data_dir}\")\n\n# Check if caching is enabled\nif qd.is_cache_enabled():\n    print(\"Caching is ON\")\n\n# Check if validation is enabled\nif qd.is_validation_enabled():\n    print(\"Validation is ON\")\n</code></pre>"},{"location":"reference/configuration/#environment-variables","title":"Environment Variables","text":"<p>qldata reads these environment variables at startup:</p> Variable Type Default Description <code>QLDATA_DATA_DIR</code> <code>str</code> <code>~/.qldata</code> Data directory path <code>QLDATA_CACHE_ENABLED</code> <code>bool</code> <code>true</code> Enable caching <code>QLDATA_VALIDATION_ENABLED</code> <code>bool</code> <code>true</code> Enable validation"},{"location":"reference/configuration/#exchange-api-keys","title":"Exchange API Keys","text":"<p>For private endpoints (not required for market data):</p> Variable Description <code>BINANCE_API_KEY</code> Binance API key <code>BINANCE_API_SECRET</code> Binance API secret <code>BYBIT_API_KEY</code> Bybit API key <code>BYBIT_API_SECRET</code> Bybit API secret <p>API Keys Not Required for Public Data</p> <p>API keys are only needed for private endpoints (account, orders). Market data is fully public.</p>"},{"location":"reference/configuration/#configuration-files","title":"Configuration Files","text":""},{"location":"reference/configuration/#yaml-configuration","title":"YAML Configuration","text":"<p>Create <code>qldata.yaml</code> in your project root:</p> <pre><code># qldata.yaml\ndata_dir: ./data\ncache_enabled: true\nvalidation_enabled: true\n\nexchanges:\n  binance:\n    testnet: false\n  bybit:\n    testnet: false\n</code></pre>"},{"location":"reference/configuration/#toml-configuration","title":"TOML Configuration","text":"<p>Or use <code>qldata.toml</code>:</p> <pre><code># qldata.toml\ndata_dir = \"./data\"\ncache_enabled = true\nvalidation_enabled = true\n\n[exchanges.binance]\ntestnet = false\n\n[exchanges.bybit]\ntestnet = false\n</code></pre>"},{"location":"reference/configuration/#per-query-overrides","title":"Per-Query Overrides","text":"<p>Override global config for specific queries:</p> <pre><code>import qldata as qd\n\n# Global config\nqd.config(cache_enabled=True)\n\n# Override for this query\ndf = qd.data(\"BTCUSDT\", source=\"binance\") \\\n    .last(30) \\\n    .resolution(\"1h\") \\\n    .get(cache=False)  # Skip cache for this query\n</code></pre>"},{"location":"reference/configuration/#data-directory-structure","title":"Data Directory Structure","text":"<p>The data directory is organized as:</p> <pre><code>~/.qldata/\n\u251c\u2500\u2500 cache/\n\u2502   \u251c\u2500\u2500 binance/\n\u2502   \u2502   \u251c\u2500\u2500 spot/\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 BTCUSDT_1h_2024-11.parquet\n\u2502   \u2502   \u2514\u2500\u2500 usdm/\n\u2502   \u2502       \u2514\u2500\u2500 BTCUSDT_1h_2024-11.parquet\n\u2502   \u2514\u2500\u2500 bybit/\n\u2502       \u2514\u2500\u2500 linear/\n\u2502           \u2514\u2500\u2500 BTCUSDT_1h_2024-11.parquet\n\u251c\u2500\u2500 logs/\n\u2502   \u2514\u2500\u2500 qldata.log\n\u2514\u2500\u2500 config/\n    \u2514\u2500\u2500 qldata.yaml\n</code></pre>"},{"location":"reference/configuration/#logging","title":"Logging","text":"<p>Configure logging for debugging:</p> <pre><code>import logging\n\n# Enable debug logging\nlogging.basicConfig(level=logging.DEBUG)\n\n# Or for specific module\nlogging.getLogger(\"qldata\").setLevel(logging.DEBUG)\n\n# Quiet mode (errors only)\nlogging.getLogger(\"qldata\").setLevel(logging.ERROR)\n</code></pre>"},{"location":"reference/configuration/#best-practices","title":"Best Practices","text":""},{"location":"reference/configuration/#development","title":"Development","text":"<pre><code>import qldata as qd\n\nqd.config(\n    data_dir=\"./dev_data\",\n    cache_enabled=True,      # Cache for faster iteration\n    validation_enabled=True  # Catch issues early\n)\n</code></pre>"},{"location":"reference/configuration/#production","title":"Production","text":"<pre><code>import qldata as qd\n\nqd.config(\n    data_dir=\"/var/lib/qldata\",\n    cache_enabled=True,\n    validation_enabled=True\n)\n</code></pre>"},{"location":"reference/configuration/#testing","title":"Testing","text":"<pre><code>import qldata as qd\nimport tempfile\n\nqd.config(\n    data_dir=tempfile.mkdtemp(),\n    cache_enabled=False,     # Fresh data each time\n    validation_enabled=True\n)\n</code></pre>"},{"location":"reference/configuration/#see-also","title":"See Also","text":"<ul> <li>Installation - Setup and verification</li> <li>Error Handling - Error configuration</li> </ul>"},{"location":"reference/errors/","title":"Error Handling","text":"<p>Exception hierarchy and error handling patterns.</p>"},{"location":"reference/errors/#exception-hierarchy","title":"Exception Hierarchy","text":"<pre><code>QldataError (base)\n\u251c\u2500\u2500 ConnectionError\n\u2502   \u251c\u2500\u2500 WebSocketError\n\u2502   \u2514\u2500\u2500 TimeoutError\n\u251c\u2500\u2500 RateLimitError\n\u251c\u2500\u2500 ValidationError\n\u2502   \u251c\u2500\u2500 SymbolNotFoundError\n\u2502   \u2514\u2500\u2500 InvalidParameterError\n\u251c\u2500\u2500 ConfigurationError\n\u2514\u2500\u2500 DataError\n    \u251c\u2500\u2500 EmptyDataError\n    \u2514\u2500\u2500 CorruptedDataError\n</code></pre>"},{"location":"reference/errors/#common-exceptions","title":"Common Exceptions","text":""},{"location":"reference/errors/#qldataerror","title":"QldataError","text":"<p>Base exception for all qldata errors.</p> <pre><code>from qldata.errors import QldataError\n\ntry:\n    df = qd.data(\"INVALID\", source=\"binance\").last(1).get()\nexcept QldataError as e:\n    print(f\"qldata error: {e}\")\n</code></pre>"},{"location":"reference/errors/#connectionerror","title":"ConnectionError","text":"<p>Network and connection issues.</p> <pre><code>from qldata.errors import ConnectionError\n\ntry:\n    df = qd.data(\"BTCUSDT\", source=\"binance\").last(1).get()\nexcept ConnectionError as e:\n    print(f\"Network error: {e}\")\n    # Retry or use fallback\n</code></pre>"},{"location":"reference/errors/#ratelimiterror","title":"RateLimitError","text":"<p>API rate limit exceeded.</p> <pre><code>from qldata.errors import RateLimitError\nimport time\n\ntry:\n    df = qd.data(\"BTCUSDT\", source=\"binance\").last(1).get()\nexcept RateLimitError as e:\n    print(f\"Rate limited. Retry after: {e.retry_after}s\")\n    time.sleep(e.retry_after)\n    # Retry\n</code></pre>"},{"location":"reference/errors/#validationerror","title":"ValidationError","text":"<p>Data validation failed.</p> <pre><code>from qldata.errors import ValidationError\n\ntry:\n    df = qd.data(\"BTCUSDT\", source=\"binance\").last(1).get()\nexcept ValidationError as e:\n    print(f\"Validation failed: {e}\")\n    # Check data quality\n</code></pre>"},{"location":"reference/errors/#symbolnotfounderror","title":"SymbolNotFoundError","text":"<p>Symbol doesn't exist on exchange.</p> <pre><code>from qldata.errors import SymbolNotFoundError\n\ntry:\n    info = qd.get_symbol_info(\"INVALIDPAIR\", source=\"binance\")\nexcept SymbolNotFoundError as e:\n    print(f\"Symbol not found: {e.symbol}\")\n</code></pre>"},{"location":"reference/errors/#error-handling-patterns","title":"Error Handling Patterns","text":""},{"location":"reference/errors/#basic-try-except","title":"Basic Try-Except","text":"<pre><code>from qldata.errors import QldataError\n\ntry:\n    df = qd.data(\"BTCUSDT\", source=\"binance\").last(30).get()\nexcept QldataError as e:\n    print(f\"Error: {e}\")\n    df = fallback_data()\n</code></pre>"},{"location":"reference/errors/#specific-exceptions","title":"Specific Exceptions","text":"<pre><code>from qldata.errors import (\n    ConnectionError,\n    RateLimitError,\n    ValidationError,\n    QldataError\n)\n\ntry:\n    df = qd.data(\"BTCUSDT\", source=\"binance\").last(30).get()\nexcept RateLimitError as e:\n    time.sleep(e.retry_after)\n    df = qd.data(\"BTCUSDT\", source=\"binance\").last(30).get()\nexcept ConnectionError as e:\n    logger.error(f\"Network error: {e}\")\n    df = load_cached_data()\nexcept ValidationError as e:\n    logger.warning(f\"Validation issue: {e}\")\n    df = qd.data(\"BTCUSDT\", source=\"binance\").last(30).get(validate=False)\nexcept QldataError as e:\n    logger.error(f\"Unexpected error: {e}\")\n    raise\n</code></pre>"},{"location":"reference/errors/#retry-with-backoff","title":"Retry with Backoff","text":"<pre><code>from tenacity import retry, stop_after_attempt, wait_exponential\nfrom qldata.errors import ConnectionError, RateLimitError\n\n@retry(\n    retry=retry_if_exception_type((ConnectionError, RateLimitError)),\n    stop=stop_after_attempt(3),\n    wait=wait_exponential(multiplier=1, min=1, max=10)\n)\ndef fetch_data(symbol, days):\n    return qd.data(symbol, source=\"binance\").last(days).get()\n</code></pre>"},{"location":"reference/errors/#fallback-chain","title":"Fallback Chain","text":"<pre><code>def get_data_with_fallback(symbol, days):\n    \"\"\"Try multiple sources with fallback.\"\"\"\n\n    sources = [\n        (\"binance\", \"spot\"),\n        (\"bybit\", \"spot\"),\n    ]\n\n    for source, category in sources:\n        try:\n            return qd.data(symbol, source=source, category=category) \\\n                .last(days).resolution(\"1h\").get()\n        except QldataError as e:\n            logger.warning(f\"Failed {source}: {e}\")\n            continue\n\n    raise QldataError(f\"All sources failed for {symbol}\")\n</code></pre>"},{"location":"reference/errors/#streaming-error-handling","title":"Streaming Error Handling","text":"<pre><code>import qldata as qd\n\ndef on_error(error):\n    \"\"\"Handle streaming errors.\"\"\"\n    if isinstance(error, ConnectionError):\n        logger.warning(\"Connection lost, will auto-reconnect\")\n    elif isinstance(error, RateLimitError):\n        logger.error(f\"Rate limited: {error}\")\n    else:\n        logger.error(f\"Streaming error: {error}\")\n\nstream = qd.stream([\"BTCUSDT\"], source=\"binance\") \\\n    .resolution(\"tick\") \\\n    .on_data(process) \\\n    .on_error(on_error) \\\n    .get(start=True)\n</code></pre>"},{"location":"reference/errors/#logging-errors","title":"Logging Errors","text":"<pre><code>import logging\nfrom qldata.errors import QldataError\n\nlogging.basicConfig(\n    level=logging.INFO,\n    format=\"%(asctime)s [%(levelname)s] %(message)s\"\n)\nlogger = logging.getLogger(\"trading\")\n\ntry:\n    df = qd.data(\"BTCUSDT\", source=\"binance\").last(30).get()\nexcept QldataError as e:\n    logger.exception(\"Data fetch failed\")\n    raise\n</code></pre>"},{"location":"reference/errors/#best-practices","title":"Best Practices","text":""},{"location":"reference/errors/#1-catch-specific-exceptions","title":"1. Catch Specific Exceptions","text":"<pre><code># \u2713 Good - handle specific cases\ntry:\n    df = fetch_data()\nexcept RateLimitError:\n    wait_and_retry()\nexcept ConnectionError:\n    use_cached_data()\n\n# \u2717 Avoid - too broad\ntry:\n    df = fetch_data()\nexcept Exception:\n    pass  # Swallows all errors\n</code></pre>"},{"location":"reference/errors/#2-always-log-errors","title":"2. Always Log Errors","text":"<pre><code>except QldataError as e:\n    logger.error(f\"Data error: {e}\")  # \u2713 Log it\n    raise\n</code></pre>"},{"location":"reference/errors/#3-provide-fallbacks","title":"3. Provide Fallbacks","text":"<pre><code>except ConnectionError:\n    df = load_cached_data()  # \u2713 Fallback to cache\n</code></pre>"},{"location":"reference/errors/#4-use-retry-logic","title":"4. Use Retry Logic","text":"<pre><code>@retry(stop=stop_after_attempt(3))\ndef reliable_fetch():\n    return qd.data(...).get()\n</code></pre>"},{"location":"reference/errors/#see-also","title":"See Also","text":"<ul> <li>Configuration - Retry settings</li> <li>Resilience - Auto-reconnect</li> </ul>"},{"location":"reference/models/","title":"Models Reference","text":"<p>Data models and types used throughout qldata.</p>"},{"location":"reference/models/#core-models","title":"Core Models","text":""},{"location":"reference/models/#bar","title":"Bar","text":"<p>OHLCV candlestick data.</p> <p>DataFrame Columns:</p> Column Type Description <code>open</code> <code>float</code> Opening price <code>high</code> <code>float</code> Highest price <code>low</code> <code>float</code> Lowest price <code>close</code> <code>float</code> Closing price <code>volume</code> <code>float</code> Trading volume <p>Index: <code>timestamp</code> (pandas <code>DatetimeIndex</code>, UTC)</p>"},{"location":"reference/models/#qldata.Bar","title":"Bar  <code>dataclass</code>","text":"<pre><code>Bar(\n    timestamp: datetime,\n    symbol: str,\n    open: Decimal,\n    high: Decimal,\n    low: Decimal,\n    close: Decimal,\n    volume: Decimal,\n)\n</code></pre> <p>OHLCV bar data model.</p> <p>Represents aggregated price/volume data over a time period.</p> <p>Attributes:</p> Name Type Description <code>timestamp</code> <code>datetime</code> <p>Bar start time</p> <code>symbol</code> <code>str</code> <p>Symbol ticker</p> <code>open</code> <code>Decimal</code> <p>Opening price</p> <code>high</code> <code>Decimal</code> <p>Highest price</p> <code>low</code> <code>Decimal</code> <p>Lowest price</p> <code>close</code> <code>Decimal</code> <p>Closing price</p> <code>volume</code> <code>Decimal</code> <p>Total volume</p>"},{"location":"reference/models/#qldata.Bar.__post_init__","title":"__post_init__","text":"<pre><code>__post_init__() -&gt; None\n</code></pre> <p>Validate OHLC consistency.</p>"},{"location":"reference/models/#qldata.Bar.range","title":"range","text":"<pre><code>range() -&gt; Decimal\n</code></pre> <p>Calculate price range (high - low).</p> <p>Returns:</p> Type Description <code>Decimal</code> <p>Price range</p>"},{"location":"reference/models/#qldata.Bar.body","title":"body","text":"<pre><code>body() -&gt; Decimal\n</code></pre> <p>Calculate body size (abs(close - open)).</p> <p>Returns:</p> Type Description <code>Decimal</code> <p>Absolute value of price change</p>"},{"location":"reference/models/#qldata.Bar.is_bullish","title":"is_bullish","text":"<pre><code>is_bullish() -&gt; bool\n</code></pre> <p>Check if bar is bullish (close &gt; open).</p> <p>Returns:</p> Type Description <code>bool</code> <p>True if bullish, False otherwise</p>"},{"location":"reference/models/#qldata.Bar.is_bearish","title":"is_bearish","text":"<pre><code>is_bearish() -&gt; bool\n</code></pre> <p>Check if bar is bearish (close &lt; open).</p> <p>Returns:</p> Type Description <code>bool</code> <p>True if bearish, False otherwise</p>"},{"location":"reference/models/#tick","title":"Tick","text":"<p>Individual trade/tick data.</p> <p>DataFrame Columns:</p> Column Type Description <code>price</code> <code>float</code> Trade price <code>quantity</code> <code>float</code> Trade quantity <code>symbol</code> <code>str</code> Trading pair <code>side</code> <code>str</code> <code>\"buy\"</code> or <code>\"sell\"</code> <code>trade_id</code> <code>int</code> Unique trade identifier"},{"location":"reference/models/#qldata.Tick","title":"Tick  <code>dataclass</code>","text":"<pre><code>Tick(\n    timestamp: datetime,\n    symbol: str,\n    price: Decimal,\n    volume: Decimal,\n    bid: Decimal | None = None,\n    ask: Decimal | None = None,\n)\n</code></pre> <p>Tick (trade) data model.</p> <p>Represents a single market trade.</p> <p>Attributes:</p> Name Type Description <code>timestamp</code> <code>datetime</code> <p>Time of trade</p> <code>symbol</code> <code>str</code> <p>Symbol ticker</p> <code>price</code> <code>Decimal</code> <p>Trade price</p> <code>volume</code> <code>Decimal</code> <p>Trade volume</p> <code>bid</code> <code>Decimal | None</code> <p>Best bid price (optional)</p> <code>ask</code> <code>Decimal | None</code> <p>Best ask price (optional)</p>"},{"location":"reference/models/#qldata.Tick.__post_init__","title":"__post_init__","text":"<pre><code>__post_init__() -&gt; None\n</code></pre> <p>Validate tick data.</p>"},{"location":"reference/models/#qldata.Tick.spread","title":"spread","text":"<pre><code>spread() -&gt; Decimal | None\n</code></pre> <p>Calculate bid-ask spread.</p> <p>Returns:</p> Type Description <code>Decimal | None</code> <p>Spread if both bid and ask are available, None otherwise</p>"},{"location":"reference/models/#qldata.Tick.mid_price","title":"mid_price","text":"<pre><code>mid_price() -&gt; Decimal | None\n</code></pre> <p>Calculate mid price (average of bid and ask).</p> <p>Returns:</p> Type Description <code>Decimal | None</code> <p>Mid price if both bid and ask are available, None otherwise</p>"},{"location":"reference/models/#timeframe","title":"Timeframe","text":"<p>Time intervals for bar data.</p> <p>Available Timeframes:</p> Enum String Duration <code>MINUTE_1</code> <code>\"1m\"</code> 1 minute <code>MINUTE_3</code> <code>\"3m\"</code> 3 minutes <code>MINUTE_5</code> <code>\"5m\"</code> 5 minutes <code>MINUTE_15</code> <code>\"15m\"</code> 15 minutes <code>MINUTE_30</code> <code>\"30m\"</code> 30 minutes <code>HOUR_1</code> <code>\"1h\"</code> 1 hour <code>HOUR_2</code> <code>\"2h\"</code> 2 hours <code>HOUR_4</code> <code>\"4h\"</code> 4 hours <code>HOUR_6</code> <code>\"6h\"</code> 6 hours <code>HOUR_8</code> <code>\"8h\"</code> 8 hours <code>HOUR_12</code> <code>\"12h\"</code> 12 hours <code>DAY_1</code> <code>\"1d\"</code> 1 day <code>DAY_3</code> <code>\"3d\"</code> 3 days <code>WEEK_1</code> <code>\"1w\"</code> 1 week <code>MONTH_1</code> <code>\"1M\"</code> 1 month <pre><code>from qldata import Timeframe\n\n# Use enum\ntf = Timeframe.HOUR_1\n\n# Convert to string\nprint(tf.value)  # \"1h\"\n\n# Parse from string\ntf = Timeframe.from_string(\"4h\")\n</code></pre>"},{"location":"reference/models/#qldata.Timeframe","title":"Timeframe","text":"<p>               Bases: <code>Enum</code></p> <p>Standard timeframe definitions for market data.</p> <p>Supports common intervals from ticks to monthly bars.</p>"},{"location":"reference/models/#qldata.Timeframe.from_string","title":"from_string  <code>classmethod</code>","text":"<pre><code>from_string(s: str) -&gt; Timeframe\n</code></pre> <p>Parse string to Timeframe enum.</p> <p>Parameters:</p> Name Type Description Default <code>s</code> <code>str</code> <p>Timeframe string (e.g., \"1h\", \"5m\", \"1d\")</p> required <p>Returns:</p> Type Description <code>Timeframe</code> <p>Timeframe enum value</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If timeframe string is not recognized</p>"},{"location":"reference/models/#qldata.Timeframe.from_minutes","title":"from_minutes  <code>classmethod</code>","text":"<pre><code>from_minutes(minutes: int) -&gt; Timeframe\n</code></pre> <p>Create timeframe from minutes.</p> <p>Parameters:</p> Name Type Description Default <code>minutes</code> <code>int</code> <p>Number of minutes (1, 2, 3, 5, 15, or 30)</p> required <p>Returns:</p> Type Description <code>Timeframe</code> <p>Timeframe enum</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If minutes value not supported</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; Timeframe.from_minutes(5)\nTimeframe.MIN_5\n</code></pre>"},{"location":"reference/models/#qldata.Timeframe.from_hours","title":"from_hours  <code>classmethod</code>","text":"<pre><code>from_hours(hours: int) -&gt; Timeframe\n</code></pre> <p>Create timeframe from hours.</p> <p>Parameters:</p> Name Type Description Default <code>hours</code> <code>int</code> <p>Number of hours (1, 2, 4, 6, 8, or 12)</p> required <p>Returns:</p> Type Description <code>Timeframe</code> <p>Timeframe enum</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If hours value not supported</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; Timeframe.from_hours(4)\nTimeframe.HOUR_4\n</code></pre>"},{"location":"reference/models/#qldata.Timeframe.from_days","title":"from_days  <code>classmethod</code>","text":"<pre><code>from_days(days: int) -&gt; Timeframe\n</code></pre> <p>Create timeframe from days.</p> <p>Parameters:</p> Name Type Description Default <code>days</code> <code>int</code> <p>Number of days (1 or 3)</p> required <p>Returns:</p> Type Description <code>Timeframe</code> <p>Timeframe enum</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If days value not supported</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; Timeframe.from_days(1)\nTimeframe.DAY_1\n</code></pre>"},{"location":"reference/models/#qldata.Timeframe.minute","title":"minute  <code>classmethod</code>","text":"<pre><code>minute() -&gt; Timeframe\n</code></pre> <p>1-minute timeframe.</p>"},{"location":"reference/models/#qldata.Timeframe.hour","title":"hour  <code>classmethod</code>","text":"<pre><code>hour() -&gt; Timeframe\n</code></pre> <p>1-hour timeframe.</p>"},{"location":"reference/models/#qldata.Timeframe.day","title":"day  <code>classmethod</code>","text":"<pre><code>day() -&gt; Timeframe\n</code></pre> <p>Daily timeframe.</p>"},{"location":"reference/models/#qldata.Timeframe.week","title":"week  <code>classmethod</code>","text":"<pre><code>week() -&gt; Timeframe\n</code></pre> <p>Weekly timeframe.</p>"},{"location":"reference/models/#qldata.Timeframe.month","title":"month  <code>classmethod</code>","text":"<pre><code>month() -&gt; Timeframe\n</code></pre> <p>Monthly timeframe.</p>"},{"location":"reference/models/#qldata.Timeframe.to_pandas_rule","title":"to_pandas_rule","text":"<pre><code>to_pandas_rule() -&gt; str | None\n</code></pre> <p>Convert to pandas resample rule.</p> <p>Returns:</p> Type Description <code>str | None</code> <p>Pandas resample rule string (e.g., \"1h\", \"5T\", \"1D\"), or None for tick data</p>"},{"location":"reference/models/#qldata.Timeframe.to_seconds","title":"to_seconds","text":"<pre><code>to_seconds() -&gt; int\n</code></pre> <p>Convert timeframe to duration in seconds.</p> <p>Returns:</p> Type Description <code>int</code> <p>Duration in seconds for this timeframe.</p> <code>int</code> <p>Returns 0 for TICK (no fixed interval).</p> <code>int</code> <p>Monthly (1M) returns approximate 30-day value (2592000 seconds).</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If timeframe cannot be converted to seconds.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; Timeframe.HOUR_1.to_seconds()\n3600\n&gt;&gt;&gt; Timeframe.DAY_1.to_seconds()\n86400\n</code></pre>"},{"location":"reference/models/#qldata.Timeframe.__str__","title":"__str__","text":"<pre><code>__str__() -&gt; str\n</code></pre> <p>String representation.</p>"},{"location":"reference/models/#market-data-models","title":"Market Data Models","text":""},{"location":"reference/models/#orderbook","title":"OrderBook","text":"<p>Order book snapshot.</p> <p>Properties:</p> Property Type Description <code>symbol</code> <code>str</code> Trading pair <code>timestamp</code> <code>datetime</code> Snapshot time <code>bids</code> <code>list[OrderBookLevel]</code> Buy orders (descending price) <code>asks</code> <code>list[OrderBookLevel]</code> Sell orders (ascending price)"},{"location":"reference/models/#qldata.OrderBook","title":"OrderBook  <code>dataclass</code>","text":"<pre><code>OrderBook(\n    symbol: str,\n    timestamp: datetime,\n    bids: list[OrderBookLevel],\n    asks: list[OrderBookLevel],\n    sequence: int | None = None,\n    source: str | None = None,\n)\n</code></pre> <p>Order book snapshot with bids and asks.</p> <p>Represents a point-in-time view of the order book.</p> <p>Attributes:</p> Name Type Description <code>symbol</code> <code>str</code> <p>Trading pair symbol</p> <code>timestamp</code> <code>datetime</code> <p>Time of snapshot</p> <code>bids</code> <code>list[OrderBookLevel]</code> <p>List of bid levels (sorted descending by price)</p> <code>asks</code> <code>list[OrderBookLevel]</code> <p>List of ask levels (sorted ascending by price)</p> <code>sequence</code> <code>int | None</code> <p>Sequence number for ordering updates (optional)</p> <code>source</code> <code>str | None</code> <p>Data source (e.g., \"binance\", \"bybit\")</p>"},{"location":"reference/models/#qldata.OrderBook.best_bid","title":"best_bid  <code>property</code>","text":"<pre><code>best_bid: OrderBookLevel | None\n</code></pre> <p>Get best (highest) bid price level.</p>"},{"location":"reference/models/#qldata.OrderBook.best_ask","title":"best_ask  <code>property</code>","text":"<pre><code>best_ask: OrderBookLevel | None\n</code></pre> <p>Get best (lowest) ask price level.</p>"},{"location":"reference/models/#qldata.OrderBook.spread","title":"spread  <code>property</code>","text":"<pre><code>spread: Decimal | None\n</code></pre> <p>Calculate bid-ask spread.</p> <p>Returns:</p> Type Description <code>Decimal | None</code> <p>Spread (ask - bid) if both sides exist, None otherwise</p>"},{"location":"reference/models/#qldata.OrderBook.mid_price","title":"mid_price  <code>property</code>","text":"<pre><code>mid_price: Decimal | None\n</code></pre> <p>Calculate mid price (average of best bid and ask).</p> <p>Returns:</p> Type Description <code>Decimal | None</code> <p>Mid price if both sides exist, None otherwise</p>"},{"location":"reference/models/#qldata.OrderBook.__post_init__","title":"__post_init__","text":"<pre><code>__post_init__() -&gt; None\n</code></pre> <p>Validate order book.</p>"},{"location":"reference/models/#qldata.OrderBook.get_depth","title":"get_depth","text":"<pre><code>get_depth(side: str, depth: int) -&gt; list[OrderBookLevel]\n</code></pre> <p>Get top N levels from one side of the book.</p> <p>Parameters:</p> Name Type Description Default <code>side</code> <code>str</code> <p>\"bid\" or \"ask\"</p> required <code>depth</code> <code>int</code> <p>Number of levels to return</p> required <p>Returns:</p> Type Description <code>list[OrderBookLevel]</code> <p>List of order book levels</p>"},{"location":"reference/models/#qldata.OrderBook.total_volume","title":"total_volume","text":"<pre><code>total_volume(\n    side: str, depth: int | None = None\n) -&gt; Decimal\n</code></pre> <p>Calculate total volume on one side of the book.</p> <p>Parameters:</p> Name Type Description Default <code>side</code> <code>str</code> <p>\"bid\" or \"ask\"</p> required <code>depth</code> <code>int | None</code> <p>Optional depth limit (all levels if None)</p> <code>None</code> <p>Returns:</p> Type Description <code>Decimal</code> <p>Total volume</p>"},{"location":"reference/models/#qldata.OrderBook.imbalance","title":"imbalance","text":"<pre><code>imbalance(depth: int | None = None) -&gt; float\n</code></pre> <p>Calculate order book imbalance.</p> <p>Imbalance = (bid_volume - ask_volume) / (bid_volume + ask_volume)</p> <p>Parameters:</p> Name Type Description Default <code>depth</code> <code>int | None</code> <p>Optional depth limit</p> <code>None</code> <p>Returns:</p> Type Description <code>float</code> <p>Imbalance ratio (-1 to 1, positive = more bids)</p>"},{"location":"reference/models/#orderbooklevel","title":"OrderBookLevel","text":"<p>Single price level in order book.</p> <p>Properties:</p> Property Type Description <code>price</code> <code>Decimal</code> Price level <code>quantity</code> <code>Decimal</code> Total quantity at level"},{"location":"reference/models/#qldata.OrderBookLevel","title":"OrderBookLevel  <code>dataclass</code>","text":"<pre><code>OrderBookLevel(price: Decimal, quantity: Decimal)\n</code></pre> <p>Single price level in an order book.</p> <p>Attributes:</p> Name Type Description <code>price</code> <code>Decimal</code> <p>Price level</p> <code>quantity</code> <code>Decimal</code> <p>Total quantity at this price level</p>"},{"location":"reference/models/#qldata.OrderBookLevel.__post_init__","title":"__post_init__","text":"<pre><code>__post_init__() -&gt; None\n</code></pre> <p>Validate order book level.</p>"},{"location":"reference/models/#fundingrate","title":"FundingRate","text":"<p>Perpetual contract funding rate.</p> <p>Properties:</p> Property Type Description <code>symbol</code> <code>str</code> Trading pair <code>rate</code> <code>Decimal</code> Funding rate <code>timestamp</code> <code>datetime</code> Rate timestamp <code>next_funding_time</code> <code>datetime</code> Next funding time"},{"location":"reference/models/#qldata.FundingRate","title":"FundingRate  <code>dataclass</code>","text":"<pre><code>FundingRate(\n    symbol: str,\n    timestamp: datetime,\n    rate: Decimal,\n    next_funding_time: datetime | None = None,\n    mark_price: Decimal | None = None,\n    source: str | None = None,\n)\n</code></pre> <p>Funding rate for a perpetual contract.</p> <p>Attributes:</p> Name Type Description <code>symbol</code> <code>str</code> <p>Trading pair symbol</p> <code>timestamp</code> <code>datetime</code> <p>Time of funding rate</p> <code>rate</code> <code>Decimal</code> <p>Funding rate (as decimal, e.g., 0.0001 = 0.01%)</p> <code>next_funding_time</code> <code>datetime | None</code> <p>When next funding will occur</p> <code>mark_price</code> <code>Decimal | None</code> <p>Mark price at funding time</p> <code>source</code> <code>str | None</code> <p>Data source</p>"},{"location":"reference/models/#qldata.FundingRate.rate_bps","title":"rate_bps  <code>property</code>","text":"<pre><code>rate_bps: Decimal\n</code></pre> <p>Get funding rate in basis points (1 bps = 0.01%).</p>"},{"location":"reference/models/#qldata.FundingRate.rate_percent","title":"rate_percent  <code>property</code>","text":"<pre><code>rate_percent: Decimal\n</code></pre> <p>Get funding rate as percentage.</p>"},{"location":"reference/models/#qldata.FundingRate.__post_init__","title":"__post_init__","text":"<pre><code>__post_init__() -&gt; None\n</code></pre> <p>Validate funding rate.</p>"},{"location":"reference/models/#openinterest","title":"OpenInterest","text":"<p>Open interest data.</p> <p>Properties:</p> Property Type Description <code>symbol</code> <code>str</code> Trading pair <code>open_interest</code> <code>Decimal</code> Total open contracts <code>timestamp</code> <code>datetime</code> Data timestamp"},{"location":"reference/models/#qldata.OpenInterest","title":"OpenInterest  <code>dataclass</code>","text":"<pre><code>OpenInterest(\n    symbol: str,\n    timestamp: datetime,\n    value: Decimal,\n    value_usd: Decimal | None = None,\n    unit: str = \"contracts\",\n    source: str | None = None,\n)\n</code></pre> <p>Open interest for a perpetual or futures contract.</p> <p>Attributes:</p> Name Type Description <code>symbol</code> <code>str</code> <p>Trading pair symbol</p> <code>timestamp</code> <code>datetime</code> <p>Time of measurement</p> <code>value</code> <code>Decimal</code> <p>Open interest value</p> <code>value_usd</code> <code>Decimal | None</code> <p>Open interest in USD (if available)</p> <code>unit</code> <code>str</code> <p>Unit of measurement (\"contracts\", \"USD\", \"base_currency\")</p> <code>source</code> <code>str | None</code> <p>Data source</p>"},{"location":"reference/models/#qldata.OpenInterest.__post_init__","title":"__post_init__","text":"<pre><code>__post_init__() -&gt; None\n</code></pre> <p>Validate open interest.</p>"},{"location":"reference/models/#symbol-models","title":"Symbol Models","text":""},{"location":"reference/models/#symbolinfo","title":"SymbolInfo","text":"<p>Trading symbol metadata.</p> <p>Properties:</p> Property Type Description <code>symbol</code> <code>str</code> Trading pair name <code>base_asset</code> <code>str</code> Base currency (e.g., BTC) <code>quote_asset</code> <code>str</code> Quote currency (e.g., USDT) <code>status</code> <code>str</code> Trading status <code>is_active</code> <code>bool</code> Currently tradeable <code>is_spot</code> <code>bool</code> Spot market <code>is_perpetual</code> <code>bool</code> Perpetual contract <code>contract_type</code> <code>str</code> Contract type (perpetual, delivery) <code>margin_asset</code> <code>str</code> Margin currency <code>filters</code> <code>TradingFilters</code> Trading constraints <p>Methods:</p> Method Returns Description <code>validate_price(price)</code> <code>bool</code> Check if price is valid <code>validate_quantity(qty)</code> <code>bool</code> Check if quantity is valid"},{"location":"reference/models/#qldata.SymbolInfo","title":"SymbolInfo  <code>dataclass</code>","text":"<pre><code>SymbolInfo(\n    symbol: str,\n    base_asset: str,\n    quote_asset: str,\n    status: str = \"TRADING\",\n    filters: SymbolFilters = SymbolFilters(),\n    trading_hours: TradingHours = TradingHours(),\n    contract_type: str | None = None,\n    delivery_date: str | None = None,\n    margin_asset: str | None = None,\n    maker_fee: Decimal | None = None,\n    taker_fee: Decimal | None = None,\n    fee_tier: str | None = None,\n    source: str | None = None,\n    last_updated: str | None = None,\n)\n</code></pre> <p>Complete symbol metadata and trading specifications.</p> <p>Attributes:</p> Name Type Description <code>symbol</code> <code>str</code> <p>Trading pair symbol</p> <code>base_asset</code> <code>str</code> <p>Base currency (e.g., \"BTC\" in \"BTCUSDT\")</p> <code>quote_asset</code> <code>str</code> <p>Quote currency (e.g., \"USDT\" in \"BTCUSDT\")</p> <code>status</code> <code>str</code> <p>Trading status (\"TRADING\", \"HALT\", \"BREAK\", etc.)</p> <code>filters</code> <code>SymbolFilters</code> <p>Price/quantity filters</p> <code>trading_hours</code> <code>TradingHours</code> <p>Market hours</p> <code>contract_type</code> <code>str | None</code> <p>For futures (\"PERPETUAL\", \"CURRENT_QUARTER\", etc.)</p> <code>delivery_date</code> <code>str | None</code> <p>For futures contracts</p> <code>margin_asset</code> <code>str | None</code> <p>Asset used for margin</p> <code>fee_tier</code> <code>str | None</code> <p>Fee tier or maker/taker fees</p> <code>source</code> <code>str | None</code> <p>Data source</p>"},{"location":"reference/models/#qldata.SymbolInfo.is_spot","title":"is_spot  <code>property</code>","text":"<pre><code>is_spot: bool\n</code></pre> <p>Check if this is a spot market.</p>"},{"location":"reference/models/#qldata.SymbolInfo.is_perpetual","title":"is_perpetual  <code>property</code>","text":"<pre><code>is_perpetual: bool\n</code></pre> <p>Check if this is a perpetual contract.</p>"},{"location":"reference/models/#qldata.SymbolInfo.is_futures","title":"is_futures  <code>property</code>","text":"<pre><code>is_futures: bool\n</code></pre> <p>Check if this is a dated futures contract.</p>"},{"location":"reference/models/#qldata.SymbolInfo.is_active","title":"is_active  <code>property</code>","text":"<pre><code>is_active: bool\n</code></pre> <p>Check if symbol is actively trading.</p>"},{"location":"reference/models/#qldata.SymbolInfo.validate_price","title":"validate_price","text":"<pre><code>validate_price(price: Decimal) -&gt; bool\n</code></pre> <p>Check if price meets filter requirements.</p> <p>Parameters:</p> Name Type Description Default <code>price</code> <code>Decimal</code> <p>Price to validate</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if valid, False otherwise</p>"},{"location":"reference/models/#qldata.SymbolInfo.validate_quantity","title":"validate_quantity","text":"<pre><code>validate_quantity(quantity: Decimal) -&gt; bool\n</code></pre> <p>Check if quantity meets filter requirements.</p> <p>Parameters:</p> Name Type Description Default <code>quantity</code> <code>Decimal</code> <p>Quantity to validate</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if valid, False otherwise</p>"},{"location":"reference/models/#qldata.SymbolInfo.validate_notional","title":"validate_notional","text":"<pre><code>validate_notional(\n    price: Decimal, quantity: Decimal\n) -&gt; bool\n</code></pre> <p>Check if notional value (price * quantity) meets requirements.</p> <p>Parameters:</p> Name Type Description Default <code>price</code> <code>Decimal</code> <p>Order price</p> required <code>quantity</code> <code>Decimal</code> <p>Order quantity</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if valid, False otherwise</p>"},{"location":"reference/models/#tradingfilters","title":"TradingFilters","text":"<p>Trading constraints for a symbol.</p> Property Type Description <code>tick_size</code> <code>Decimal</code> Minimum price increment <code>step_size</code> <code>Decimal</code> Minimum quantity increment <code>min_quantity</code> <code>Decimal</code> Minimum order quantity <code>max_quantity</code> <code>Decimal</code> Maximum order quantity <code>min_notional</code> <code>Decimal</code> Minimum order value"},{"location":"reference/models/#type-aliases","title":"Type Aliases","text":"<p>Common type aliases used in qldata:</p> <pre><code>from typing import Union, Dict\nimport pandas as pd\n\n# Single or multi-symbol data\nDataResult = Union[pd.DataFrame, Dict[str, pd.DataFrame]]\n\n# Callback types\nDataCallback = Callable[[pd.DataFrame], None]\nErrorCallback = Callable[[Exception], None]\nCloseCallback = Callable[[], None]\n</code></pre>"},{"location":"reference/models/#see-also","title":"See Also","text":"<ul> <li>Historical Data API - Using models with queries</li> <li>Reference Data API - Getting symbol info</li> </ul>"},{"location":"user-guide/concepts/","title":"Core Concepts","text":"<p>This guide explains the fundamental concepts and design principles behind qldata.</p>"},{"location":"user-guide/concepts/#design-philosophy","title":"Design Philosophy","text":"<p>qldata is built around three core principles:</p> <ol> <li>Fluent API - Chainable methods that read like natural language</li> <li>Sensible Defaults - Production-ready settings out of the box</li> <li>Explicit Over Implicit - Clear, predictable behavior</li> </ol>"},{"location":"user-guide/concepts/#the-fluent-api-pattern","title":"The Fluent API Pattern","text":"<p>qldata uses a fluent interface (also called method chaining). Each method returns an object that allows calling the next method:</p> <pre><code># Traditional style (not qldata)\nquery = Query(\"BTCUSDT\", \"binance\")\nquery.set_days(30)\nquery.set_resolution(\"1h\")\ndf = query.execute()\n\n# Fluent style (qldata)\ndf = qd.data(\"BTCUSDT\", source=\"binance\") \\\n    .last(30) \\\n    .resolution(\"1h\") \\\n    .get()\n</code></pre>"},{"location":"user-guide/concepts/#query-vs-execution","title":"Query vs Execution","text":"<p>The fluent chain builds a query object. No data is fetched until you call <code>.get()</code>:</p> <pre><code># This only creates a query configuration - no network calls\nquery = qd.data(\"BTCUSDT\", source=\"binance\") \\\n    .last(30) \\\n    .resolution(\"1h\")\n\n# This actually fetches the data\ndf = query.get()\n\n# Queries are reusable\ndf1 = query.get()  # Fetches again\ndf2 = query.clean().get()  # Same query, with cleaning\n</code></pre>"},{"location":"user-guide/concepts/#data-models","title":"Data Models","text":"<p>qldata uses strongly-typed data models for consistency across exchanges.</p>"},{"location":"user-guide/concepts/#bar-ohlcv","title":"Bar (OHLCV)","text":"<p>The most common data type - candlestick/bar data:</p> <pre><code>from qldata import Bar\n\n# Returned as pandas DataFrame with these columns:\n# - open: float - Opening price\n# - high: float - Highest price\n# - low: float - Lowest price\n# - close: float - Closing price\n# - volume: float - Trading volume\n# Index: timestamp (pandas Timestamp, UTC)\n</code></pre>"},{"location":"user-guide/concepts/#tick-trade","title":"Tick (Trade)","text":"<p>Individual trade/tick data:</p> <pre><code>from qldata import Tick\n\n# Columns:\n# - price: float - Trade price\n# - quantity: float - Trade quantity\n# - symbol: str - Trading pair\n# - side: str - \"buy\" or \"sell\"\n# Index: timestamp (pandas Timestamp, UTC)\n</code></pre>"},{"location":"user-guide/concepts/#orderbook","title":"OrderBook","text":"<p>Order book snapshots:</p> <pre><code>from qldata import OrderBook, OrderBookLevel\n\n# OrderBook contains:\n# - bids: List[OrderBookLevel] - Buy orders\n# - asks: List[OrderBookLevel] - Sell orders\n# - timestamp: datetime - Snapshot time\n# - symbol: str - Trading pair\n\n# OrderBookLevel contains:\n# - price: Decimal\n# - quantity: Decimal\n</code></pre>"},{"location":"user-guide/concepts/#symbolinfo","title":"SymbolInfo","text":"<p>Trading pair metadata:</p> <pre><code>from qldata import SymbolInfo\n\ninfo = qd.get_symbol_info(\"BTCUSDT\", source=\"binance\")\n\n# Properties:\n# - symbol: str - Trading pair name\n# - base_asset: str - Base currency (BTC)\n# - quote_asset: str - Quote currency (USDT)\n# - status: str - Trading status\n# - is_active: bool - Currently trading\n# - is_spot: bool - Spot market\n# - is_perpetual: bool - Perpetual contract\n# - filters: TradingFilters - Price/quantity constraints\n</code></pre>"},{"location":"user-guide/concepts/#timeframe","title":"Timeframe","text":"<p>Time intervals for bar data:</p> <pre><code>from qldata import Timeframe\n\n# Pre-defined timeframes:\nTimeframe.MINUTE_1   # 1m\nTimeframe.MINUTE_5   # 5m\nTimeframe.MINUTE_15  # 15m\nTimeframe.HOUR_1     # 1h\nTimeframe.HOUR_4     # 4h\nTimeframe.DAY_1      # 1d\nTimeframe.WEEK_1     # 1w\n</code></pre>"},{"location":"user-guide/concepts/#exchange-categories","title":"Exchange Categories","text":"<p>Different exchanges organize their markets differently:</p>"},{"location":"user-guide/concepts/#binance-categories","title":"Binance Categories","text":"Category Market Type Symbol Example <code>\"spot\"</code> Spot trading BTCUSDT <code>\"usdm\"</code> USD-Margined perpetual futures BTCUSDT <pre><code># Binance spot\ndf = qd.data(\"BTCUSDT\", source=\"binance\", category=\"spot\").last(7).resolution(\"1h\").get()\n\n# Binance USDM futures\ndf = qd.data(\"BTCUSDT\", source=\"binance\", category=\"usdm\").last(7).resolution(\"1h\").get()\n</code></pre>"},{"location":"user-guide/concepts/#bybit-categories","title":"Bybit Categories","text":"Category Market Type Symbol Example <code>\"spot\"</code> Spot trading BTCUSDT <code>\"linear\"</code> Linear perpetual contracts BTCUSDT <pre><code># Bybit spot\ndf = qd.data(\"BTCUSDT\", source=\"bybit\", category=\"spot\").last(7).resolution(\"1h\").get()\n\n# Bybit linear perpetuals\ndf = qd.data(\"BTCUSDT\", source=\"bybit\", category=\"linear\").last(7).resolution(\"1h\").get()\n</code></pre>"},{"location":"user-guide/concepts/#transform-pipeline","title":"Transform Pipeline","text":"<p>qldata provides a powerful data transformation system:</p>"},{"location":"user-guide/concepts/#built-in-transforms","title":"Built-in Transforms","text":"<pre><code># Cleaning (removes duplicates, sorts, validates)\n.clean()\n\n# Fill missing values\n.fill_forward()      # Forward fill\n.fill_backward()     # Backward fill\n.interpolate()       # Linear interpolation\n\n# Resample to different timeframe\n.resample(\"1h\")\n</code></pre>"},{"location":"user-guide/concepts/#transform-order","title":"Transform Order","text":"<p>Transforms are applied in the order you specify:</p> <pre><code># Good: Clean first, then fill, then resample\ndf = qd.data(\"BTCUSDT\", source=\"binance\") \\\n    .last(7) \\\n    .resolution(\"1m\") \\\n    .clean() \\\n    .fill_forward() \\\n    .resample(\"1h\") \\\n    .get()\n\n# Order matters! This produces different results:\ndf = qd.data(\"BTCUSDT\", source=\"binance\") \\\n    .last(7) \\\n    .resolution(\"1m\") \\\n    .resample(\"1h\") \\     # Resample before cleaning\n    .clean() \\\n    .fill_forward() \\\n    .get()\n</code></pre>"},{"location":"user-guide/concepts/#custom-pipelines","title":"Custom Pipelines","text":"<p>For advanced use cases, create custom transform pipelines:</p> <pre><code>from qldata import TransformPipeline\n\npipeline = TransformPipeline() \\\n    .add(remove_duplicates) \\\n    .add(remove_outliers, sigma=3) \\\n    .add(fill_forward)\n\ndf = pipeline.apply(raw_df)\n</code></pre>"},{"location":"user-guide/concepts/#resilience-features","title":"Resilience Features","text":"<p>qldata is designed for production use with built-in resilience:</p>"},{"location":"user-guide/concepts/#auto-reconnect","title":"Auto-Reconnect","text":"<p>Streaming connections automatically reconnect on failure:</p> <pre><code>stream = qd.stream([\"BTCUSDT\"], source=\"binance\") \\\n    .resolution(\"tick\") \\\n    .on_data(handler) \\\n    .get(start=True)  # Auto-reconnect enabled by default\n</code></pre>"},{"location":"user-guide/concepts/#rate-limiting","title":"Rate Limiting","text":"<p>API calls respect exchange rate limits automatically:</p> <pre><code># Even with many symbols, rate limits are handled\ndata = qd.data([\"BTC\", \"ETH\", \"SOL\", \"DOGE\", \"XRP\"], source=\"binance\") \\\n    .last(30) \\\n    .resolution(\"1m\") \\\n    .get(parallel=True, workers=4)  # Workers respect rate limits\n</code></pre>"},{"location":"user-guide/concepts/#sequence-tracking","title":"Sequence Tracking","text":"<p>Streaming detects missed messages:</p> <pre><code>from qldata.resilience import SequenceTracker\n\n# Built into streaming sessions\n# Automatically logs warnings for gaps\n</code></pre>"},{"location":"user-guide/concepts/#configuration","title":"Configuration","text":""},{"location":"user-guide/concepts/#global-configuration","title":"Global Configuration","text":"<pre><code>import qldata as qd\n\n# Configure at startup\nqd.config(\n    data_dir=\"./market_data\",     # Where to cache data\n    cache_enabled=True,           # Enable disk caching\n    validation_enabled=True       # Validate data on fetch\n)\n</code></pre>"},{"location":"user-guide/concepts/#per-query-configuration","title":"Per-Query Configuration","text":"<pre><code># Override config for specific queries\ndf = qd.data(\"BTCUSDT\", source=\"binance\") \\\n    .last(30) \\\n    .resolution(\"1h\") \\\n    .get(\n        cache=False,      # Don't cache this query\n        validate=False    # Skip validation\n    )\n</code></pre>"},{"location":"user-guide/concepts/#environment-variables","title":"Environment Variables","text":"Variable Description <code>QLDATA_DATA_DIR</code> Data directory path <code>QLDATA_CACHE_ENABLED</code> Enable caching (<code>true</code>/<code>false</code>) <code>QLDATA_VALIDATION_ENABLED</code> Enable validation (<code>true</code>/<code>false</code>)"},{"location":"user-guide/concepts/#error-handling","title":"Error Handling","text":"<p>qldata uses a consistent exception hierarchy:</p> <pre><code>from qldata.errors import (\n    QldataError,           # Base exception\n    ConnectionError,       # Network issues\n    RateLimitError,        # Rate limit exceeded\n    ValidationError,       # Data validation failed\n    ConfigurationError,    # Invalid configuration\n)\n\ntry:\n    df = qd.data(\"INVALID\", source=\"binance\").last(1).get()\nexcept ValidationError as e:\n    print(f\"Validation failed: {e}\")\nexcept ConnectionError as e:\n    print(f\"Network error: {e}\")\nexcept QldataError as e:\n    print(f\"qldata error: {e}\")\n</code></pre>"},{"location":"user-guide/concepts/#best-practices","title":"Best Practices","text":""},{"location":"user-guide/concepts/#1-use-the-fluent-api","title":"1. Use the Fluent API","text":"<pre><code># \u2713 Good - Clear and readable\ndf = qd.data(\"BTCUSDT\", source=\"binance\") \\\n    .last(30) \\\n    .resolution(\"1h\") \\\n    .clean() \\\n    .get()\n\n# \u2717 Avoid - Breaking the chain\nquery = qd.data(\"BTCUSDT\", source=\"binance\")\nquery = query.last(30)\nquery = query.resolution(\"1h\")\ndf = query.get()\n</code></pre>"},{"location":"user-guide/concepts/#2-always-clean-production-data","title":"2. Always Clean Production Data","text":"<pre><code># \u2713 Good - Data is validated\ndf = qd.data(...).clean().get()\n\n# \u2717 Risky - Raw data may have issues\ndf = qd.data(...).get()\n</code></pre>"},{"location":"user-guide/concepts/#3-handle-errors-gracefully","title":"3. Handle Errors Gracefully","text":"<pre><code># \u2713 Good - Explicit error handling\ntry:\n    df = qd.data(...).get()\nexcept QldataError as e:\n    logger.error(f\"Data fetch failed: {e}\")\n    df = fallback_data()\n</code></pre>"},{"location":"user-guide/concepts/#4-use-appropriate-parallelism","title":"4. Use Appropriate Parallelism","text":"<pre><code># \u2713 Good - Parallel for many symbols\ndata = qd.data(symbols, source=\"binance\") \\\n    .get(parallel=True, workers=4)\n\n# \u2717 Wasteful - Parallel for single symbol\ndf = qd.data(\"BTCUSDT\", source=\"binance\") \\\n    .get(parallel=True, workers=4)\n</code></pre>"},{"location":"user-guide/concepts/#next-steps","title":"Next Steps","text":"<ul> <li>Historical Data API - Deep dive into <code>qd.data()</code></li> <li>Streaming API - Learn about <code>qd.stream()</code></li> <li>Resilience - Production resilience features</li> </ul>"},{"location":"user-guide/installation/","title":"Installation","text":"<p>This guide covers how to install qldata and its dependencies.</p>"},{"location":"user-guide/installation/#requirements","title":"Requirements","text":"<ul> <li>Python 3.10+ (3.10, 3.11, or 3.12 recommended)</li> <li>pip or another Python package manager</li> </ul>"},{"location":"user-guide/installation/#installation-options","title":"Installation Options","text":""},{"location":"user-guide/installation/#full-installation-recommended","title":"Full Installation (Recommended)","text":"<p>The default installation includes all core dependencies plus support for Binance, Bybit, and DuckDB storage:</p> <pre><code>pip install qldata\n</code></pre> <p>This installs:</p> <ul> <li>Core data processing: <code>pandas</code>, <code>numpy</code>, <code>pyarrow</code></li> <li>Exchange adapters: <code>python-binance</code>, <code>pybit</code></li> <li>Database storage: <code>duckdb</code></li> <li>Live streaming: <code>websockets</code>, <code>aiohttp</code></li> <li>Utilities: <code>tenacity</code> (retry logic)</li> </ul>"},{"location":"user-guide/installation/#minimal-installation","title":"Minimal Installation","text":"<p>For lightweight deployments or when you only need core functionality:</p> <pre><code>pip install qldata[minimal]\n</code></pre> <p>This installs only:</p> <ul> <li><code>pandas&gt;=2.0.0</code></li> <li><code>numpy&gt;=1.24.0</code></li> <li><code>python-dateutil&gt;=2.8.0</code></li> </ul>"},{"location":"user-guide/installation/#exchange-specific-installation","title":"Exchange-Specific Installation","text":"<p>Install support for specific exchanges only:</p> BinanceBybitAll Exchanges <pre><code>pip install qldata[binance]\n</code></pre> <p>Includes: <code>python-binance</code>, <code>websockets</code></p> <pre><code>pip install qldata[bybit]\n</code></pre> <p>Includes: <code>pybit</code></p> <pre><code>pip install qldata[exchanges]\n</code></pre> <p>Includes: <code>python-binance</code>, <code>pybit</code>, <code>websockets</code></p>"},{"location":"user-guide/installation/#feature-specific-installation","title":"Feature-Specific Installation","text":"Storage BackendsStreaming SupportEverything <pre><code>pip install qldata[storage]\n</code></pre> <p>Includes: <code>pyarrow</code>, <code>duckdb</code></p> <pre><code>pip install qldata[stream]\n</code></pre> <p>Includes: <code>websockets</code>, <code>aiohttp</code></p> <pre><code>pip install qldata[all]\n</code></pre> <p>Includes all optional dependencies</p>"},{"location":"user-guide/installation/#development-installation","title":"Development Installation","text":"<p>For contributors and developers:</p> <pre><code>pip install qldata[dev]\n</code></pre> <p>This includes:</p> <ul> <li>Testing: <code>pytest</code>, <code>pytest-cov</code>, <code>pytest-asyncio</code></li> <li>Linting: <code>black</code>, <code>ruff</code>, <code>mypy</code></li> <li>Documentation: <code>mkdocs-material</code>, <code>mkdocstrings</code></li> </ul>"},{"location":"user-guide/installation/#verify-installation","title":"Verify Installation","text":"<p>After installation, verify everything works:</p> <pre><code>import qldata as qd\n\n# Check version\nprint(f\"qldata version: {qd.__version__}\")\n\n# Quick test - fetch symbol info (no API key required)\ntry:\n    info = qd.get_symbol_info(\"BTCUSDT\", source=\"binance\", category=\"spot\")\n    print(f\"\u2713 Successfully connected to Binance\")\n    print(f\"  Symbol: {info.symbol}\")\n    print(f\"  Status: {info.status}\")\nexcept Exception as e:\n    print(f\"\u2717 Connection error: {e}\")\n</code></pre> <p>Expected output:</p> <pre><code>qldata version: 0.3.0\n\u2713 Successfully connected to Binance\n  Symbol: BTCUSDT\n  Status: TRADING\n</code></pre>"},{"location":"user-guide/installation/#configuration","title":"Configuration","text":""},{"location":"user-guide/installation/#environment-variables","title":"Environment Variables","text":"<p>qldata uses the following optional environment variables:</p> Variable Description Default <code>QLDATA_DATA_DIR</code> Directory for cached data <code>~/.qldata</code> <code>QLDATA_CACHE_ENABLED</code> Enable/disable caching <code>true</code> <code>QLDATA_VALIDATION_ENABLED</code> Enable/disable data validation <code>true</code> <code>BINANCE_API_KEY</code> Binance API key (for private endpoints) None <code>BINANCE_API_SECRET</code> Binance API secret None <code>BYBIT_API_KEY</code> Bybit API key (for private endpoints) None <code>BYBIT_API_SECRET</code> Bybit API secret None <p>API Keys Not Required for Public Data</p> <p>For most use cases (market data, historical bars, public trades), API keys are not required. Keys are only needed for private endpoints like account balances or order placement.</p>"},{"location":"user-guide/installation/#python-configuration","title":"Python Configuration","text":"<p>You can also configure qldata programmatically:</p> <pre><code>import qldata as qd\n\n# Configure at runtime\nqd.config(\n    data_dir=\"./my_data\",\n    cache_enabled=True,\n    validation_enabled=True\n)\n\n# Check current configuration\nprint(f\"Data directory: {qd.get_data_dir()}\")\nprint(f\"Cache enabled: {qd.is_cache_enabled()}\")\nprint(f\"Validation enabled: {qd.is_validation_enabled()}\")\n</code></pre>"},{"location":"user-guide/installation/#troubleshooting","title":"Troubleshooting","text":""},{"location":"user-guide/installation/#common-issues","title":"Common Issues","text":"ImportError: No module named 'binance' <p>You have the minimal installation. Install Binance support: <pre><code>pip install qldata[binance]\n</code></pre></p> ImportError: No module named 'pybit' <p>You have the minimal installation. Install Bybit support: <pre><code>pip install qldata[bybit]\n</code></pre></p> SSL Certificate Errors <p>Some networks block WebSocket connections. Try:</p> <ol> <li>Check your firewall/VPN settings</li> <li>Update <code>certifi</code>: <code>pip install --upgrade certifi</code></li> <li>If in China, consider using proxy settings</li> </ol> Connection Timeout Errors <p>Exchange APIs may be slow or rate-limited:</p> <ol> <li>Check your internet connection</li> <li>Try a different exchange (Binance vs Bybit)</li> <li>Wait a few minutes if rate-limited</li> </ol>"},{"location":"user-guide/installation/#getting-help","title":"Getting Help","text":"<ul> <li>\ud83d\udcd6 Browse the full documentation</li> <li>\ud83d\udc1b Report issues on GitHub</li> <li>\ud83d\udcac Check the Cookbook for examples</li> </ul>"},{"location":"user-guide/installation/#next-steps","title":"Next Steps","text":"<p>Ready to start using qldata?</p> <ul> <li>Quick Start Guide - Your first data query</li> <li>Core Concepts - Understand the API design</li> <li>Historical Data - Detailed API reference</li> </ul>"},{"location":"user-guide/quickstart/","title":"Quick Start","text":"<p>Get up and running with qldata in minutes. This guide covers the essential operations you'll use most frequently.</p>"},{"location":"user-guide/quickstart/#import-convention","title":"Import Convention","text":"<p>By convention, we import qldata as <code>qd</code>:</p> <pre><code>import qldata as qd\n</code></pre> <p>This keeps your code concise while making it clear you're using qldata functions.</p>"},{"location":"user-guide/quickstart/#fetching-historical-data","title":"Fetching Historical Data","text":"<p>The <code>qd.data()</code> function is your gateway to historical market data. It uses a fluent (chainable) API that reads naturally:</p>"},{"location":"user-guide/quickstart/#basic-example","title":"Basic Example","text":"<pre><code>import qldata as qd\n\n# Fetch last 30 days of hourly BTCUSDT data from Binance\ndf = qd.data(\"BTCUSDT\", source=\"binance\", category=\"spot\") \\\n    .last(30) \\\n    .resolution(\"1h\") \\\n    .get()\n\nprint(df.head())\n</code></pre> <p>Output: <pre><code>                            open      high       low     close      volume\ntimestamp                                                                 \n2024-11-05 00:00:00+00:00  69500.00  69750.00  69400.00  69600.00  1250.5432\n2024-11-05 01:00:00+00:00  69600.00  69800.00  69550.00  69750.00  1180.2341\n2024-11-05 02:00:00+00:00  69750.00  69900.00  69700.00  69850.00  1320.8765\n...\n</code></pre></p>"},{"location":"user-guide/quickstart/#understanding-the-api","title":"Understanding the API","text":"<p>Let's break down the query:</p> <pre><code>df = qd.data(\"BTCUSDT\", source=\"binance\", category=\"spot\")  # (1)!\n    .last(30)           # (2)!\n    .resolution(\"1h\")   # (3)!\n    .get()              # (4)!\n</code></pre> <ol> <li>Create a query for BTCUSDT on Binance spot market</li> <li>Set time range to the last 30 days</li> <li>Set resolution to 1-hour bars</li> <li>Execute the query and return a DataFrame</li> </ol>"},{"location":"user-guide/quickstart/#different-time-ranges","title":"Different Time Ranges","text":"<pre><code># Last N days (default unit)\ndf = qd.data(\"BTCUSDT\", source=\"binance\").last(7).resolution(\"1h\").get()\n\n# Explicit time unit\ndf = qd.data(\"BTCUSDT\", source=\"binance\").last(24, \"hours\").resolution(\"1m\").get()\n\n# Specific date range\nfrom datetime import datetime\ndf = qd.data(\"BTCUSDT\", source=\"binance\") \\\n    .range(datetime(2024, 1, 1), datetime(2024, 1, 31)) \\\n    .resolution(\"1d\") \\\n    .get()\n</code></pre>"},{"location":"user-guide/quickstart/#different-resolutions","title":"Different Resolutions","text":"Resolution Description <code>\"1m\"</code> 1-minute bars <code>\"5m\"</code> 5-minute bars <code>\"15m\"</code> 15-minute bars <code>\"1h\"</code> 1-hour bars <code>\"4h\"</code> 4-hour bars <code>\"1d\"</code> Daily bars <code>\"1w\"</code> Weekly bars"},{"location":"user-guide/quickstart/#market-categories","title":"Market Categories","text":"BinanceBybit Category Description <code>\"spot\"</code> Spot market <code>\"usdm\"</code> USD-Margined perpetual futures Category Description <code>\"spot\"</code> Spot market <code>\"linear\"</code> Linear perpetual contracts"},{"location":"user-guide/quickstart/#cleaning-data","title":"Cleaning Data","text":"<p>Raw market data often needs cleaning. qldata provides a built-in cleaning pipeline:</p> <pre><code># Basic cleaning (removes duplicates, sorts by time)\ndf = qd.data(\"BTCUSDT\", source=\"binance\") \\\n    .last(30) \\\n    .resolution(\"1h\") \\\n    .clean() \\\n    .get()\n\n# Aggressive cleaning for production\ndf = qd.data(\"BTCUSDT\", source=\"binance\") \\\n    .last(30) \\\n    .resolution(\"1h\") \\\n    .clean(\n        remove_invalid_prices=True,  # Remove zero/negative prices\n        validate_ohlc=True,          # Ensure high &gt;= low, etc.\n        remove_outliers=True         # Remove statistical outliers\n    ) \\\n    .get()\n</code></pre>"},{"location":"user-guide/quickstart/#fill-missing-data","title":"Fill Missing Data","text":"<pre><code># Forward fill (use last known value)\ndf = qd.data(\"BTCUSDT\", source=\"binance\") \\\n    .last(30) \\\n    .resolution(\"1h\") \\\n    .clean() \\\n    .fill_forward() \\\n    .get()\n\n# Interpolate (linear interpolation)\ndf = qd.data(\"BTCUSDT\", source=\"binance\") \\\n    .last(30) \\\n    .resolution(\"1h\") \\\n    .clean() \\\n    .interpolate() \\\n    .get()\n</code></pre>"},{"location":"user-guide/quickstart/#resample-data","title":"Resample Data","text":"<pre><code># Fetch 1-minute data and resample to 1-hour\ndf = qd.data(\"BTCUSDT\", source=\"binance\") \\\n    .last(1, \"days\") \\\n    .resolution(\"1m\") \\\n    .clean() \\\n    .resample(\"1h\") \\\n    .get()\n</code></pre>"},{"location":"user-guide/quickstart/#multi-symbol-queries","title":"Multi-Symbol Queries","text":"<p>Fetch data for multiple symbols at once:</p> <pre><code># Sequential (default)\ndata = qd.data([\"BTCUSDT\", \"ETHUSDT\", \"SOLUSDT\"], source=\"binance\") \\\n    .last(7) \\\n    .resolution(\"1d\") \\\n    .get()\n\n# Parallel for faster downloads\ndata = qd.data([\"BTCUSDT\", \"ETHUSDT\", \"SOLUSDT\"], source=\"binance\") \\\n    .last(7) \\\n    .resolution(\"1d\") \\\n    .get(parallel=True, workers=4)\n\n# Returns a dictionary of DataFrames\nfor symbol, df in data.items():\n    print(f\"{symbol}: {len(df)} bars\")\n</code></pre>"},{"location":"user-guide/quickstart/#live-streaming","title":"Live Streaming","text":"<p>Stream real-time market data with auto-reconnect and resilience features:</p> <pre><code>import qldata as qd\nimport time\n\ndef handle_data(df):\n    \"\"\"Called when new data arrives.\"\"\"\n    if not df.empty:\n        latest = df.iloc[-1]\n        print(f\"[{latest['symbol']}] Price: {latest['price']}\")\n\ndef handle_error(error):\n    \"\"\"Called on errors.\"\"\"\n    print(f\"Error: {error}\")\n\ndef handle_close():\n    \"\"\"Called when stream closes.\"\"\"\n    print(\"Stream closed\")\n\n# Create and start the stream\nstream = qd.stream([\"BTCUSDT\", \"ETHUSDT\"], source=\"binance\", category=\"spot\") \\\n    .resolution(\"tick\") \\\n    .on_data(handle_data) \\\n    .on_error(handle_error) \\\n    .on_close(handle_close) \\\n    .get(start=True)\n\n# Stream runs in the background\ntry:\n    while True:\n        time.sleep(1)\nexcept KeyboardInterrupt:\n    stream.stop()\n</code></pre>"},{"location":"user-guide/quickstart/#stream-resolutions","title":"Stream Resolutions","text":"Resolution Description <code>\"tick\"</code> Individual trades (raw) <code>\"1m\"</code> Aggregated 1-minute bars"},{"location":"user-guide/quickstart/#symbol-information","title":"Symbol Information","text":"<p>Get metadata about trading pairs:</p> <pre><code>import qldata as qd\n\n# Get symbol information\ninfo = qd.get_symbol_info(\"BTCUSDT\", source=\"binance\", category=\"spot\")\n\nprint(f\"Symbol: {info.symbol}\")\nprint(f\"Base/Quote: {info.base_asset}/{info.quote_asset}\")\nprint(f\"Status: {info.status}\")\nprint(f\"Tick Size: {info.filters.tick_size}\")\nprint(f\"Min Quantity: {info.filters.min_quantity}\")\n\n# Validate prices and quantities\nfrom decimal import Decimal\nis_valid = info.validate_price(Decimal(\"50000.50\"))\nis_valid = info.validate_quantity(Decimal(\"0.001\"))\n</code></pre>"},{"location":"user-guide/quickstart/#list-available-symbols","title":"List Available Symbols","text":"<pre><code># All active USDT pairs on Binance spot\npairs = qd.list_symbols(\n    source=\"binance\",\n    category=\"spot\",\n    quote_asset=\"USDT\",\n    active_only=True\n)\nprint(f\"Found {len(pairs)} USDT pairs\")\n\n# All BTC pairs\nbtc_pairs = qd.list_symbols(\n    source=\"binance\",\n    category=\"spot\",\n    base_asset=\"BTC\"\n)\n</code></pre>"},{"location":"user-guide/quickstart/#exchange-information","title":"Exchange Information","text":"<pre><code># Get exchange-level information\nexchange = qd.get_exchange_info(source=\"binance\")\n\nprint(f\"Exchange: {exchange.exchange}\")\nprint(f\"Timezone: {exchange.timezone}\")\nprint(f\"Total Symbols: {exchange.symbol_count}\")\n</code></pre>"},{"location":"user-guide/quickstart/#funding-rates","title":"Funding Rates","text":"<p>For perpetual futures, get funding rate information:</p> <pre><code># Current funding rate\nrate = qd.current_funding_rate(\"BTCUSDT\", source=\"binance\", category=\"usdm\")\nprint(f\"Current Rate: {rate}\")\n</code></pre>"},{"location":"user-guide/quickstart/#whats-next","title":"What's Next?","text":"<p>Now that you know the basics, explore:</p> <ul> <li>Core Concepts - Understand the architecture</li> <li>Historical Data API - Full API reference</li> <li>Streaming API - Advanced streaming features</li> <li>Cookbook - Real-world examples</li> </ul>"}]}